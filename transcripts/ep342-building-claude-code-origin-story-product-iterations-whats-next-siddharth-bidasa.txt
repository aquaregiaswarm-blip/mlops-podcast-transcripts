I've seen people with like 100 MCB servers installed or something like that. And I was like, what are you even do with 100 MCB servers but hey, it works for them, you know, like they're happy with it and, you know, it works for them. So, yeah. There's always like these, like, surprising things where all the composable parts of cloud code, like they're being used in such creative ways in ways that we didn't quite expect them kind of to be to be used.
 Tell me about Claude code. What what's the Genesis of it? Because I never heard the origin story.
 uh, yeah, so the original story is we
 In stopping had this team called the labs team and this the charter of this team was just a prototype new products to kind of play around with things and see what hits more of an experimentation team. Really?
 And that's kind of the team team that I joined when I joined into it and then one of my colleague's Boris he had he had this like Nifty little prototype when he joined in trouble. He already he killed it in his first week and it was basically access and clawed in a terminal.
 A nice and I couldn't, it couldn't like write code or I didn't have any access to any tools. It was, it was literally just like,
 You know, calling the the entropic apis from the terminal and you could like type into it. And I remember the first demo that he showed us he was just like he spun it up and then the first thing he wrote into it was like two plus two. And I was like bro that's like the worst thing you want to ask another, you know like ask it something something nice.
 But it was funny, I think like so that was, he's kind of like, you know, had that as a prototype and then we were experimenting with other coding services and other coding products. But at some point, he ended up adding two tools to do this late little terminal thing. He had the first one was the ability to control his Spotify.
 Yeah, nice. It was like, I want this under control my music, so he's like, all right, like me this. So, he added that from the terminal from the terminal.
 Because who doesn't want to operate Spotify from their Terminator? Exactly. Exactly.
 You know, are you really a hacker if you had over here, but the second thing he had, it was just like like filed duel file tools, like file, reading fired writing stuff like that.
 The moment he added that he like you know shared it with us and I was like holy shit. Like I got it was just like a instantly. I was like there's something here. It feels really ergonomic. It feels very different from you know like web-based apps and things like that. So I think I was still working on kind of some other surfaces then, but I was like, you know, I think I just want to join you and hack on this and he was he was all so kind of getting pulled into other projects. But then at some point kind of made a decision to be. Okay, let's just like double down and work on this a little bit more. So we spent a couple weeks hacking and then we kind of released it internally at entropic and like almost immediately just like got on like wildfire like people were just using it. Like everyone was so pretty excited and they were like, well, this is like within two weeks. We had like some 300, active daily users and this was one of the topic was like, 600 people in the whole company. Even this. Yeah. Oh, is using it? Yeah. No.
 Control, there's Spotify. You know, do you remember what model it was
 This was three five. This was sorry. This is three five, I think. Yeah, around this like, October October November of last year.
 Um, yeah. And I think that's kind of how it all started. And then once that, once we got some momentum internally, there was talk about launching externally. But honestly at the time like we weren't really sure if this is gonna be a thing we were like you know, this is still in the terminal kind of still feels a little Jank you know. It doesn't quite feel as polished as like cursor is like cursive feels like
 Oh, like, you know, they have this cool interface and they have the table auto complete, and they're like forking an IDE. Like, this is literally just a terminal. Like, it's just like a terminal app, so we had no idea. You know, if this was well, what would happen? And like, how this would be received, remember, I was like some food and there was like, you know, kind of all kinds of discussions going around, but yeah. Ultimately we decided to do like a small Lake EAP with a few customers like seeing what their response would be like and I people just really like that they like grew attached to it very quickly and that's when we can decided to launch more externally. And once we launched it and just say,
 After a couple weeks, it kind of blew up on social media and things like that. And just
 had a life of its own, but
 Yeah, it was it was not it was not a pattern at all like it would I feel like it was a lot of, like, happy accidents that happened among the way that like, kind of got caught us to that point.
 There's so many things that you said that are so fascinating. Right now one is that there's just like an R&D Department to go and try it and create cool new stuff and you are on that team which I love the second is the
 one tool that you added, that changed everything. And what was it about that tool you were like it's ergonomic, there's some different here. Why did you have that intuition there?
 Yeah, I think the final edit file rituals. It was I think the biggest thing was that these fires were local and you could spin up Claude anyway,
 Uh, with the most with kind of most products before that you'd have to have some sort of like synchronization or like setup step where you need to like copy over your files or you need to, you know, like create a Docker, image with your repo or give them like access to your git, repository or like some form of like sharing your files and then it could start working on those things. And then it was, it wasn't like super clear how to how to be collaborative in a product like that. Like, if if you're, if everything is being exported over to a VM where like your agent is running, how do I then very easily take what the agents done and then continue that and like improve that myself like, you know, like the models are pretty good and they're getting better, but they're not good enough to like zero shot at one shot everything. So I need to go in and make some changes, adjust things like you know, do things make it so that it looks like actual code and that was very hard to do.
 With these other products or like with kind of this other worldview. And I think in the terminal when you can just like spin it up, no matter what files you have, like, what repo it doesn't it doesn't matter. It's just what matters is that you have to file is locally. You can just spin up Claude, ask it to read a bunch of files. Ask it to explore, kind of the, you know, how a human would it just actually magical? It just felt really like
 Low friction. If it was a very low friction way of getting started and I think like that's kind of what felt really ergonomic about it.
 What's been your favorite feature that you added? I'll tell you mine first, the clear context window. Yeah.
 Slash clear? Yeah, yeah, yeah, yeah. It's that clear. It's cool. Yeah.
 How about you?
 I think my favorite feature that I added would probably be honestly like the to-do list.
 The to-do list was, I think that remains my favorite feature. Just something about like tasks, getting checked off and just like, you know, you are one that is doing them. Yeah. Yeah, it feels satisfied, you know, like feeling ever. Yeah. Yeah, it's just doing all this stuff for me. I'm just watching, like, it's like watching those tiktok videos where he cleaning of cars or houses. And you're like, this is oddly satisfying because I'm not the one that has to be the one cleaning right now. Yeah, exactly exactly. And I think like adding the to-do list, all so kind of just made the model, stay on track longer for like longer Horizon tasks and that was cool to see, too. Like, you see a lot of times like hey, like I have these 100 files? Can you go and, like edit their names or, you know, do something to them? And it would do like 30 of them and be like, I'm tired. Now, you know, you can do the rest by yourself or something like that and then like, you give it to do list tool and like it uses it. Let's create it to do list for itself and like
 Batches the 100 files and like, you know, batches of 10 Airmen keeps checking them off one at a time and it goes through. The whole thing is like, oh, this is, this is quite satisfying. Like now this is becoming a little bit more deterministic, not super deterministic still, but just a little bit more deterministic than it was before.
 Did you notice? Because I remember we had my friend David Hershey on here, who created Pokemon, Claude plays Pokemon, and he was talking about how for him, he saw
 Such a unlock that it was almost like this latent, unlock where people didn't realize, when a new model dropped the potential, it had, until they were playing around with it for a little while. And then you saw, whoa.
 This is really good at coding and there's something here. Did you notice like big jumps from different models?
 Oh, 100%. 100 percent I think.
 I think three like three five was pretty good and and but three seven is kind of like where things really started to come together.
 I think you could see a step change in the complexity of tasks that the model was now able to handle, you could see a step change in the way that the model kind of navigated through complex structures. You know, it's like it it almost feels like the there is like, you know, if I was to tackle the task, what would I do? It would like do a lot of those same things to kind of get to its conclusion. And that was really fascinating, and I think that I saw that step jump between 35 and 37, were, like immediately. Like, like 3/7 felt like it was just way more capable and I think, because like I I'm using the models all day every day, right. I think a lot of people at the topic are and just like even outside like so you get quite
 A tune to Model Behavior and then once you see a model behaving slightly differently, it jumps out like you can tell it's like it has a, it has a slightly different like smell to it, you know. It's like I can I can tell this is something different. Yeah, it's like, wait a minute. You just broke my frame of reference? Yeah, shouldn't do that. Yeah.
 Yeah, and it's also kind of tricky, you know, because like once you especially if you use coding agente, coding products, a lot like you you start to form an intuition about the kinds of things that it might be able to do versus the kinds of things that you might not. It might not be so good at and you'd probably have to play a more Hands-On role in getting that task to completion. But then, you know, a new model will come along. That's actually much better in a step change, and then you have to rewire your brain into like, okay, no. Now that I can it can actually do this now and that can be tricky for people sometimes like it can. And I think that might also just be a blocker, and like adoption of AI tools kind of going forward because people kind of form a point of view about what it can do. But then that that point of view needs to be adjusted, you know? Very very frequently or more frequently Than People realize.
 It's funny. You mention that because we had my buddy JQ on here and he was talking about how if, for some reason, the model like leans towards doing something, what you would consider the wrong way, then try to change your frame of reference into. Can I make it fit into what the models doing? Like if the model wants to always do this, can I see if I can now change me to let the model do that? And see if it can then complete the tasks, you know? Yeah yeah. That's a fascinating idea.
 Yeah, it makes up like, keeping the model on distribution, like, there's something there's something to that, right? Like if you, if you keep it on distribution, it's kind of doing what it really innately wants to. You're not trying to like, you know force it to go a certain way or like steer a certain way. Yeah, I think that's an interesting field of research and study too. Just like seeing kind of how keeping the model on distribution might actually help or
 Even if it's unintuitive to reaching one.
 there's something I want to talk about, that's close to your heart, which is this idea of forward compatibility and making sure that when
 You're creating today, you're not spending a bunch of time on something that is going to change in the next model drop or with some kind of unlock with, maybe it's like, oh, great. Now. We can just use mCP servers for that and so I wonder if you have examples of things that you have done in the past that ended up being like you almost shot yourself in the foot or it was just a quote unquote waste of time and I'll give you an example of one that my buddy Flores was talking about on the podcast, a few months ago. And he said, when chat TV came out, I spent so much time trying to extend the context window. I did everything I could to make it so that it was so janky. It was so hacky. And all I needed to do was be patient and wait and the context windows for all these different models. Just got bigger by default. And so I wonder if like you
 Have felt that in different areas where you're sitting there. Now looking back you realize I spent way too much time on this thing that I could have just been patient on.
 Yeah, there's a lot I think like one of the core like philosophies of our team is we, we absolutely love deleting code and like taking it and just deleting features. And and nice that I think that's like by Design somewhat because because of this exact issue because you're like, the you there's like a phrase that it's like, unhauling the model, right? Like it's like basically it translates to let the model cook, right? Like that, that is the the centerpiece and the showpiece here. And the harness is really just about providing the model with the tools that allows it to cook as a post to like trying to steer it in a way that's like unnatural or like steered in a way that you know, might be redundant in a few bottles releases. So, an example of that is like, when when clock code first came out, we we had, we had like a bunch of dudes like the ls tool, we
 Had a that was literally just for listing files. We had a few other tools that were just like very file system specific and then we realized that we don't really need any of these tools like we can just like literally just give it the Bosch tool and it like will know. It can just do all of these things just through the abstraction of of a bash command. So we stripped them all out and we like we don't we don't really want this in here and just gave it the Bosch tool and it still is able to do the same exact things, maybe even better than before just because like it understands the concept of Bosch so much better than a tool that we invented and gave it gave it gave to it.
 So, there's, there's like other kind of, fascinating examples of like, you know, how much harness is too much harness, right? I think. Like, it's, that's a question that kind of, I think everyone who's billing. AI apps is kind of asking and there isn't a clear answer, I think it just kind of there's a balance. It's more of an art really is. Like, you've got a balance it out because you want to be useful now to your users. But at the same time, you you want to be able to adapt and you want to be able, you want to be really agile. So that if the model changes tomorrow, you can just like, rip out and diabetes of your code base and just like do something else and just let it cook. So that's always like like hooks. I don't know if you've kind of used Cloud code hooks. Yeah. Or no? They're, they're like
 They're like, they're like a feature that allows you to kind of hook into the life cycle of cloud code.
 And what I mean by that is, let's say you want to a simple example, is like logging, right? Like you want to log every single tool, call that clock code makes this part of its like operations. So you can you can create a hook, you can register a dual call hook or I forget what actually aim is but that's effectively what it does is like it's a piece of code that the harness runs.
 Before each to a call and that piece of code is provided by you, it's provided by the user. So you can have a bash script, or you can kind of, have any kind of code that takes in some parameters, for, like, what dual is being called, what's the context before that? And a few other piece of information and it can return some information back into Claude, like, it can like disallow that tool or it can like steer it in a certain way. So it's like it's a very flexible system that kind of makes you that makes Cloud go a little bit more deterministic and like more composable according to how you want want it to be. I remember reading like oh my colleagues like Dickson kind of came up with this. And I remember thinking I was like
 Okay. Is this too much harness, you know like do we do we really want this but then I think that his point was like, quite I mean, clearly a lot of people are using it. A lot of people like like hooks, but his point was that, you know, like we need to kind of be somewhere in the middle. Like we need to. We this is a problem that we're facing right now with the model, you know, like does something that people don't want it to do and they want to steer it. So let's kind of create an abstraction that that works here. Like we're not trying to like, do something very heavy-handed, but we just kind of make that life cycle hooks which are very common concept you in many kind of like devtools, right? Like you you have these lifecycle hooks
 Yeah, so let's say it's always a struggle, kind of like trying to figure out like, what is, how much harness is too much harness.
 But kind of we lean towards this being leader rather than being more harness heavy.
 It's so funny that you mentioned that specific thing because last week I gave a talk all about. How there are a lot of downfalls with the chat interface, and one of the downfalls that I see is that we don't have this granular, steer ability if we want it.
 Because we're using words and words or inherently fuzzy, they're like symbols of things that we want to happen, right? And especially with language itself, you don't get like a knob that you can turn.
 you have a word that you use or you use a stronger word or you use a weaker word and so,
 You saying that makes me rethink will do we even need steer ability, right? Like, because your whole thesis is in the way of just let the model cook, you don't need to steer it. You just need to get out of its way and that was all kind of like jq's thing is when it's doing what you don't expect it to do then figure out how to make you fit into its patterns as opposed to it in your patterns. And so now I'm
 Like gonna have to go back and rethink this whole idea of this durability.
 Yeah, it's it's about balance. It's about balance, right? I think they I don't think like needing or wanting to your ability is entirely bad. I think it makes it makes sense, right? Like people are using it today and they want it to be useful for them right now. And if what they want right now is to your ability, and the model is not able to give it to them. Then really, the only option you have as an application developer is to create some harness that would allow the user to steer the model in one way or the other.
 But there's kind of two things to it. There's like one is the point that you were making earlier is like, oh, should I be changing my frame of reference and would that help? And then the second is what would happen if let's say two months from now, there's a new model that comes out and like it just does it for you. Yeah. What did you just spend a whole bunch of resources on it for nothing? So, so I think it's like being agile, like, having a tech stack that allows you to be really agile, Dexter, kind of allows you to experiment a bunch. And you don't feel bad, really throwing away, a lot of your code like that that becomes really key, right? Like, it's it's because you should and you should experiment with the harnesses and you should experiment with letting it steer order or like more heavy-handed steering mechanisms, but then at the same time, when the time comes, it should be easier about. It's not like you've now, like build five more things on top of that steering abstraction, and now it's like impossible to take out from your clothing and now your thoughts. Right. Exactly. That's like, you gotta you. So it's about committed. It's like
 I can't delete that it holds up the rest of this mountain of code that I have. And so you're you really like got yourself into a pickle, right? Yeah.
 What features are on The Chopping Block in your mind? Like you would be happy to delete.
 Oh, I would be really happy to delete hooks.
 like I think, I think like if
 If the model was just working perfectly in a perfect world, you wouldn't need hooks.
 Right, like you, you can just like tell them all you want to do, when you can have like different ways of ingesting, some sort of context into the model and the model is adheres to it perfectly every single time, let's say, you have like let's say like like probably the most common use case of hook is hooks is logging.
 So you can literally just tell the model. Hey, like every time you use a tool like log it using this endpoint,
 And if it adheres to your your contacts or your request perfectly, you don't need hooks anymore.
 Because hooks are way of like, adding determinism to do like an inherently, like abstract inherently like non-deterministic process, so that would be really cool.
 Let's see what other tools.
 I think we've like kept we I think we've done a pretty good job of keeping like our tool is pretty lean. Like we've been leading a bunch of code, a bunch of tools like over time. That's like the the big one that kind of comes to mind is maybe maybe like some memory features, right? Like if the model had Perfect Memory and perfect recollection of things that you've said it in the past, let's say you have infinite contacts going forward, you just kind of like point it to the transcripts that it had before and it just knows what what to look for. You don't really need any kind of special scaffolding for memory or use a preferences. It just kind of knows but these are these kind of sound like pipe dreams but not really. I think like there is like I can see a world where it kind of gets to that.
 But yeah, I think those would be two features that might be delete, my delete. Well, it's kind of
 Like certain things are almost Moore's Law ish in how much they're developing and how fast they're developing. And one of them is the context, windows are getting bigger. There's debate there around, like, how effective it is to keep everything in context, right? And how useful these large contacts windows are, but we do see like the push for bigger context windows. And then, another one is like the price per LM College dropping and that continues to drop in like a Moore's Law type of way where you're like, it's a better model and it's cheaper than before.
 and so,
 Yeah. I potentially could see it. Maybe it's not like in the next month, but if we're talking 10 year Horizon, there's a world where that makes a lot of sense.
 Yeah.
 Yeah, I agree. Yeah, I think like the timeline is always really tricky with these things. You don't really see it coming until you see it in me like you know, it's like you're, you're oblivious, you're oblivious, you're oblivious and boom. It just smacks you in the face and like, oh shit, I can do this now, or at least. That's been my experience with it at least. So yeah. Timing is kind of a bit of a, you know, Oddball. But I do think that there is a world where something like that exists. Yeah.
 Speaking of timing and how things have evolved. I know that we had your colleague, Eric on the mlms agent Builder, Summit panel that we did in San Francisco in May.
 It's now we're in September and one thing that Eric was talking about back in May was how hard verification is and how that's something that keeps him up at night?
 You had mentioned like there's been some advances but it's still a very hard problem. Can you go into that a little
 Yeah. Yeah, for sure. So, so for context, like, verification is the ability of the model to verify that the work that it's doing is correct, or like some form of like course, correction mechanism, where like, if it's going down a bad path, it like, recognizes that and can course, correct, I think as I do, I would kind of break this down into two different sub problems, really? The first is a Model Behavior, like does the model know that to check its work regularly and the illicit that behavior?
 And the second is do you have the tools or have you given the models the tools to effectively check its own work?
 And I think both of those things are kind of advancing at their own pace. I think the first one where, like the models are now, they know about verification, and they know that like, it is, it is a path to success. It is a good path to success and it's more on distribution for them to them to be doing this. And I think that's chugging along. And, you know, I think like, we, my hunch is that we will see that kind of keep getting better pretty rapidly over the next few months and years. But
 The second piece of it is is the tools that you're providing to the model. So in in the coding context really we have you know there's there's a really wide variety of tasks that you can be coding up and I think we have figured out verification for a small subset of these. Like for example, if you're, you know, coding up a website and you're mostly dealing with like JavaScript components and CSS and HTML and just like the visual hierarchy of elements, that is a little bit easier to do verify. Now, you have some mCP servers, like there's a puppeteer mCP server that can open up a web browser for you. Take a screenshot, send it back to the model and the model can iterate based on that screenshot. So if it's like changing the color of a button or if it's changing the position of a button it like has instant feedback of like what it's doing. But then like more complex things here too. Like let's say it's like
 Animation, really, let's say you're like cooling up an animation and it's like, or some sort of user interaction in that requires some sort of animated frames, those are still harder to kind of verify like you. It's hard to kind of provide the model with the video stream of what's happening. At least in how today's models are architected, it's still possible. You could like, slow down the animation frame rate and take like screenshots at certain times, but, you know, it's it's fuzzy and it's unclear how effective those things are.
 And then you've got things like, you know, like you could be doing some sort of like performance work, like you're working on some sort of like inference thing and it's like super low level performance work again. Like, what is verification? Even look like here? Like you know, how do you measure that, how does the model to measure that? So the easiest thing to do and this is a bit of a cop-out I realize, but it's like unit dusts, right? Like I, I think that unit tests like smaller units of dust that humans, pay extreme attention to and make the framework for making unit tests and maybe even end-to-end tests, much easier that will be
 Probably the shortest path to verification success. And so if you're, you know, if I'm creating a new product tomorrow, the one thing that I will for sure do is make sure that I have a unit testing framework that is able to test as large of a surface area as possible of my code. Because if I do that, then I can leverage AI tools to write more of my code and Trust the output of those tools. So I think I mean just ruin has been around for ages, right? Like it's not a New Concept and people but I think it is a concept that is being rediscovered to some degree. Like I think everyone talks about Testament but if I look back at my career like how many times have I read it in the unit tests before I write the actual code? And I like not that many, I'm gonna be honest, right? Like, it's like, but but like now with with the models capable of writing the code, like the unit desk code too.
 A little bit lower friction, they're kind of right goal that way. So that's that's gonna be the other piece of verification which is unsolved and a I think it's it's going to be tricky to get to a point where we can like completely solve that
 this unit testing, sounds like
 It's going to take forever. Like, you gotta run the test too, though.
 Yeah. Yeah you do have to run the tests but the model just figures out which tests it needs to run and just like, right? Yeah, that's an optimizes that for you. So yeah, there there's there's degrees of being AGI, pilled and, you know, like depending on kind of where you fall on that Spectrum, you might see it differently.
 Yeah, the models. Just gonna learn from the worst of us and be like fuck it. I'm testing and prod
 Like a true bro. Yeah, exactly. Yeah. I know.
 I've seen enough of these models do that kind of stuff like on GitHub issues or something where it'll comment. It's like this was a human behind. It, wasn't it? Yeah, this cannot be really. Yeah. Have you seen those? Like I think that was a trend on I think levels I owe on on Twitter like kind of tweeted about this and then people started doing it was like I think he called it like Vibe devops or like Vibe infra or something like that where he didn't have any like deployments strategies or like deployment code. It was that was no infrastructure as code. He would literally just like SSH into his production Box, open up Claude and just like tell her to deploy stuff and like do like you know do database maintenance and so just like you know upgrade upgrade this schema or something like that and then oh I missed this. People just kept doing that over all that project so that was like yes this is maybe this is the future, I don't know. Yeah.
 Oh, man, that makes me so nervous but I am glad that somebody's trying it and pushing the limits.
 Yeah. For sure. Speaking of pushing the limits I want to hear about
 The power users and how they're using Cloud code? Like how have you seen people just surprise you with what they're doing? Yeah.
 there's,
 There's a lot of power users who have surprised me.
 I think the number one thing that surprised me was like this one person who was using a fleet of like 10 to 12 clause for like one problem.
 And he was using the file system as a mechanism for all of these different instances to talk to each other. And he, like, gave all of these different instances a Persona. So, he had like a, you know, like a back-end engineer from engineer like that. Yeah, exactly. Like the end, they all operated on like different folders in his code base and I was extremely impressed by that setup so much, so that I think the sub-agents kind of feature in Cloud code today is, like, inspired heavily by that approach, that makes it was. Yeah, it was, it was extremely cool to kind of see that. And that's, that's, I think people have I've seen people with, like, 100 MCs in store or something like that. And I was like, what do you even do with 100 MCB servers but hey, it works for them, you know, like
 Happy with it. And, you know, it works for them. So, yeah, there's always like these, like, surprising things where all the composable parts of cloud code, like they're being used in such creative ways in ways that we didn't quite expect them. Kind of to be to be used plot, twist The 100.
 Yes, love it. Love it.
 Yeah, I actually want to create this like little web app that literally just like controls just bought it Spotify to, and that's all it does. They just like to do it? And it has like, lots sitting on top and just like, all it does is like connect to your Spotify. Does what the play I would love to be able to
 Just sing with that, on finding new music. Yeah, you know I want and just give it all a brain dump on. I want to play list with this kind of music and trying to explain everything that I'm feeling in that moment and then it goes and creates it. Love it. Oh what if he, what if he gave it a webcam and a mic?
 So what you could do is that you could like set that up at a party.
 And the corner. And it like looks at the vibe of the party and plays music according to it. It's the Jukebox is the 2025 jukebox. Exactly. Exactly. And then people can go and Whisper requests into the microphone. Oh, hell yeah. I think, I think we just created the next booty dollar app, dude. Yes, I'm Gonna Save this episode and not release it until I get 20 25 box calm or dot, AI website. Yeah. And so I've heard sub agents called agents as tools. I'm also
 Just been seeing how incredible it is to have that like, sub-agent kind of design pattern for lack of better word.
 How do you see or foresee sub-agents evolving?
 Yeah, I think salvation's are
 The possibilities are just too many. There's this, this, there's a lot of different ways that this can shape up. I think, when we first like launched sub-agents, there was like no good way for kind of, like, everyday, users of an agent decoding product to create their own, custom sub-agents. And the idea really was, let's do the thing. The simple thing that works, right? It's like we want to do the absolute simplest thing.
 that we know will work and like people can play around with and experiment with
 But there's so many other things you can do, like right now, the way at least it's implemented in Cloud code is, is you. It's salvation as a tool, it's an agent as a tool, right? So it's like Mama claw or like, you know, the main thread like will call into these tools and then wait for those tools to turn back to them at some point and then continue with the conversation. But then what if you just had like, you know, a master master model where you had like multiple sub agents kind of all doing their own thing that is no like parents, they're all communicating with each other.
 The the way that they communicate with each other becomes an interesting kind of decision as well as like magic. Is it message buses? Is it like point-to-point communication with and when you when they are communicating with each other? Like when do you actually inject those messages in like do you inject did you preemptively inject them or do you wait for them to finish, kind of how important is that, you know, where these sub-agents really running? Like, are they going to is the code that they're writing going to conflict with each other? Or is it going to be read? Only or like, do you designate some of them as read-only and or does me some of them is like read right? Like there's a lot it opens up a whole can of worms but it's a really exciting. I think there's a lot of research that's going to be done about this, a lot of kind of Open Source repos all, so that are going to explore this using Cloud code as the base.
 So I'm extremely excited about kind of this direction and kind of what we find to be honest, it is unclear to me right now, whether some of these like more complexed, a more complex agent or some Asian topologies lead to better results.
 and I think, unless we have
 Some form of evidence of, like these kind of Asian topology like works really well. I'm hesitant in kind of adding that complexity to the product because it not, it's not just like the complexity of adding it like the code that you're gonna add, but it's also the complexity for users to understand how it works. Yeah. And you know, I feel like a lot of, a lot of coding agent, coding tools are gonna geared more towards power users, to begin with, and what's more exciting to me right now? I mean, power users are great and I think I'm a power user I build for myself all the time. But what's more exciting is like this whole other spectrum of users who are just like just about, you know, just getting their feet wet with this. Like they they're Skeptics or they don't quite believe in the eye and they like, you know, oh like I can write this better, it's wasting my time, like there's like all of that stuff, but they're not wrong. I mean,
 I think they're right if when you for certain things but I love to kind of have sub agents and the future of some agents kind of catered more towards them and helping them get a better outcome from from the product.
 oh, there's so much that you said there, and one thing that
 Stands out to me.
 In.
 all of that when you have agents,
 going about and you add that extra complexity of just like,
 A swarm of Agents, right? And our Hive of agents that are flying around and doing their own thing and then communicating with each other and figuring out how and when, and where you want them to communicate, or you want to add extra context is complex in itself.
 I instantly think about there's certain things in the context when does and maybe it's a little less. So for coating agents, but if we were to extrapolate this out and say for agents across the Web, the whole thing that I think about as you're talking about these complex agent, intertwining and passing around, a lot of contexts from One agent to the other and not really having a superior agent. Put even just if you did have a superior agent that is overlooking it all of it, you know, like the I've sorrow and agent, you
 Still are going to have a really hard time.
 Being able to identify what is sensitive in all of this information that's being passed around. Like there's no protocol right now.
 For this is sensitive and it's not I'm not even saying like, pii I'm saying like stuff that I wouldn't potentially want going around the internet, you know, and it's not like my social security number, it might just be like my YouTube preferences.
 Yeah.
 No, I get it. I think that is I think you kind of nailed that one. It's like
 I think that's two problems and observable. Bloody is it is almost is really hard for for complex salvation topologies and because of that, as a result of that, like how you do permission management and how you do like that gonna become this complex too. So like, for example, if in include, if you let's say, you spend up like, parallels of Agents like that, you spin up like three parallels of agents that like, going off and doing their own things for you.
 Anytime.
 Any of them encounter some form of like tool that it doesn't have permission to run like bumps up and like tells you asks you like hey can I can I use this tool and then you like go and say Yes or whatever and then they goes off and does his thing.
 This is not scalable.
 Right? Like it's not it works because, you know, the sub-agent implementation. We have is quite simple and so it works. But if you have more like complex station topologies, it doesn't scale.
 What is the answer? I don't know. I'm not sure. It's like it's I think it's something that we're
 we're going to have to come up with a better way of dealing with this. And then permissions is one thing I think. Like once you get permissions to do something, what do you do with that? And who do you pass it on to? And like, how do you know that that person or that agent will not will do the right thing with it? So, yeah, I think like, alright, give permission forever. It's permission right now and then maybe for five minutes or maybe for an hour, but I'm gonna revoke that permission because I don't want you to be able to always do that. And so, that's a little bit weird, too. I
 I find permissions fascinating too especially again like extrapolating it out for just regular agents that sometimes I do want to tell the agent to go buy something and I want to give it permission to buy it, but then sometimes I don't and I definitely don't want it to buy the same thing like five times. So if I give it permission, once it potentially has that permission to just keep buying
 yeah, I mean
 Oh, I found it cheaper. Deal on this. Ferrari wanted to buy 500,000 dollars. Boom. Yeah, that would be bad.
 Yeah. Specially if it's the fourth one, it just bought. Yeah. One for each day of the week. I thought that's what it was trying to help you out. Exactly. Oh, exactly, man. Yeah, you can get into a lot of trouble there. I'll use like Cloud code, amp lovable, and what I noticed going back to that permissions. Part is whenever it comes up and it will ask me. Hey, can I do this?
 I joke, like,
 I just will constantly hit yes, so that I don't have to review it and be like, I guess I'll know later, when it breaks and it's kind of like the new looks good to me. Yeah, I'm good. Merge pull request. Yeah, that's really how I feel whenever I press. Yes, without looking at anything, I'm just like
 Send it. We'll see what happens. Yeah, we've like joked about just having this like little red button that we like so whatever you want. I'll just like even just give out to a customer's that just says that you are absolutely. Right. And you just like press that I just say Auto access permissions for you every single day. Everything she's like, take it all. I don't want to be bothered again. Yeah, it's like super yellow mode. Yeah, that's Peter levels style. That is but also you were talking about some fascinating with at scale.
 It I'm not going to be able to save any time if I have 12 sub agents that are constantly asking me for permission. It's a full-time job like trying to hit. Yes even if I'm not even looking at what it's doing.
 God forbid, I have to like look through the code. It generates, right? But if I am not even looking, I'm still gonna have to just constantly be pounding. The yes button. Yeah.
 I I mean I think my take on this at least right now is that as the model to get smarter, we'll be able to rely more on them to do kind of these like you know the eye of Sorrow on Lake Asian that you have like is cool is going going to get really, really good at understanding user intent and and like, providing Dynamic permissions. That's the only way that I see the scaling, to be honest. I don't see how like you can create a really complex web of like Dynamic setting and dynamic config and auth and just like, you know, but it's gonna have a Breaking Point and and
 The more I'm kind of working with LMS, I'm realizing that if you're, if you're scaffolding is just like really, really complex.
 You will not survive, you know, and then so maybe it solves the need right now. And maybe like, it is useful for a few months, but looking to the future, I think it is going to be offloaded to some sort of like model. That's, that's highly tuned to something like this.
 How often are you going to the researchers? And just saying like watch me work real fast and I'll tell you what's painful and then maybe you guys can figure out how to fix that on the model side.
 yeah, I mean, I think we like our team and we were like quite in touch with research in my ways, as I think,
 that's like one of the advantages of working at a, at a lab is that you kind of have that and the what you can come up with then is is just like
 Blessed and backed by research and and also it's like a flywheel. So it's not just like one way information coming in but it's also like what you learn from user behavior and what you learn from product usage, kind of like feeds back in the research and like what the research priorities are going forward.
 so it that's like a flywheel that you know, we're definitely tapping into and we
 Yeah, we make it a point to kind of tap into that. As much as I imagine, you also have the Boon of being able to see what's coming down the pipe. And then,
 See, like okay, is this new model?
 Whatever characteristic.
 It can we leverage it in some way shape or form with Cloud code?
 Yeah I think that yeah that's that's definitely a big Advantage. We kind of like have access to you know some of the preview models and things like that and that that helps set products strategy kind of a little bit earlier that we would if he didn't have that.
 Do you? And this might be above your pay grade. So and we'll have PR listen to all this so they may tell us the cut this. Yeah, question completely but
 Do you foresee a world or is it already happening where?
 there's,
 just like so many resources that are going towards clogged code and just coating models in general that that is now like
 A gigantic model machine in a way.
 I mean I think the topic has lean into coding for for a few model releases. Now that's not to say that there's not other stuff happening, but there's definitely is, you know, a kind of a focus on coding just because our models are really recording and I would argue the best. I think it's kind of unanimously known people try but they're like, it's not as College. Code is like what you Benchmark, everything else against
 Right. Yeah, I think we've been kind of fortunate and of course, like props to everyone who kind of these amazing models. But yeah, I think that there's definitely a focus on it. I can't say so much about like what if there's a trade off? So like I know what things like that, I only don't even know but I I know that that is an area of focus and you know,
 There is a significant number of people who kind of looking into it.