The couple are observability of the physical and The Logical with our context about how this stuff is supposed to be working, marry all that stuff up. What you figure out is the Delta between our, like our observations and what's really happening and what our intent says or what the design says. And then that Delta is the problem. We have to go fix.
 Probably a really good place to kick it off. Like how is this new world shaken down and what does it look like now?
 Yeah. Well I mean and first now the now that we're up and running you know just to contextualize and then for the audience a little bit, I'm Chris, I'm confetti CEO, I'm an engineer and I work on him for sure. That's me. So like you know what we're talking about today, I think mostly is.
 all of this infrastructure investment that is happening in support of
 Hey I and machine learning and these as we as we have talked about these things that are taking over the world right now. And you know, the, the infrastructure investment here, I mean it is it is enormous, right? It is some some meaningful percentage of GDP growth in America this year, right? Like is AI infrastructure and so what is going on there? I think is, you know, our big theme today and then just
 to contextualize like,
 You know, myself and netbox and how we fit into this and what we see.
 Netbox is the system record for infrastructure. That's what it is, right? So if you still that way, down at its core at a box, is a model that the teams that are building this kind of, for sure are using to keep track of everything in their infrastructure, everything from space, and power and cooling. He's sort of like foundational fundamentals that we hear about all the time. All the way up to like
 I mean, certainly racks and GPU servers, and switching and cabling, and then into logical stuff, like IP addresses, and switch configs, and server configs, and all of the automation that happens around this. So, like really from from his early as
 I've decided I want to design a new big AI data center to this thing is running and scaling and serving, you know, inference or training workloads or whatever it is at Mega scale. We have this incredible lens into to that journey and then
 the other simple point of context, I'll share is, I don't think there's any idea Center in the world that is built without netbox and so we get this incredible cross-cutting view into all the variations and all the things that people are trying and what what is happening in. Like the word we were using a few minutes ago was chaos, right? Like the chaos in this space right now and it is insanely chaotic just because of the pace and the amount of demand that there is and the level of investment that is happening. And how many teams and companies are being formed, all at the same time to tackle this and the geopolitics of it, even like there's so many factors, right? So, that's a little bit of the context. I think of what we're going to talk about. And the headline here, is like, everybody's investing here right now. There is, there's no secret answer to how to build infrastructure. It's a lot of hard work and a lot of logistics.
 And a lot of like supply chain type problems and where am I going to get the power and how about a get the power in 45 days when I've made a commitment to get, you know, 300 megawatts online and and where am I going to get the servers in the gpus and the cabling and the racks and the humans to do all this stuff or the robots increasingly right? Like all of that is what is happening? So fascinating time in this space
 And so, it feels like every single one of these steps.
 Is a potential bottleneck.
 Are there some that?
 You see, being more of a bottleneck than others. I know that back in the day it was like, GPU constrained, has that been alleviated? And now it's more on the actual wiring or the power.
 yeah, it's it's such a great question and
 Building. These kinds of infrastructures at the speed and scale that the world demands right now.
 Is a constraint satisfaction problem. In any given time, there is a constraint and it is the primary bottleneck. And there have been several of them over the last couple of years and there will continue to be several of these. As long as demand is what it is, which is, you know, almost like infinitely more demand for AI infrastructure than there is Supply, right? And so that's that's the root cause I think of like, you know, the furiosity with which investment is happening in the space and the pace at which teams are trying to trying to build in this space. So let's just break down some of the different kinds of constraints that we will hear about, right? We all hear about power as a constraint for an example, where am I going to get?
 Three gigawatts of power. I did a call last and not last week, the week before last with
 a public company.
 The, you know, building a data center infrastructure.
 That I didn't really heard much about in the past. They grew up in kind of Bitcoin land and on a call at the CTO. And he said, you know, we have three gigawatts of power capacity and my jaw dropped, right? Like, because that, that's problem. Number one, that you usually hear like, where, where you gonna get all of this and the kinds of anecdotes were hearing just give
 Everyone a sense of the, the chaos and the scrappiness, with which this power problem is being approached. We have we have a
 Saying we use in our team, netbox labs for how we need to operate to serve this kind of customer. And that's saying is turbines in the parking lot and that's a real anecdote, you know, a few months ago we're talking with one of these, you know, real hyperscale data center Builders who's got tens of billions of dollars in commitment, from one of the research labs to bring in, for sure, online incredibly fast. And what they told us was
 Hey Chris. Hey netbox, Labs team.
 This infrastructure is coming on online real fast. We're buying turbines, we're putting them in the parking lot. That's how we're getting our power fast enough because we can't the grids can't operate this quickly, right? I'm in can't scale this quickly or we can't build nuclear reactors this quickly, right? And so it power is a big constraint that everybody's investing in obviously, wait. And so how did this other company have the three gigs of spare capacity? Yeah. Um, luck in history and, you know, one of the one of the sort of interesting trends that we've seen
 Now is companies that invested maybe seven, eight, nine years ago in.
 Tapping, you know, cheap power or building infrastructure and environments suitable for you know, large-scale data center infrastructure with good cooling characteristics or access to hydro both for power for cooling like those kinds of things for Bitcoin. These are companies that are really well. Positioned actually in sort of this AI infrastructure world and we've all seen that with core. We've sort of the flagship, you know, builder of infrastructure in this space. I think a lot of their historical contemporaries in the Bitcoin mining space have recognized like, hey, it's way more lucrative to shift over to this AI stuff and use the fact that they've already invested in solving these big constraints to power and the cooling and the space. And even just like,
 Logistics. I think that's the next big. Constraint the we see that, maybe a lot of
 A lot of the time is not as talked about as it should be which is think about everything that has to line up to bring a big. I don't know. 300 megawatt. AI data center full of Nvidia, super pods online. There's a lot of moving parts and they all have to converge and they start as early as like.
 I've purchased a parcel of land and I have some power commitment. Great. What I'm going to do with that, I need to design a physical space.
 I mean, to interlock that with my ability to procure, your racks and GPU servers and switching, and fiber optic cabling and
 Turbines and power infrastructure and liquid cooling infrastructure and all of this stuff has to converge in a design.
 Has to drive a purchasing workflow. All of those components have to arrive before you can bring anything on line. And so like that problem of even just what am I going to order to make sure that it's all going to work together at massive scale, right? And I'm going to make sure that it all arrives in a in a way that
 You know, I can, I can interlock that with my design and make sure I've got everything I need to bring this this infrastructure up and running. And then, how am I gonna even deal with the fact that I've got, you know, thousands of pallets of stuff, arriving at a loading dock, and it needs to get rocked and stacked and plugged in and cabled and burned in and tested and configured and deployed and observed and
 And then ultimately delivered, you know, to an end customer for training or, you know, sliced and diced Cloud style for for retail like inference type use cases. So incredible Logistics problems and let's just make it a little worse. Everyone of those components is sold by a different vendor and, you know, one of the really interesting challenges that we see is that everyone of these vendors operates differently, they skew differently, they expose their catalogs differently. They expose lifecycle data about their catalogs differently. Like if I want to buy a GPU server from Dell over here and I need to get some Fiber Optic cabling from Corning over there, and I need to switch from a store over here. I've got three different procurement problems to solve three different kinds of data. I need to figure out how to work with, and then let's compile it one more time and then I'll stop the other big problem is that there's so much demand in this space in the challenges are so hard.
 The componentry vendors.
 Are iterating on their own offerings, incredibly fast identity space. And so, the the ground is Shifting under the feet of the folks who are seeking to build these data centers, the kinds of switches they can buy or the kinds of service. Every few months, Nvidia has a new architecture, right? And and then that nullifies like all the other stuff that attached to it you have to rethink all of this. So it's a really hard problem space at the moment and I imagine when
 When I want to learn something, I usually will go to YouTube and search how to do X or I'll read some articles and some blog posts about how to do that and kind of immerse myself in it. That way I get the feeling you don't have these
 Engineers going around making YouTube videos on how to put together the gpus and the date data centers. Yeah, this is not a space like
 I don't call it call It software development. For example, where there's a vast area of humans and some people are inclined to Tinker and share and that kind of thing. In fact, you know, I would say there are
 Few hundred people in the world roughly who know how to build this kind of infrastructure. This sort of speed and scale and they all know each other. Of course like mostly they live in like a five block radius in Soma in California or something like that. They probably all have drinks with each other every Thursday or whatever but they're too busy to, you know, be sitting down and recording YouTube videos. And so on, these are the kinds of folks, who I mean, honestly on Christmas day, they're operating, you know, for sure and they're procuring stuff. That's the pace at which this
 This space is moving right now and again like the furiosity with which these folks are operating. And so they're figuring this out on the Flies, they're sharing with each other within their Community. Just don't think there's been enough like enough duration for the learning to propagate. And, you know, because of the rate of change in this industry, the learning is our
 Going stale really fast too. So this is not an easy space to dive into.
 So, how then?
 When something is updated.
 And you have better throughput with one provider.
 Does that?
 not necessarily the knowledge, get propagated but just like how do you update and
 Keep tabs on.
 It when you're building out your data center and you recognize, whoa, there's actually a better way of doing it. So all of the inventory that I was gonna order now, let's upgrade to this but that means that these five things Downstream are going to be affected too. Or how do you know, like the second and third order repercussions I guess of such a great question and let's, let's break this problem up a little bit because I think there are a few different answers first, the teams that have started.
 To figure out the answers to this question. Are the teams have been at this a while? And by a while I mean more than a year, right? Like the team's building, you know, real generator AI for structure at you know 100 plus megawatt scale. You can count them mostly on a couple couple hands and
 these are teams that are practiced a life cycle management of their for construction. And I think with this roughly looks like is
 Because of the rate of change and the rate of turnover in these environments it's not like let's rip and replace all that stuff that we built 18 months ago. It's well we're building, 40 more data centers this year. And so the new data centers are going to get the new architecture and that new architecture is changing is turning over every, you know, four to six months, roughly with a lot of alignment and similarity, right? Like there's a lot of convergence on some of the basics.
 So I think that's roughly what it looks like. And then, you know, the other the other setting here is and this is the honest reality.
 Probably about 100, Neo clouds. If popped up in the last 12, 18, 24 months, right? And these books have not tackled this problem. Yet, they're still building Greenfield, you know, they're they're first or second generation of data center infrastructure is and, you know, we in, in a totally different world in Enterprise, where has lived for decades, you know, we think and talk all the time about lifecycle management and of life and of support one. Is it time for us to take out that old switch and replace it with the Next Generation? How do we think about Network, refresh teams in AI for structure, haven't
 This is an absolute. But as a rule of thumb, haven't gotten to lifecycle management yet. And so like this is a problem that is coming. Not a problem that these teams generally have a great set of answers for today.
 Well, if you have
 A new data center that has all the newest and best components.
 But you also have the second third generation.
 data centers is the demand that you've been seeing for those second and third generation data centers and what they can provide for GPU usage
 Is that just skipping to the newest one? Or is it still like there's just as much for as far down and as
 many generations back as it can go. So one thing I won't pretend to be is an actual operator AI Data Center and so you know only they know their real like business models and you know kind of what the demand looks like a cross. There are different kinds of footprints but my perception is that
 The demand here is deep. Yeah, and you know you get with a current generation, I don't know.
 You know, Nvidia super pod, you know, with call it, you know, it GB, 300 architecture, or something like that is efficiency relative to Prior Generations in a bunch of Dimensions power, efficiency, cooling efficiency, and so on, right? So really that's what we're trading off. Like there's a ton of demand that is still being served by older architectures because they're available and they're online and they work. But as we transition toward newer generation architectures, you know, we're serving more demand per watt, for example, or more demand per. Well, I think what is really the right, the right measure. I do know that some friends of mine did some calculations on their usage and it was cheaper for them to use the newer.
 Versions, even though it's more expensive per hour, they could get more compute and get things done faster.
 And so they didn't have to use as many hours.
 Yeah, I think that's that's roughly a simple and good way to think about it. Now, put yourself though in the shoes of
 you know, a large nio Cloud operator where you've made you know, billions of dollars of investment in
 you know last year's generation of infrastructure. And I think this is a general, a general question in the market today that we don't have great answers to how long is the useful life of that infrastructure? We haven't reached it yet. This whole this whole push really roughly is only been going on for, you know, 24 months or or thereabouts, right. And so, I think there's a lot of learning we're going to have Downstream over the next two, three, four years about what happens to the two, three, four year, or four, four generation old for structure and is do the economics work to rip and replace it. Do we just keep it on line, serving less, you know, let's critical workloads or workloads that are more mental to the lack of efficiency there. What do we do? We don't know yet. I don't think. Yeah. And so now, can you take me through?
 This stack again, from the the tangible stuff, you can touch.
 All the way to the more software type intangibles. And how
 You can keep track of all of it and then know what needs to be done. Where or, how much of this we have is that enough of what we've got and just be able to
 Keep the trains running on time. Yeah.
 So much about this.
 spanning you put it really well, like the tangible all the way up to the
 Sort of the, the actual outcomes, which are token generation more, you know, roughly so much of that.
 Is about.
 The data through thread of what are all of the things that make up our ability to produce this outcome? And how do they interact with each other and how do they interlock? And so if we if we rewind just a little bit, we talked about
 the earliest phases.
 of these AI for structure, builds being
 we've got, you know, we've, we've procured some acreage roughly, and we've got a power commitment, from somebody, from that moment forth the teams that are doing this best,
 Are managing from intent. They're designing and they're carrying the data of their design all the way through to token generation. And what I mean by that is, okay, we've got, you know, 200 Acres of space and we've got 300 megawatts of capacity.
 What's the shape of the building? We're going to build? How many racks can fit in it? What are the thermal calculations say about that? What kind of power and cooling density? Can we achieve what sort of
 The inference or training infrastructure can align with those parameters. What Nvidia gear, we can buy or what switching footprint, are we going to buy all of that stuff? All needs to end up in?
 A data model and this is what netbox is.
 The captures.
 The.
 The inventory, like, what are all the components, the interrelationships between that inventory, like, on this interface, and this switch, we're plugging in this cable with this length. And it's gonna, you know, route in this cable run to this server in this Rack in this, you know, geometry in the data center and all of that has to flow all the way back to like, power and Cooling. And so on, all the, that has to flow from design intent. This design is going to meet our
 Our parameters for thermal thermals and cooling characteristics and power consumption and token generation. What
 Happens, if you don't do that.
 Is at some point you you have so much logistical complexity that you can't keep track of all this stuff and we see this one team start with spreadsheets, right? Like the canonical way to do this would be like, okay, let's do some power calculations and all right, we need 18,372 cables and they all have these different lengths at some point. You know, that's spreadsheet gets messed up and you order the wrong thing and, you know, a fun, anecdote from a couple months ago from me now.
 Spending time, with one of the largest producers of fiber optic cabling in the world, their number one business problem. Returns everybody orders their own cable lengths, right? And why does that happen? Bad management of design data and correct cable calculations that are maybe not taking into account, things like cable, Bend radius or, you know, obstructions in the, the physical facility. So data really has to be the through thread from, you know as early as like I've got some space and some power all the way through to this is running and then you know one other dimension this that I think is important to start to pull apart
 Is.
 You know, we're talking about AI for structure is sort of this monolithic concept, but there are different goals for different kinds of infrastructure. And, you know, we see
 A range from I'm building a gigantic. You know, 500 megawatt facility to do at scale training for a research lab single tenant for structure.
 I, you know, all the way to things like what I call retail nio Cloud infrastructure, we're going to let people come and swipe a credit card and rent, some GPU capacity for a few hours and then, you know, return it to the pool. So a lot of ephemerality and then over to what I usually think of as AI Factory infrastructure maybe like pre-canned builds even things in you know, shipping containers size. Prefab pods that might get shipped off to some Enterprise Bank or whatever, who wants to buy some Ai and doesn't have the capacity themselves. And so we also have to consider like, what's the, what's the end use case? Who's going to consume this? How are they going to consume at that has to feed into the design as well?
 just trying to Croc, this idea of
 thousands of different cables and laying them out across, a gigantic Data Center. And I know that when I chatted with Andy from vast, he was saying that a lot of times folks will break up the data centers, into four different grids or eight different grids. So that if, for some reason, you lose some power,
 It hopefully you don't lose power in the whole thing and you're able to kind of Salvage whatever you lose. Well you just touched on there is yet another kind of like outcome constraint a
 Resiliency or redundancy, constraint on Power and we see the same thing when connectivity and we see the same thing on Cooling and so on, right? So, you know, really,
 What we've just described is a gigantic math problem where there are all these constraints on one end and all these inputs on the other end. And right now, a mix of expert humans and software, like netbox or other CAD tools. And so on are going together and out. The other end is popping, you know, kind of a design that you know, to best, guess meets those constraints.
 And you said something about, like, the bend.
 Constraint that some cables have I imagine that's just because you can't put a 90 degree angle in it like a hose, the water doesn't come out. Yeah, exactly. Exactly. Like that. Like, light is traveling through these fiber cables. And so, you've been to 90 degrees like the light doesn't doesn't make that then. And so there's a Bend radius, you have to take into account. So, like all kinds of fun math in, in these data centers,
 It and does I think I heard something about Nvidia, giving a lot of suggestions on how to set up the data centers or they have standards? Well, this is such a great topic for us to Broach a little bit because one of one of the I think,
 One of the.
 drivers of
 Speed in these you know kind of hyper complex. Many dimensional like constraint satisfaction Logistics problems is going to be data standardization. And here what you're referring to are, you know, blueprints or reference architectures. That Nvidia provides for here is our blueprint for a
 You know, an h100 superpod or something like that. And you know, you you need power in this configuration and you cabling that looks like this and you need this kind of switching footprint. You need to plug things in this way and these sort of cooling characteristics and, you know, think of it as like an instruction set for how to build a working pod in their blueprint with, you know, kind of all of the physical and logical elements pre-conscious for you. So that you if you are not a
 You know, an expert at designing these things from scratch can say, Okay, I want to implement that blueprint. Here's everything I need to buy. It's almost like the Lego brick instructions, right for how do I get, how do I get a working in a pod in nvidia's definition. And now extend this, we see this from fiber optic, cabling providers, they have they have blueprints or reference architectures. We see it from data center fabric Network fabric vendors like you know, high density, infiniband fabric Blueprints and so on These Blueprints the way they manifest today mostly is PDFs. Right? So if you, you know, if you're, if you're going to build a big huge, you know, 300 megawatt data center, what are you doing first?
 You're reading a lot of PDFs that are very good and then you need to interlock them with each other. You need to take this fabric design
 And this compute design and this cabling design, Etc. Right? And figure out how do I marry these things up. And we're not here yet in our ecosystem or generally today, but what we are working on here is how do we start to create some
 Programmatic representations of not just these reference designs but also the componentry that goes into them. This is this is one of the things that netbox has really brought to the space, is the notion of a de facto industry standard, way of modeling, all of this information. The
 Vendors and data center, operators and tooling companies building software used by these teams. And really everybody can sort of count on, in a line to here, is how we're going to share data about cable lengths, and cable bends, and cable, geometry, and cable types. Here's how we're going to share information about switches, and servers and routers, and firewalls and storage devices. And so on physical dimensions, logical Dimensions, configuration details interfaces. And if we can come up with a programmatic language, for that information to be shared, then we can start to automate much faster. Then these teams can start to automate the design process by consuming vendor data in canonical form. So this is one of the areas that we're working on and this is all about all the way back to what we talked about earlier.
 The, the bottle the logistics bottleneck like, how do we solve for that Logistics? The procurement bottleneck of? I've got stuff that I got to get from 100 different vendors and it's all good or arrived. And it all has to work together. And right now it's a very human problem and humans are the bottleneck and that scenario. And so if we can program it ties and automate, that Logistics process around standardized data as an industry, we're going to move a lot faster.
 Well, it does feel like
 that's a perfect use case for trying to automate it and knowing that there's you have all these constraints.
 And you have your inventory. How can we make sure that what we have matches our constraints?
 I also was thinking, as you were talking about that, like I am imagine. There's people as you were saying those two, 200 people in the world that
 understand how to do this and have been doing it for a while that are
 Trying to figure out the best way to do it and they've got some tried and true tested tricks or they're pushing the boundaries. I remember reading a blog post back in the day from The Meta engineering team about how they had two different clusters of 24,000 gpus and one was using the traditional infiniband, but then another one they were doing something different to try and get a little bit more speed out of it. And ultimately it was kind of the same, I think, but
 There's going to be that R&D. That's happening too. And so in a way, what I was reminded of was like it kind of feels like you could do some flight simulator program or something. Akin to that where you get to go in and try and say what if we did this and weeked these things and maybe you would get a simulation and then before, going and buying all that inventory, or before spending all those hours, you can at least, like sanity, check it.
 So there's a term that you'll often hear in infrastructure management or in all other kinds of Industries and the term is digital twin and that's roughly what you're describing, right? Like we want to create a digital twin of the eventual, Mega scale infrastructure that we're going to build so we can pressure test it. We already talked about a few of the, you know, the really simple ways that people are doing that kind of thing today. You don't really want to go build a 300 megawatt data center if you haven't.
 Through your digital twinning and design process, proven to yourself that your design, you know, meets powered on it. So you can trains for example, right? Like that would be, you wouldn't be able to meet your slaughs to your end customers without considering those characteristics in your design where we where we start to run into, constraints is
 The.
 The depth, the FFC, the Fidelity, I guess, with, which we can digitally twin these environments part because there are not standard ways of sharing data about the characteristics of the components and how they're going to work in practice and and so on, right? So this is, this is a key part of the design process that we want ultimately to make higher Fidelity by having
 More current more aligned and more granular data about everything that goes into these environments so that we can pressure test, you know, and many different ways and be confident that when we do go by, you know, a billion dollars worth of stuff to deploy the data center. We're going to meet those design constraints that we've laid out for ourselves and that Fidelity isn't there? Because it's still so new.
 That fidelity.
 Can be there with a lot of hard manual labor today. And again it goes back to reading PDFs, like design specs for individual servers or switches or cables or whatever. That's where that information resides today were, it doesn't reside generally. Without a lot of hard work by these teams is in a common data model like net box where you can say, you know, look, I'm going to design this data center. It's going to have this layout. It's going to have these physical characteristics. It's going to have this cabling architecture. It's going to have this network configuration. It's going to have these this switching model. It's going to have these server models. It's going to have Etc. The data about all of those components that feeds the
 Call it like the evaluation of that design in a programmatic sense. It's really hard to get out today. It's sitting in PDFs, right now look
 We know where that's going like data. And PDFs is not is not as mysterious as it used to be like circular reasons to our conversation, right? But like, yeah, isn't it. But
 what we need to arrive at is a is a way for vendors to expose that data programmatically, so that the people designing these massive infrastructures
 As new component trees being designed every few weeks for for their new needs and new constraints can slurp up that that data about this infrastructure and pressure test new designs Drive effective, procurement workflows, and compress this time, Nvidia has a term that they use just time to first train and that's really the North Star metric that we're talking about often. You know, we have designed constraints, we want to meet
 We want to compress the time from. I've got space in power to, I'm training my my model in my now, online infrastructure. And one of the biggest constraints to that is all of these data Logistics and all of the pressure testing of the, the design, through digital twinning and effective aligned data in a data model like epoxy. So that's what we're working on.
 well, it can just imagine the
 Amount of time, it takes to just plug everything in.
 That and that's just one piece of it. That's like probably you're in the home stretch when you start plugging things in. Well now let's talk about that because I think this is the the act of racking stacking cabling plugging things in right? That act is is an emerging constraint and that constraint is going to get solved in the way. We all think it is too pretty soon, which is robots roughly and AI is going to help us with that as well. And so what do you need for a robot to walk into a gigantic Data Center and know what to rock wear and how to plug things in and how to run cables and all like, all of that kind of stuff. You need accurate data for that robot to act on. And so I think that's another another
 thing that we find ourselves thinking about or having conversations with all these operators about constantly,
 Like how am I going to give that robot accurate instructor. Accurate, what I call field operations instructions right now. Today even a even a human, you know, like a data center technician. Someone we're asking to walk into the data center and go down this cold aisle and, you know, walk around to the front of this rack and unplug this thing in this interface and plug it in over there. Um, that person isn't an architect, they don't often have all the information and all the knowledge to to do exactly what to do without really clear instructions and we'll call these instructions, like a cut sheet or a standard operating procedure, something like that. And
 Now think about how precise the you know that cut sheet or those those operating procedures need to be. If the thing we're instructing is no longer a human technician.
 but it's a
 It's an Optimus robot or something that's walking through the, you know, the, the data Hall and taking actions that's happening today for what it's worth in certain large, hyperscale facilities. So that's another constraint that we're going to start to compress is like, the racking stocking that stacking like the day Zero field operations, and then all. So the ongoing field operations because things break all the time or need to be reacted reconfigured.
 I,
 recorded a few musical, albums back in the day and it was at a studio that
 Was.
 Owned by a guy who absolutely adored.
 Complexity in the way that there were so many wires everywhere and he really was into analog gear. And so things were going through here and there and I didn't understand half of it, but I spent enough time because I recorded like three albums at this studio and I I was there so much that he eventually just gave me the keys and said, you know, like record when you want.
 but,
 Nine times out of 10, when I would go to record when I wanted, I was troubleshooting for the whole session because I couldn't figure out what the hell was going on with the complexity that he had set up, and this was in a studio, the size of the room that I'm in right now. I can't imagine a like, five different football field length Data Center.
 and, and that's such a great microcosm example because
 What you needed?
 Was something written down somewhere that you could refer to this red cable here. Like plug it in over here if you want this outcome, right? And that's
 If we distill it down, that's actually all netbox really is right? Like it is that documentation in a programmatic form that gets used to affect an outcome, whether it's a physical outcome. Like, plug this Cable in here, or or, you know, deploy this rack with, you know, this much space around it for thermal reasons or whatever or it's a logical outcome like a sign. This IP address to This Server so that it can be exposed to this and customer in this way, right? That's, that's roughly all it is and I think the
 Simplest and biggest takeaway here, a huge amount of complexity, huge amount of chaos, huge amount of demand, a huge amount of speed. And what what that requires
 Is good day. No surprise, right? Like when you can operate with good data, whether it's at Studio scale or whether it's a mega scale, you eliminate those inefficient, you would have been recording in three minutes and said of, you know, using all your time to figure out analog cabling.
 So many long nights trying to figure out why the hell I can't hear anything everything's working but no sound is coming out. What is going on? Oh man so yeah those it's almost like the
 the Sops of the
 data centers, need to be so clear and
 crisp and precise because you have so many more variables that are involved. And now if you're
 trying to,
 Eliminate constraints.
 In every single move because you speed is King, right here. You just royalty really and you're saying, well, could we throw robots at this or could we throw? Can we make this programmatic? Can we try and use a different
 Infiniband the Next Generation. There's always something that you're trying to iterate on.
 I can see how.
 something like netbox is going to be immensely valuable, but also how people are just
 Probably pulling their hair out left and right when it's amazing that any data centers are actually online right now that I think about it.
 It's such a it's such a fascinating space and I like, you know, many minutes into our conversation. One thing. I'll admit I'm not a data center engineer. I have no idea how any of this stuff really works. What we see?
 Is these teams that are the best in the world at building these infrastructures like how they are doing it in this really interesting, sort of cross-cutting view because they all are using netbox to solve this data problem. And I think you're right, there's, there's a reason why there's only a few 100 people in the world who are really pros at this. It's a really hard problem to solve. It's really Dynamic and I think there are some really interesting analogies by the way, till like the early days of the internet. Um, you know, 20 years ago, you could get in a room with roughly, the 200 people who ran the internet, they all knew each other, they knew how it worked, they talked to each other, it was evolving at a really fast clip. That's what's happening in AI for structure. Right now. Did this knowledge will propagate it'll start to normalize over time. How you do this stuff? Um, what we don't know yet is whether like the diversity that we're seeing in the ecosystem will persist, will there continue to be hundreds and hundreds of, you know, operators of for structure, will we see?
 More consolidation there are real economies of scale in this space, you know to the you know Ultra hyperscalers. I think that's also going to shake out over the next couple of years.
 but is
 absolutely intriguing. How
 until a few years ago, there were three clouds
 And now it was really it and now there's been this Cambrian explosion and so much. So we actually just released the GPU guide on the whole ecosystem because I just kept seeing all of these funding announcements and the majority of them that were raising a whole boatload of money were
 A very low level infrastructure plays and it was like well what are the value props that each one of these folks have? I don't understand what the difference is between a modal and a base 10 or a fireworks or together.
 And then are they even going and building their own data centers? Not really, they're kind of just renting them off of other people's data centers that are already out there so then you have a little bit lower that you could go to like the lamb does and they are building their own data centers and they're trying to do that. And so I was intrigued by all that which led me down the rabbit hole of. Okay. Well what are the value props here? Like what do I when would I want to use one versus the other? And I think you use a great term here, which is Cambrian explosion, the market answers. We don't know the answer is to like the, the actual value props that are going to stick in the long term, and that's why this can be an explosion is happening. There's an exploration happening in the market right now, right? And so, it could be that all these different business models make sense and all in the persisting. And, you know, we retain this diversity of kinds of infrastructure providers to meet these ultimate value.
 Positions whether it's, you know, really lightweight ephemeral, ephemeral, ability to pop up new infrastructure, really quickly on top of existing collocation Footprints or whether it's in a mega single tenant, purpose-built facilities with, you know, specialized Cooling and power, and whatever characteristics data centers in space, who knows, right? Like, um, so we're seeing an exploration happen right now, some of the, some of the value props that I do think.
 Are going to continue to.
 Like way into a diversity of infrastructure, types, and providers at least for, for some time.
 One is sovereignty and this is an interesting one. But if you think about how important to the world AI has become in such a compressed time, what we're seeing is countries Nations, right? Say this is strategically important. We need Sovereign AI for structure. We can't be dependent on a, for sure. You're sitting in the United States. For example, so you're not going to solve sovereignty with big monolithic. Hyperscale infrastructure is we're seeing Sovereign AI infrastructures pop up all over the place. Now, there are companies that specialize in building AI infrastructure, so that may be a specialization that persists another
 He kind of specialization that we already touched on a little bit. Is the the Spectrum from
 You know, single tenant Mega scale like, you know, training footprints for research Labs, all the way to, you know, slice and dice retail type infrastructures. These are very different and use cases and value. Propositions that may not all be best served by the same kind of company or architecture or operationalization.
 And then one more that we see often is, and this is akin to the sovereignty one.
 A certain kinds of Enterprises really want to own their own, AI infrastructure. We see this a lot in financial services, we see it a lot in healthcare and particular and Pharma where I performance compute is really valuable to have for drug Discovery and things like that. We see it a lot in government obviously. And one of the most interesting places that we see this a lot is in energy, if you're if you're generating, you know, gigawatts of power, it's a pretty natural extension in your business to like, put some gpus next to that power. But what all of those kinds of organizations are not are hyperscale data center Builders and operators, right? So when I think of the term AI Factory which we hear a lot it's mostly about that sort of value proposition. How do I provide
 Like the ability for, you know, Financial Services or Pharma or government or utility to get an AI data center without themselves, having to develop all of this expertise. So there's a bunch of different business models that we're seeing be explored right now. The aren't obviously all served by the same exact kind of
 Like converged, you know, hyperscale company. So for a while, I think we're going to continue to have this diversity.
 Will what you said earlier about a shipping container. Basically a data center in a box. Yep. Is new to me. I had never heard about that.
 Actually something that has existed for some time, even back in, you know, back when we all talk about Cloud as the next big thing, which ship has sailed a little bit. We've all consumed cloud and now like some repatriation, whatever, but deploying private clouds in shipping containers, or like think of them is just prefab. Cloud forest established concept. And so, maybe no surprise at the same, methodology is playing out in AI or GPU for structure as well for organizations that need to be able to deploy, you know, not hyperscale but owned single time footprints.
 yeah, and I like how you say,
 The.
 Classic quote from Amazon, right? Where
 Stick to it. Makes your beer tastes good and if you're a financial services company building data centers is probably not what your bread and butter is. So how can
 You reap the benefits of all of this without having to become a data center expert. Is it that you just hire one of these 200 people? Or is it that there's ways now that companies are popping up to service that demand and that's exactly it. There are companies that we're seeing that are I call them, AI, Factory, companies roughly, the who's value prop is exactly that I'm going to deliver
 Like an AI data center to meet the needs of this bank, or whatever it is. Or there's there are
 Spaces that have existed forever and what we call systems integration, right. So the the big systems integrators who forever have solved problems of building, it infrastructure or OT infrastructure or whatever. For Enterprises all now have ai Factory or high performance Computing practices who consolidate some of that expertise and repeatedly for their customers are able to procure. All the equipment solve all these problems that we've just talked about and pump out, AI data centers, you know, to spec to meet the needs of their customers. So that's a business model I think will persist
 now, when you
 Are.
 Looking up the stack, how high up do you go in terms of?
 That maintenance piece or if we need to do update to the gpus, I know that can be a headache in itself because yeah every second that the GPU is offline. You're burning cash. Are you all? So looking at that or is there a level where you you say all right cool we've we made it to hear and we kind of stopped.
 We have spent a lot of time today, talking about like the build process time to first train to use nvidia's term, right?
 I would say at least as important is the kind of operational processes around this infrastructure is up and running and living and then that blade in that rack died. What do we do, right? Or yeah, we need to do some software upgrades on, you know, these 18 racks or something like that. So here again, the data is critical all of these systems in real time are interacting According to some configuration. This server has this IP address on this interface. It's connected to this switch, it's running this software. It's allocated to this tenant, or this end customer or something like that, right? So all of that data context, equally important. Once you're up and running four things like I want to drain this infrastructure so that I can do a bunch of field operations on it, or reconfigure it or something like that.
 and, you know, I would also say like the pace
 Uh, in an operational, state is another order of magnitude faster, right? Like here, we're talking about operations or sorry automation, things can happen that are not driven from design when you're operating it for structure, like a backhoe can cut a piece of fiber and that just happened. Now what now what has to happen to flow around that all of that must be automated. There's no way to deal with that situation in a satisfying way without Automation and so automation demands good data.
 and I,
 I just keep coming back to like there's so many ways that this can fail, okay, from human error to just yeah, power outages or you blow a fuse and
 You now have to troubleshoot.
 You know, have to troubleshoot. I mean, and you're right so many ways this can fail, this is part of, why is really is the design phase.
 We need to Define our reliability or resiliency constraints and design for failure for everything, always fails and infrastructure. That's that's just a truism, right? At some point, a backhoe will cut that, you know, piece of fiber or, you know, that generator will blow up or something. Well, some that will happen, right? And so we design for those failures with appropriate redundancy and so on. But then we have to resolve those failures. And this is what you're getting at. We need the data and the visibility to understand. What is that thing? What's it connected to what is impacted by this?
 And what are our options for doing something about it. And, you know, a model like netbox and codes. All of the logical and physical information to understand that stuff, you need to couple it with tools that are observing behavior of these systems. In real time we call these observability tools for understanding the flow of network traffic or understanding thermal characteristics in the data center, like actual heat sensors on all the racks or power load characteristics or anything. You can imagine. We want to have visibility into as well to couple that data with the context of what we've built and how to supposed to be working. So we can ask is the design intent being met based on our observations based on what we can sense in this operational and if not what do we going to do about that, right. That's that's one we get humans to work, right? Like these switches are behaving differently than we expect for
 Our design humans, can you look at all the data and decide what we should do about this and then increasingly of course? So like we hope that AI operations sort of closes that loop as well AI agent. Like this seems to be behaving differently than we expect. What do you diagnose is the issue and what would you do about it?
 Well, this is fascinating because you're when you're talking about observability, you're referencing.
 Like the physical, the actual things you can touch and whatever I think about observability. It's like, oh yeah, is there like a data dog? Type of tool and solution is what my mind instantly goes to when I think of observability and
 Well, right? Like because
 Again think about the value proposition in these infrastructures ultimately its tokens are being generated roughly. And so you need to observe what I think of is The Logical like the flow of network traffic or is the server up or down, or whatever. That's that's a part of the process of generating those tokens.
 But the logical parts that process are underwritten by the physical parts of that process, there are servers and there is power and there are fiber optic cables. And so on that make up the ability to generate those run the software, that's generated those tokens. And so it's not enough just to observe things at The Logical level especially if you want to diagnose like
 Why did that IP address suddenly go offline? Well, it could be because somebody cut cut the cable, and we need to be able to diagnose down to that level, to remediate that issue, and get that IP address back online, right? So, the couple are observability of the physical and The Logical with our context about how this stuff is supposed to be working, Mary, all that stuff up. What you figure out is the Delta between our, like our observations and what's really happening and what our intent says, or what the design says. And then that Delta is the problem. We have to go fix.
 man, this is so cool to learn about, there is so much involved in it and it is
 a very high value problem because
 there's so much on the line and as we know like gpus are measured in seconds.
 and so you need to keep them on line at
 all costs.
 And this is the operational problem. They were talking about 100% agree. You need to keep them online at all costs when there's a, this is why these spaces like observability. For example are such high value spaces because the outcome when something
 Fails is deeply negative, right? The other the other
 Value equation. Going back to conversation. We had earlier is the speed to deliver value from these operating infrastructures to get them operational. And I think the other thing that we're seeing in this, in this space is the demand is so high and the expectations are so high to meet that demand that delays in speed delays and Logistics like when those constraints,
 Are bottlenecks create drag to bring infrastructure. Operational that has a really negative impact on value for the world too. And certainly for the companies that are building this infrastructure. So constraints, both pre-operation and post operations on speed, resiliency scale of this kind of thing.
 What are you seeing as far as the average of?
 Time it takes to stand up a data center. It's compressing really, really fast now. I mean, I think
 if you asked me that same question, five years ago,
 Otis said a typical data center, is a two year build at least. And today, I would say
 look, I had I had a week in November
 when I had calls with,
 Seven or eight of our customers building an infrastructure.
 Where every single one of them said, listen we're going to be 10x in our infrastructure over the next six months. You know we need your help in these ways or we need to make sure we're ready in way X Y or Z. So I mean just think about that math, right? These are organizations that have a large scale data centers online today and they're saying it's 10x in the next six months. They're building a data center a week. Roughly um you know, it's and now the now let's be clear, right? They're not starting from scratch and getting it all online in a week, right? These things are operating. They're happening in parallel is a complex product project management, you know, Logistics management, problem, to line, all these things up to pump out that many data centers that quickly, but that's roughly. The pace that we're seeing now.
 Where do you?
 feel their
 Are pieces missing right now with the whether it's in the build or it's in the operation parts of the data center.
 Yeah, like we're going through. Yeah I think so. I think the integration of all these things that we've talked about is a really tough challenge, it's way tougher than it should be today and we we delved into some of those in talking about.
 The notion of standardization of.
 Say component data, for example, from from networking and server and GPU and cabling and whatever vendors, right? Like the more we can start to standardize on how vendors share that information. The more we can compress the time to operations the time to first train so that's that's one example of the integration problem. Another example we talked about
 once these infrastructures are online,
 they're all these.
 Systems. That these teams are using to understand to, observe, like how their behaving, and integrate that with, how are they supposed to behaving? And integrate that with, we want to drive change and we want to scale this? And we want to support new kinds of workloads and so on. And so the, you know, right now
 Um, these teams are having to Kabul, too much of that together glue too much of that together on their own. And so, I think we'll see continued, like tightness in the way.
 Tools, like, netbox or we have observability capabilities or drift, detection, capabilities, or things like that. All glued together, tightly to form, kind of a cohesive
 Approach for these teams from as early as design intent, all the way through this thing is running, and I'm changing it. Without having to, you know, themselves integrate many, different components or data sets. Is it going to be
 The different providers start to integrate tighter, or is it going to be something where you see, netbox being the one single pane of glass that you can look through my general point of view is there? It's gonna be both roughly, like, one of the things that we think about is that there will be black platform consolidation in this space, it does make sense to have a tightly integrated set of
 tooling and capabilities to serve, the end-to-end needs. Given how tightly these operators need to need to operate from Israeli as design, all the way through, to kind of managing change and operational for structure and we're building for that. However, the reality is every infrastructure is different, there's no such thing as like a magic Blue. Print is hard as Nvidia and others are trying that everyone is going to follow the Cambrian explosion that we talked about just dictates that right there are different value propositions. There are different ideas that people are trying and so there probably will not be one magic you know tooling stack to rule them all will build, we'll build for that. But the other guiding principle that I think is really important in a space like this, and we have the supplies that out of AI data centers, too into Enterprise infrastructure, OT infrastructure. All kinds of infrastructure is
 One of openness and composability. So you know one of the things that we haven't talked about very much is the fact that netbox is open source. Almost everything that we build has open source elements and that's really purposeful and important. We need it to be easy for these teams to decide. I'm going to use all the netbox stuff to run this stuff. Except for this one piece because I really want to custom build something over here for. I don't know, observing or driving Automation in my infrastructure or some design element, that's unique to my business. But that needs to be able to integrate with the rest of the stack and this is where openness and apis and composability of the tool chain that these that these operators use to manage their own for structures is really, really important. And that's, I think a fundamental to how we think about the space and how I expect it to continue to evolve.