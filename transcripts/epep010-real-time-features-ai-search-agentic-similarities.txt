Like streaming aggregation, windowed aggregation. A lot of the compute stock is where we were. Like, oh man, once you look at level deeper, it's like you kind of see that it never quite got there. And so we were like, okay, we are the only ones that have cracked this nut.
 Creature platform is like how it started out. Like all kinds of fuses. I just know, generally, anything that goes into on a metrics. So roll engine's, or into context. Like this companies like
 So the feature platform idea, I know there's like a few different ways of explaining it. How do you guys explain like what the future platform is?
 What? I'm just a great job. He's the pro. Yeah no I think there are different definitions of it and I think the first thing I like to say when it comes to Crown on one thing that crown on does differently is that it you know, it does the compute. So there's like feature stories that leave the computer on the users and then they'll like do storage more as like a classic KV store with some stuff around it. But what we saw and the reason why we built on is that compute was really the hard thing that people struggled with. Like, if you want streaming features, if you want to be doing screaming, aggregations, if you want to be doing online, serving and offline training of, you know, offline training and have consistency, between those two things, you got to be Computing, your features a very specific way.
 So far us, what the future platform is, is takes raw data in produces features, serves them online. Serves them offline for online for inference service and offline for training. Does both of those things in a very scalable way and exposes a very easy API to the user to do that to power those flows. And so you know, that's the scope that we take a future platform that I think that's what made kronon unique and I think that's why I kind of the open source, gotten some good adoption is because it kind of hits on the main paint point that people face. Yeah. And that was my big question because I know that
 There's the feature stores that do the compute. They don't do the compute. They don't even store anything. They just will help you orchestrate things. And so you have all of those different iterations of it.
 It came from Airbnb. What made you want to build it? There when I joined it and be, that was already the last question of Corona called zipline that. Like what I'm done. Brad another boot.
 I remember reading that blog too, by the way and I was looking for there was no author on the blog and I was I wanted to bring you guys on and I was so pissed because I'm like, who created this and me being in Germany, I couldn't just like ask anybody, you know? So I was going nuts because I wanted to have you on the podcast or at least on back in those days in 2020. We were doing like the virtual meetups. Oh yeah. And it was like, this is a great blog. I want to know more about zipline because zipline did everything right. It wasn't just the feature store. Yeah. Yeah. So and I joined, I think the very first meeting I was in was like, there was like frosting in the room and they're like, hey, we need to be able to engineer, just hunt them out and proud very quickly because the nature of Florida that would say, right? Like someone figure out a way to order systems and like, bleed money. And that was a big problem back, then I would be and that was a big Focus. So that's what like, no, no.
 The early versions of cronon were built to solve that like to make it off-road? Yeah, yeah, people think of Airbnb as a travel company but the fact of the matter is it moves a lot of money across a lot of borders. So it looks like, I mean there's a whole payments company within Airbnb which is kind of from the outside, you wouldn't necessarily think that and so all those payments challenges that people have around payments fraud and trust and all those things, you know your baby had those exact same challenges. Basically that was the nature of the beast. But you know, they needed to be in a position where they can like fight fraud in a matter of hours. Right? But people who are trying to
 Do a bunch of things. They have to figure out the batching side of it. Because spark, then they have to like, figure out the stream processing side of it, then the figure out, you know, how to index it correctly, so that they can serve it, you know, at scale, then they have to figure out how to orchestrate it. You know, using airflow, and it's pretty mind-bending just to get one signal all the way through to the application, and they have to do it with hundreds of signals. All right? So imagine like, the complexity and the number of components that would be involved. So when you say signal, it's like basically a pipeline
 Yeah. It's like a piece of information. Like, how many times a user use discredit card in the past? Yeah. Like use this IP in the past X days. It's a really simple piece of information. But like to engineer this to the application and to the model training process, they have to like write massive pipelines. Yeah. Right. And hundreds of signals is like the lower end of things. It's usually thousands of signals. Yeah.
 Yeah, these models are very greedy. Oh yeah, they need all the signals. They can get they get better. You know the more you give it the best. It gets that then became crown on that then become Chrono. Yeah, and you bolted it on two zipline.
 Where I mean we're largely taking crown on and building zipline around it. So basically the story is that you build crown on you, spun that out or you open sourced it from Airbnb which
 I feel like Airbnb has open source to other stuff in the past. Yeah, info airflow. That's new. There was some big data thing that came out of. Oh yeah. Super set from both from Maxine. Yeah, what's my Max? Yeah, so just like the crown on open source was actually in collaboration with stripe. So before we lose first, we had like a close partnership with right, again, another payments company basically and we collaborated with them on their repository, for
 Six eight months or so before going open source. So it's a jointly managed
 Between the two companies? Well, it makes sense if it's very heavy on the fraud part that stripe would be interested. Yeah.
 Yeah, and then, actually the journey with an Airbnb after payments is kind of interesting because search was the next big one that came along, right? So search person lization is another use case. That's very sensitive to real-time. Data has very very high volume and can move the needle on the business. So it's like we're pushing that forward if you can and so that was kind of like the next big partnership that we had and what was interesting is that once we were kind of working at search scale, we saw other interesting use cases within the company. You just start organically popping up. So like if you go to Airbnb and you see any listing you'll see like a forklift SARS average or whatever. That's computed on Chrome on because that team basically wanted that to be real-time. You know, the same way that fraud and search want their signals to be real-time and they wanted to be like a windowed aggregation. So that, you know, really, really old Things fall out of the window and you see a more recent up to date view of that data at the user. And so, as the exact same data, engineering challenge that ml faces. But just as a product facing, you know, metric. So they were like, well, Trump's a great tool for this and it, like, simplified,
 Their life from reading this. Crazy Flink job to simply saying, hey, here's my data source. I want an average over this time window. And I want to, you know, plug it into this thing here. And it went from months to like a couple days to get that up and running. How did they find out about kronon? They just were hearing others, use it because I imagine things can get lost in an organization that big. I was very interesting process Airbnb. Got bigger, we know. Yeah, I believe it. Yeah. Where it gets out. I mean, you know, you struggle with the data engineering stuff enough and where it gets out like, hey, there's this thing, that'll make your life easier. So that was really cool for us to see here. I think the search you guys hearing played a big role in them finding us okay? Because they're such a tough, you scared that, it wouldn't be like a lot of people talk. Like, it wouldn't work on like, very easy, but the fact that it worked like, was very surprising and very impactful inside everyone's. So and Holmes was very like the team that did that use case a little, it was very close to search. Yeah. Okay. Searches so funny to me because
 A lot of the stuff that we're doing now with AI and all of the agents or rag, it's like, this is a search problem, even the Context Engineering. Now, it's like that. Feels like there's a lot of search going on here. And you gotta be good at search in some way, shape, or form. Yeah.
 Such as one of those things like, where the number of signals is like, in the order of thousands. And so a chance to be very complex, right? Some of these things include sequence modeling, llms like typical Vector indexing for embeddings.
 All these kinds of things in like one monolithic system, right? The more sophisticated, you know search setups. Look look like that and date engineering for that means like
 at least, you know, 200 or 300, mini pipelines all like together pushing data into
 Vector search. Yeah, all right. So back to the story. You win. You Open Source, crown on with stripe,
 And then you were like, I guess it's time that we started a company and go all in on this. So we saw a stripe use it and it wasn't very easy to get set up with crown on and they already had expertise with Flink and Spark and all of this other Technologies and it was still hard for them. So like okay if someone wants to use it then you should be a lot more work. Yeah. And like if someone was not familiar with any of this big data Technologies,
 It's going to be very hard for them to like use cronon.
 At the end of the day, like Chrono does a good job of abstracting these Technologies away from the user.
 Right. Users write SQL like stuff, and under the hood, all of this is happening. Like the sparkling and bigtable and like, all this technology has come up like even airflow, they don't have to even worry about airflow. Like any of these Technologies, they're just like right there queries and these things happen automatically.
 It does that job. But like to set it up, you need to know how all of those things of course. Because before you abstract it away, you've got to have a deep understanding of it. Basically, it's a technology that
 got a ton of different teams out there we think, but right now it's like, you know, there's a lot of need to the role. The business partly is to productize it and make it, you know, very easy to adopt. And yeah, I mean I think it's great that it has like this open core around it so that you know teams can adopt it with us. But then they have that like open source safety net there. Which means like no vendor lock in and kind of that sort of easier to work with business model for larger. Enterprise is thought, you guys were crazy when you came out and you were doing this, I was like
 But Feast is out there, which is kind of similar space. And I'm not saying you're crazy, because you're competing with Feast, but because of what happened with Feast, where it felt like it got bastardized a little bit. And then and then also feather, same thing, like LinkedIn release feather, and that also got bastardized. So, so we did this. We did this exercise with an Airbnb, right? Because we don't want to just be open sourcing anything for any reason we were like, okay, what you know, what is this doing in the market? What got this solving and really, what I came down to is kind of what we started off with, which is the compute stuff, right? The compute, the hardest part of the actual data engineering challenge for AI and ml.
 A feast, as an example of a something that adds a lot of value, like kind of Downstream of that, but it doesn't solve that, that main problem and never try to feather is really interesting. If you look at the documentation for it, it talks about all those problems, but then, if you go and look at the implementation, there's a lot of to Do's that never really got done like streaming like streaming aggregation window aggregation. A lot of the compute stuff is where we were. Like, oh man, once you look at level deeper, it's like you kind of see that it never quite got there. And so we were like, okay, we are the only ones that have cracked this nut. And so we need to be out there. And this is a very valuable sort of contribution to the community. Yeah, I guess. Feather they released it and they wanted to see if there would be any uptick and people using it and how that would and when they, I just don't think they got what they were looking for. Yeah, he had the right Vision. I mean, you read that documentation and I think they hit the nail on the head on a lot of stuff, but I think when they got out there they're just wasn't enough of it. There working really well I mean it took us a long time really? Well it's hard and I see I see
 Lie. It never got it was a grind for many, many years and then I think the opportunity to work with stripe before getting out there into the open source. Gave us a chance to like really battle tested at a whole nother company at scale and like iron out all these things. And so by the time we went open source like the dream was real. As of I think I think feather had the vision but I think by the time I got out there from what we saw, the implementation wasn't quite there. But yeah, I mean I don't mean to talk about any of these tools like they're no, I don't think you're talking bad, if anybody's talking about is me calling investors.
 Jon Snow.
 They're all like they're all very interesting technology. I think I think we are unique in that like we took our like we took the time to like really make sure we nailed the hardest part of the problem and I think that's what was unique about our open source.
 And so why was it so hard?
 To get that working.
 That is a series of problems, right?
 That I think like, but like, maybe talk about the two main ones I suppose.
 One is generating training data. That is point in time, correct.
 all right, so people already have
 a series of like observation and labels associated with those other situations like
 That's part of my card, like, way down the line. You know, someone said this is fraud, you know, Cloud money back through a trash bag or whatever. So they have this observation slogs of observations all companies have these and they're like, okay when these are the relations happen, we need to create features at those points in time.
 So when I say point in time, correct training set, like I have a new feature idea and I need to create those features at the observation point in history.
 That is.
 A n Cube problem. Essentially, if you do it, then I SQL way, right? If you write a SQL query saying, like, give me all the raw data at that point and then aggregate for every one of those observations that blows up very quickly. Yeah. And that's what people are doing and they're like, okay, this is blowing up and I'm not going to figure out how to make this fast. I'll just use that features. That's true. That's why real time is so hard.
 You put yourself into the user shoe is, right? It's like okay. They're like I understand my data and I understand the transformation I want to run and then it's like to express that you have to learn like Flink spark. I mean like those Technologies fundamentally we're not built for these use cases. It's really like if you look at the history of thatch like oh lap, it's like it's pretty much bi. I mean it's like like for you know, Matt produced and high, all these things. Kind of just evolution of bi and powering pipelines and that won't get for like, you know, every day I need to generate a report that someone's going to look at you know, executives.
 and now, it's like,
 The actual workflows for AI and ml. They cross these boundaries of streaming, and batch of online serving of inference and training. It's like they cross all these boundaries and no tool. Really took a step back and addressed that sort of user need in a first-class way, everyone started duct taping stuff together, and then that's where all these like nightmare data, engineering projects come from. And I think, yeah, one thing unique about us is that we took that step back and we're like, okay, what if we exposed
 The abstraction that the user is actually trying to do, which is, here's the data. Here's a transformation, I needed offline. And this way from model training and I needed online with these very strict requirements for low latency inference and like what if we try to make that magic? And and it's hard turns out there was a reason why nobody had done it. People have tried it, we have seen like, many many years. There's a graveyard full of people who have tried it, but Airbnb was a
 Wonderful place for us to build it because it gave us. It gave us what we needed to try it a few times and make some like mistakes that I think. If we were like if we had turned back the clock seven years and started this startup, you know, from then, I don't think we would have had to leave way to make the mistakes that we needed to make to learn how to do this properly. So I think because we had like Airbnb as a place to get this, right? And stripe as well as a place to get this, right? That's what led us come out, the gates or something that worked. Yeah. And that was huge for us and it kind of felt like you could battle test it but you could also recognize
 If it works in two companies that are very different, we could probably make it work in more. Yeah, right. And and having the flexibility to do that was like
 we were yeah, we were in a very unique place in time to be able to pull that off and Airbnb. You know, of course, has the kind of like culture to to like excellent engineering culture to kind of support that and and Foster that and see the value in that and invest in those like long-term projects which is really rare. Yeah. So now, what do you thinking about now, it's the whole data life cycle, right? It's not just the Feature Part,
 Yeah. Oh yeah. Because I should preface this by. You won the pitch competition for San Francisco. Congratulations, as promised we are on a podcast.
 I don't have most pitch competitions that give you like 100 Grand all this very fancy stuff. You get a podcast my friend let it be known each us pays his debts yes.
 Exactly. Yeah.
 Yeah, whatever. So whatever you investing. I mean it's very interesting. Now, we're out there, we're working with customers. We're seeing what the actual needs are on the ground. And we're seeing sort of where the main pain points are and and how to, you know, get the most out of this technology that we started. Building a couple of things are standing out. One is definitely governance and just, you know, like data privacy data governance having confidence in these systems that are serving in the most, critical use cases at these companies. And so we're thinking a lot about that and how to make that part of the platform and the other one is yeah. I mean, we've seen people kind of still figuring out.
 More foundational pieces of data infrastructure. A lot of teams are trying to move to Iceberg. A lot of teams are you know, trying to move to open source, you know, things from cloud specific offerings and we're thinking about that too. So we're kind of following where the actual needs are on the ground wherever very plugged into trying to plug into real value at real use cases and those two things are standing out to us right now.
 It's
 interesting. What you were talking about with Iceberg earlier how
 Everyone wants Iceberg. They're not sure how yeah, for sure. It's hard. I mean yeah.
 Where are they getting stuck? There's a lot, I mean, series of choices, right? It's like you have an event bus or you have a database that's online and you need to wait to transfer that into your offline file system, like S3 or GCS.
 And from there like you need to, once you have the iceberg files or whatever you need a catalog that you could use, right? And
 Depending on which Cloud you're on, it catalog is not a solved problem, that's a very open problem and that needs to play will with their existing data, right? If they're on bigquery, it needs to play well with the existing thing and you need to have an engine that can like understand this Iceberg file. Well and work with the optimization that as work allows you to do.
 All right as well has like a huge depth of like optimizations that you can like plug into which Indians like bigquery do automatically under the hood, right? Just because you have some data and Iceberg doesn't mean you're getting the full benefit of
 having that nice work. Oh really? Yeah, it's not that straightforward. Like you need to like be able to do clustering, do views, do all of these things that the defect of offerings on things, like Google Cloud. Simply don't support
 Oh, so what do you have to do then? So people like, try all kinds of things that try Polaris, they try gravity, and all this, like, budding problems, they write big their own catalog, right? And they're like, figure out how to get their data. They like move from pubsub into GCS Avro as it is, and then like, use some ETL to process that into parquet and form Iceberg out of it and then figure out this catalog thing and put it in there.
 Right. How many people we don't think like, a lot of people are successful with, like doing this kind of a dance around their data infrastructure. So then is the idea to just be like, hey, potentially, there is a world where
 you can hit zipline.
 And you're instantly on Iceberg and it is as easy as you would, hope that it would be eventually want to get the. So there is two levels to that. I think like one is like I already have my data.
 In pubsub. Yeah, right, you take care of this dance of getting this into an iceberg and catalog, and you take care of like, leveraging the optimization, right? Then there are people, who are? Like, I have a service. I'm not talking anything. But if you, if you tell me, if there is a library that I can log into, I will do it, right? So there is that level even eventually want to get there. Hey, this is a zipline Library.
 You log it under the hood, we log it to pubsub or Kafka and like create the iceberg warehouse and you can leverage it, right? So that's eventually where we want to get to. But first, we are like trying to get to a point where you already have Pulsa. We are going to make Iceberg warehouse for you. And what about the engine? Because the hardest parts compute? Yeah. Well, so we started there, right? Yeah.
 She's a bit Downstream of these problems and now we're working Upstream which is yeah a kind of kind of a funny Journey but I think somehow coincidentally not not through any strategic planning of ours, kind of a good way to tackle. This problem actually to start there in the middle kind of in between you're like ingestion and your online. AI ml use cases and kind of expand expand from there. But I think yeah. I mean I think the cool thing is
 Also like there's a lot of value in just people struggle with best practices for like how to you know do this ingestion like write to these daily partition files in a certain way that it'll scale really well and plug in really well with Downstream compute engine. So I think as we kind of put this stuff out and we'll be putting it out into Open Source, by the way, this will be not kind of vendor technology. It'll, it'll kind of give people an example of like, hey, we've seen this stuff a couple of times. We've scaled this from like really bad practices to good practices as a couple big companies. It's like we can start you off on a good path and I think there's a lot of value just in that as well. Starting on the right foot. Yeah. Like I can't tell you how many times we've migrated from like a huge monolithic Json logging to like schema and force, you know, smaller topics and things like that and it you know it makes sense because to start with the monolith because it's a lot easier to do that right now but if it was just as easy to start with the right thing, I think that would save so much pain for a teams but anyway. Oh yeah. I I see that completely and so it's almost like you're doing.
 The things that are the easiest just because they're easy, even though, you know, later you're like, yeah, just building my tech debt right now. Yeah, yeah. I think that's a game that killing like to play.
 Should we looked at the data engineering problem for it? MLA is like that was the question that we asked. Yeah. The answer is well, very differently than how it works and English, some of there's like Iceberg and ingest and stuff that we're seeing out there. It's like, well, this should be easier. Yeah. And so I think there's some idea how to make it easier.
 all right, so you guys
 Were also doing like agent stuff at Airbnb back in the day tell me more about that. Yeah, so the biggest thing I'd be in B that was using chronon
 But don't feed data into llms was customer support.
 Customer support is a big cost center for Airbnb, right? I mean, we traditionally like implies people in us, right? And pays a lot of like
 Money for that organization. And the cost is like, not super high and like everything that they can save their translates to like profit or translation. Lord prices.
 Right. So all of that.
 Was a big driver and the biggest problem they had was populating context correctly.
 They already have the agent workflow figured out, and the workflow has workflow decision points which are like either, you know, give some data to llm.
 And see what it says and or it is more like gather data from around the organization from different surfaces and see what the user was doing in the previous day or previous week and figure out what they might want.
 This features.
 Basically, it's basically features. It's contest. Engineering is what they call it now, but it's basically featured. It is true. So they started to build out something on their own using Lang chain and all of these like when they're prototyping. But then, but when it came to prod it, you know, it was a national thing for them to like, hey, let's like move all of this thing to Corona and have Chrono like Drive the pipelines, and the indexes, and endpoints that power this context, right? So that's kind of where it started and search agent, which I don't think is like out there yet. But is another one that that was, those are the two main search agent.
 this, it's like, you know, your chatting with a
 Agent. That's helping you figure out how to book your next Airbnb and where to travel even. Yeah, right. So that's like the idea that it's like, a virtual travel agent and
 Those are the two main use cases at Airbnb. And so that was also just taking features from you and helping the search features and like in this one a bit of embeddings too.
 I was gonna say we should talk about embeddings as well. Yeah talk about that. That's been an interesting one for us and coming out more and more recently. Yeah even in places you wouldn't expect it like fraud and personalization and search oh really yeah rag was a big one right? Like like in customer support for example user says something and this something is about a particular set of policy and like this policy related to all this paragraphs in the policy documents and there's huge Corpus of like policy documents that training to pull from.
 All right, so that was all driven by Rags. So, you know, it's like
 Chunk. This thing's and embed them and store them in a vector store and then pull it out. You know, whenever you need that information, and there is another set of things, which is like users conversations, right? As the third is like, happening with the whole start with the support agent, the intent of the conversation keeps changing. And that intent is captured as embeddings, right? So what you're trying to do is essentially like take this intent side and match it with the policy side, right? That's two embeddings and you're doing a DOT product to like figure out what's the most relevant information that eliminate to get to make a decision.
 Fascinating. So we were on both sides of this but mostly on the user side because that's harder because you need to move a lot of real-time data embedded and store it in a vector index. And then surface it. Yeah, yeah. And so, this is like something that has some recent momentum in the corona, open source, like first Native, embedding support within cronon. So, it's not really features anymore. It's like features and embeddings now, which is pretty exciting, and there's a ton of value in like orchestrating more complex graphs, you know, combining features and embeddings together into and workflows, which again was pretty much prohibitively difficult before for all about. The biggest, most sophisticated teams that we're trying to make that just as easy as anything else in Corona. But you're not
 Creating embeddings out of features.
 A lot of raw database. Yeah. I mean so we created embedding sort of
 Message history and we treat a window of messages as a feature, okay? All right.
 And I mean we treat that as a transformation like that windowing operation on the message stream as a feature essentially and feed that into an embedding model. Nice get a numbering out user activities is another good example, right? Like user sequence modeling know, you take a bunch of a user activities. Again, you're usually aggregating like the last 50 or 100, although now, bigger Windows have become an interesting thing that teams want to experiment with, you know, of user activities and turning that into a user embedding. And using that to drive recommendations or personalized experience. Tiktok does 5000 5000 biddings, 5,000 activities into an embedding and tiktok has the team to build that in front. Yeah, not a lot of companies have access to that even though they have potentially very high value use cases and I think that's where we're offering a compelling, you know, open source base products here that can actually power that that kind of use case has scale