It is useful to understand energy levels and think about, when light hits atoms, how electrons will change energy levels? But it is more accurate to think about the electron cloud. And so that what you sort of modeled with the web is probably more accurate, but decision trees and flow. Diagrams are still potentially useful constructs to think about how an agent should behave.
 The difference about AI is that instead of the software being super cheap, super fast super reliable. It's actually quite expensive to run.
 Kind of slow gets slower and slower the better. The reasoning models get and non-deterministic so it can be creative. It can be flexible but it can also hallucinate. And so the methodology that you need at each of those different junctures in this flywheel that you're trying to build.
 Is pretty different from with traditional software. So it's like traditional software, does this? Let's just take the opposite of all of those. A good example is like, unit testing, right? So with unit tests,
 You run them once, if they pass, you're good with simulations, which is what we call our Flagship testing product. In Sierra, we might simulate a given conversation 510 15 times and then you'll look at what data changes happen as a result of the conversation, which is a similar methodology to what we published with Tau bench, which is the open source framework for eval. But will also do using an llm as a judge or third agent. So you kind of have the user agent, the agent agent, and then the evaluator agent and the evaluator agent will say, you know, did this conversation meet the checklist and that's pretty different from unit tests or even integration tests and traditional software. Do you even put that in the cicd pipeline? You do? Yeah. So we have the concept of what we call critical simulations, which are simulations that run, you know, when you actually will merge a commit to Maine or schedule a release or what?
 Of you feels like that. Could be really slow. It could be, we have a high degree of parallelism. So if you have 300 simulations that you need to run, you're not waiting for them to run one after the other, they're going off and being executed in parallel. And when you say simulation, are you only talking about it for voice or are you talking about it for everything?
 It's interesting. You ask that question with voice first. I feel like most of the time I get that question. It's are you only thinking about it for chat? But it is both. So it's actually pretty interesting to listen to voice simulations the
 Way that they work is, we'll have a library of background noise, library of voices, a library of all these sort of different entropic things that you can introduce to try to simulate, what it would actually be like to get a phone call. And our customers are all over the world and all different environments and all different Industries. Exactly. So you have people calling in from the car, you know, Sirius XM is one of our larger customers and people will call in because their radio is not working and they're in the car by the, you know, on a busy street or something. And so you have the background noise, you have different accents, you have different microphone quality, not everyone's talking into this, you know, magical podcast mic. And so, you have to deal with all that and our simulations have kind of gone through that punch list, you know, row by row and said, okay, we're adding this to the product and then if you run it 510 15 times,
 Over three 400 simulations. You have a pretty good idea that if those are all passing, your agent is doing what you would expect it to do. Do you also look at simulations a little bit, like red teaming.
 Definitely. So there's I don't know if I would say there's two classes of simulations, but there are definitely some where it's just the happy path. Oh, I need to reset my radio because the encryption keys and expired and so, an API call goes out and a satellite beams down. The new encryption keys, and you can listen to sports talk again or Howard Stern, or whoever, whoever you like to listen to,
 But then there's also the more adversarial simulations where you're trying to, you know, we call it abuse the agent. And so we have a number of custom models that are just about detecting abuse and those are often customer specific as well where you know, some customers they might have younger audience and things like self-harm and bullying are top of mind. Some customers might have different audience and things like hacking into the system or top of mind. So you have to be pretty customer specific in how you think of it. The nice thing is, this is a very valuable problem for our customers and so they're deeply engaged with us and we've gone over the last six months or so making the entire product fully self-serve. So that it's self-explanatory. You can get up to speed and while it is, the deep thought process, it's kind of up to you on the spectrum of how much you want to take that into your own hands. How much you want to work with Sierra's agent development team. How are you creating these in the Furious?
 Simulations, there are three agents involved, there's the user agent, there's the agent itself, the AI agent, although they're all Ai and then there's the llm as a judge. And so the user agent, basically can take a system prompt as part of the simulation, but you don't have to massage it to get it to be like really bad.
 Um so I think to get it to be really bad. You would and typically we won't have the really bad simulations as part of the
 The run. You can also you want to catch that before it's out or trying to get to production. I think the honest reason is that you typically the list of really bad stuff, you just want to make it. So not everyone has to look at that. Every
 Couple minutes. Yeah and also I don't think that AI models are that good at imagining
 Some of the terrible things that people say probably because you know the model providers have gotten out in front of that. Yeah that being said we also have the concept of verbatim simulations where you can just hard code a script of what the user agent should say. When the AI agents says X. And so for those ones where you really want to test against you know some of this behavior that you definitely want to prevent against or you know prompt hijacking or these kinds of things you basically will do a Verbatim simulation instead of an AI user AI simulation. Does that make sense? Yeah, the really bad stuff. I'm not necessarily thinking really bad and like what humans are capable of yeah just thinking really bad out of like as a
 Prompt hijacking type of thing where I'm just trying to get some data out of the model. If I know that I'm now dealing with an AI agent. Let's see what I can get from it right that way. Maybe it's naive. I feel like the
 models that are out there today, are not that good at trying to, like, hijack themselves.
 There's two things that come into play here as well. One is that the actual access to sensitive information is always safeguarded in a deterministic fashion show. So we'll have more traditional unit tests that will make sure that the access controls to a system are no different from what you would have if you were on the website, you know, logged in as a user as an example. So we don't leave it up to the model in any case whether to expose sensitive information. We leave that up to deterministic systems. How does that work? Like the connection between access and model?
 so often, let's say you go to all think like, Sonos for example, and your logged in,
 The fact that you're logged in means that you have access to a set of data in Sonos database. Maybe the speakers that you've connected to the networks in your home.
 And the AI model also has access to that same information so you would never be able to use the model to get information that isn't already available to you you know as a logged in user on the website. Yeah. So it's almost like
 As you log in, then the model just has this sandbox of Your World, correct.
 And then if it needs to go and do something because you have a complaint, then it like gets out of your world or it.
 Well if you have a complaint, that would be something you could do in your world as well. So the models they're taking action all the time but they're not taking actions that you would not have permission to do as a user. Yeah. And so then you're just protecting on the permission side of things like and that doesn't seem like it's
 like that's a tried and true thing that we've been doing in software and that didn't necessarily flip like you were talking about back with that right thing? It's not one of those slow non-deterministic if you can make sure that the model doesn't have access to it. It just gets access to what it gets then whether or not it gives. The information is where things get wonky.
 That's exactly right and you said earlier like oh so you're just kind of doing the exact opposite of the software development like cycle. And I kind of just took it in a different direction because it's that's actually not true. A lot of the times you need to do the exact same thing, that's tried and true from traditional software development. Sometimes you need to do the opposite and sometimes you need more of a hybrid approach. So it's more of a first principles analysis of each of the different steps of kind of plan. Build test release, optimize analyze plan, build test release, you know, etc, etc. But just kind of from the first principles of what's changed using AI systems along with deterministic systems as a post to only deterministic systems. I wonder how different the simulations are for voice and for text.
 Or if they are, I know that, of course with voice, you got to add in all these special things, like you're saying like noise background noise. Also, I I've talked at length with people about conversational design, you can't let somebody know that the model's going off and doing something, right? Or you don't want to have somebody thinking that somebody hung up the agent hung up, because the model is off and doing something. So, you want to give like cues and all that stuff. So, I imagine that's one type of simulation and that you're only gonna find invoice, right? And then in text, you have different types of simulation and how do you see those two being different? It's a really good question. And one that's very close to my heart. Because my personal story at Sierra was I spent the first nine months building agents with customers. So I mentioned Serious XM because they're one of our larger customers that were proud to work with. But also, because I helped build the very first version of their agent.
 And then Serious XM, you know, as large as they are over chat, they're even larger over voice. And so just seeing that kind of having it beat us over the head of, hey, voice is actually the opportunity here, you know, led me and a couple others from the team to start prototyping. What would it look like to build out a voice version of their agent and
 so we iterated on that and eventually kind of moved up the hierarchy of needs from just being able to go back and forth to actually responding to verbal cues and interruptions
 One example is.
 An interruption is not actually a super objective thing. If you start talking right now, you might be agreeing with me, encouraging, me interrupting me, sort of telling me to go in a little bit of a different direction, but most automated systems today, if you say something, they will just stop and start over no matter what you said. And so painful to as the user. Yes. Yes. And so actually feels like they're talking over you because you're like you go. No, I go and I don't know if you everyone's had this where you're walking down the hall and someone's walking towards you and you're like, who's gonna move? And that's what it feels like all the time dancing in the way. Yeah. And like, obviously, once you get so deep in the Matrix, you notice everything. So, as an example, the two of us were just talking at the same time.
 But it wasn't a problem. Another example is
 If I pause for a very long time, like I just did in the middle of a sentence, you know, to wait for me. But if I'm done speaking, you know, that it's your turn to speak and so context is so important. Both was this in an eruption, and is it my turn to speak and it you can't just boil it down to a number of milliseconds. You need to actually think about what's being said and start planning your response. You know, before the other person's done talking, everyone almost has their Cadence their way that they talk is unique to them. Right? And so I'm a give longer pauses and I may speak slower and I may not want to finish but then actually I do finish or things like I speak. Weird. Right. And we all kind of have our own quirks when we speak.
 And you can't have a universal setting of. All right. Well the models gonna be like this, the model almost has to adapt to each individual way of speaking, but I haven't seen anywhere. Maybe you've messed around with this where you can have the model interpret, the first, whatever, 10 seconds and go. Okay, this person takes long pauses in the middle of sentences or this person speaks a little bit slower and so I'm going to give them more time between words, right?
 It's a really good point at the very high level. You can do some of this for customer specific. As an example, you know, if a customer has mostly older callers, you might wait longer. If a customer if a customer, has a lot of authentication flows, you know, that it takes a while to, you know, talk through your email or your password or these kinds of things. So some of it is shared
 That being said I think to do it in a personalized manner. Like humans do you probably will have the most success with some of the speech to speech models where the audio tokens themselves? Are the things that are being inferred upon and so that actually all kind of gets boiled down into the training data.
 That being said right now most of those systems for most production environments are just a little bit too hallucinatory. Yeah our approach has been we've built a modular architecture, so on the transcription side and on the synthesis side,
 And by the way, even if you're using the speech-to-speech model, you need transcription because you can't make an API call with a bunch of voice tokens. And so, we transcriptions part of the pipeline, no matter what, but we do have support for models like, you know, the the model that underlies, the real-time API, the GPT Audio models as well as the Gemini Audio models, which are these kind of fully speech-to-speech models. And I think that's going to be the future. It's just being honest with you right now.
 The amount of hallucination that we've seen in our production tests, is such that for the larger customers.
 Ah, the text to speech is still the most reliable way. Yeah, I've heard that from just about everybody, I've talked to where it's like we want it with that speech-language model but we can't have it because it's just I can't put that into production with any amount of confidence. Yeah. And I would I would go step further than we want it which is you know that I believe in it. I think if you and I were passing notes across the table right now, it would be a much less interesting and productive conversation and that's basically what AI agents are doing. So we're willing to make the long-term investment in our architecture where we support that out of the box today even though it's not quite ready. And we're following the openai in particular, just released a new real-time Audio model and every time one of those things happens, we, you know, tested out, figure out, are there places where we could use this, and obviously, there's a risk tolerance, and risk, likelihood Spectrum for each of our customers. So, I think we will find that.
 For certain languages for certain customers. For certain use cases, this is going to be an absolutely magical experience. And then over time, it will kind of disrupt the text to speech Approach. At least that's my personal belief. Do you have a pipeline that you'll run models through as soon as they come out just to see like because obviously
 When you look at benchmarks, it's just a bunch of bulshit, right?
 We do some benchmarks are really cool as well. Like, we love our Tau bench Benchmark. It's really cool. When the math Olympiad is won by an AI but when it comes to putting systems in production for our customers, I think what you said is roughly accurate we do immediately. When a model comes out, we have a whole Suite of evals that will run. But it's usually an iterative process because one model might be better if you prompt it in a different way or if you shot it in a different way or even if you find tune it in a different way. So it's not you have a good Instinct immediately but it's often a multiple days, multiple weeks. Process to know if the ceiling of the new model is higher than the ceiling, you know, the local maximum that you've climbed to on the previous model. So it's it's and then I would say also for Voice language is a huge deal as well as like dialect and Locale. So Brazilian Portuguese being different from Portugal Portuguese and so you have to
 We basically have a rubric and we have, you know, basically callers that we work with who can call in and test out each model, you know, because you need people that actually speak the language that can be in realistic scenarios or else you're going to most likely overfit to some data or, you know, not be representative. Yeah, my buddy was telling me how he was doing a bunch of simulations on the
 Openai real time. And one funny thing that he found was when you
 speak English with an Italian accent or know when you spoke in Spanish. Yeah, with an Italian accent. Yeah.
 It would switch to this like made-up language, that was like a mix between Spanish and Italian. Oh wow! And when you spoke German, when you spoke English with a German accent, it would just switched to German and speak to you in German. And so it was like, what is going on speaking English? You know, I wanted to be in English but it keeps switching to German. Yeah and that's the end of the day you're like what is it the end of the world because if the
 German accent is there? That probably implies they speak. German and that's why not just begin to in German exactly. It's like
 I don't know. Do you speak any other languages besides English? Okay, so if you go to a restaurant, let's say and someone greets you in English, but they have an accent that suggests they speak Spanish or Portuguese? You do you kind of feel that urge of like, oh, I want to practice my Spanish short. Like, you know, always could we have a discussion in another language? Wouldn't that be fun? And I guess that's sort of what's going on in the model. Yeah. And on the simulation, I know that
 Our mutual friend, Willem has told me about how he uses heat maps to see where the agents are good and where they're bad and this is like, on the task completion side of things. Have you tried to do any of that with like because that feels very orthogonal to simulation in a way. It's like you you simulate things and you see where it's good, where it's bad. But then if it's an agent maybe it's like the next step is. Can it do this? Can I actually like complete the tasks that we ask it to do. It's a really important piece of it is not just what did I do wrong, but how do I do it right next time? And I think, without a clear, understanding of where you went wrong, which I think maybe what you're getting out with the heat map. You can't really understand what the fix would be. So to give a few examples, sometimes the agent will go in the wrong direction because it doesn't have the right answer.
 Sometimes the standard operating procedure is wrong. Sometimes it was asked to reason about too many things at the same time.
 And so, you want to know those things at the point where there's an error, so that you can fix it most quickly. And in simple cases the agent can fix it itself. So one example is a number of conversations from Sierra, it's remarkably low at this point with a lot of our agents but a number of conversations end up getting transferred to a human especially if there's something that you need to do that. Just requires oversight or regulated Industries, Etc.
 and so in those cases though,
 You can actually learn from what the human did post-transfer and detect. Is there anything missing in my standard operating procedure? Is there anything missing in my knowledge base and have ai author draft article of? Hey, you should maybe you should add this knowledge. We had, you know, 150 different agents all mention this thing. But the AI agent doesn't seem to know about it yet. And sometimes it's like, no, no, I don't want the AI agent to know about that and sometimes it's like, oh yeah, that was missing and it's remarkable how often it's the latter, because a lot of the companies we work with one of the things we hear a lot on. Our Discovery calls is like, I don't know if I'm ready because my knowledge base isn't in a good place and so our response to that and one of the reasons that we build this product is well, actually the best way to get your knowledge base in a good place, is to launch an AI agent and just make sure that it's scoped appropriately, but you'll actually find the edges of what it knows and our system, The Seer
 Platform will create basically a prioritized list of the knowledge that your agent should have but doesn't have or where it's a little bit off or implying the wrong thing. It reminds me of like the continuous integration where you're just, you're seeing where's the edge case. Okay, cool. Now let's integrate that back into the knowledge base so that hopefully it's not an edge case next time. Yes. And I think there's two other things here, I know I'm doing a lot of twos. There's two other things here that are very, very important. One is it's a really important business problem for customers. So when you create the system that allows you to kind of pull in the right direction and just create that upward spiral of improvement,
 they're going to pull on it. So we have customers where they have, you know, 10 plus full-time, people evaluating conversations and looking for opportunities for improvement because it's such an important business problem.
 And then the other piece, I know it's not a business podcast, but I think it's kind of geeky too, is we have this outcome-based pricing model where Sierra only gets paid when the agent just does the job? Well yeah and so you have the incentives on the customer side and you have the incentives on the Sierra side and so as sort of a systems thinker it's this very very fun environment where if you create the system the business incentives on both sides. We'll just pull the agent and upwards spiral and I think that's accountable for a surprising amount of our success is just that the incentives are so aligned, and the table is set to improve the agent. I always loved the idea of outcome-based pricing but
 Feel like it.
 Is insanely dangerous? Why do you say that? Because you, it's on you and if your agent fucks up and then you don't get the outcome.
 You pay money like you eat that price of us? Yeah, exactly. Like
 There's a potential world where you don't get the outcome, but you end up spending money obviously it's like we're talking sense here potential, but at gigantic scale and you don't recognize there's a problem soon. Enough you can burn through some cash. I think the
 these are two correlated events in a way, which is
 It kind of turns a lagging indicator into a leading indicator. We'd actually rather know that sooner, rather than later that our agent isn't performing. Well, we'd rather feel the pain of letting money on fire so that we have to fix it. And then, when it comes time to renew a contract the year, from now, we actually might feel better about our relationship with our customers. So I think our NPS with our customers is much higher because of this because we actually find out about issues and we have to fix them because we're feeling the pain of like a hole in our pocket in the moment instead of you know 12:00 hey yeah we you know it wasn't performing as well as we thought. Yeah. That's a great Point. You're not going to get that conversation as often because you're going to be charging them when they have successful cases. Right? I could see that right? One thing that I've heard folks talk about a lot. Is that getting the especially in the customer success Lane?
 Getting it working for one or two.
 people when they're coming in and complaining or doing something is not, I'm not going to say easy because it's not easy, put it is doable and then where it really gets hard is when you have to service
 A company that has millions of users and then the customer support is trying to service all of these tickets at scale.
 Have you, how do you think about like that? And is that right? Because I've heard it from folks, I want to like fact, check it real fast. And then see what how you think about it? And you're talking about the AI agents or human agents? Yeah. Because we, we definitely see that on the human side where, you know, it's not a coincidence that so many of our customers are large consumer companies where they have millions of customers, I think,
 I think it's true that most of our customers have millions of their own customers. Most of our customers have over a billion dollars in Revenue, so that kind of stands to reason if they're a consumer customer, they probably have millions and
 They see this scale such that the power of bringing in AI just changes the nature of their relationship with their customers. Where previously. Maybe they had a strong incentive to hide their phone number on some Backwater page of their website. Now they can plaster it on the front. That's the only offer we've already seen that come. Yeah, yeah, we're here like trying to click through contact these. Yeah, yeah, it's like a meme at this point. And so I think when you think about, you know, the AI agent as kind of the analogy to the internet website or the mobile app,
 It's also about the actual addressable Market of contacts with a business growing because now you can provide a great experience to anyone who calls in I think though.
 What you said about you know seeing just a different distribution when you get scale. The stat that's stuck with me a lot. I spent the first seven years of my career at Google and to this day, something like 20% of all. Google searches have never been made before.
 And that's because different things are happening every day. New language changes. You know the things people are curious about change Etc and so you need a system that's actually like resilient because the same thing is true for our businesses, the reasons people are chatting in are going to change each day. You know, if someone is doing an interview in The Serious XM Studio, you're going to get different questions from a day where they had an outage or something like that. And so each day there's just different questions and you have to build a system that's truly resilient.
 And one of the things that I look back on Google, really fondly about is just the amount of invention occurring in the company. You'd go to the All Hands which is called TGIF and you would hear, oh, you know, we use machine learning to improve the way that cooling works in the data center and it's saving us a billion dollars. It's a lot of money for an algorithm or like, you know, they before the latest iterations of large language models, you know, we are understanding search queries better, we created this Bert, classifier or analyzer, which can tell us, you know, a lot more about the actual semantic. Meaning of a search query, not just the keywords that are in it or you know, our data centers, they run 20 degrees hotter than any other data centers because actually, machines failing isn't a big deal for us because we have failover different from everyone else. And so there's the sense of invention and you know building things and creating differentiation at the technical level, not just at the product and
 Marketing level and Sierra is the first experience I've had since then, where I feel like because AI is moving so fast and because we just have some of the most genius thinkers in the world and builders in the world, you have that feeling of were inventing new things. And I think the, what we call our agent SDK, which is the software layer that our agents are on
 Both the developer ergonomics and tooling and release cycle, and kind of the what we call the agent development lifecycle put into a product but also the software constructs and the agent architecture itself.
 Are just novel and inventive and flexible, and I think it's it's what I said. I'm I definitely feel a lot of just admiration for the team, but it's also being out on the experience. Curve ahead of some other companies. I think I just building with customers from the beginning, starting early in 2023 less than six months after chat, GPT came out and just getting reps with customers means that the abstractions that we have are a little bit less leaky a little bit more robust for all the different things that could come in at least, that's my theory and then I think we have the right sorry to ramble a little bit here, but I think we have the right layers of the stack where you have the platform but then you also have the flexibility of agent development. So, most of our agents at this point are being built in, no code, many of them are being built by our customers directly.
 But you still have that ability to express anything. You need by dropping down into code and kind of just interoperate between the two. And I think that's where you want to be working with the customers. We work with where their Business Leaders might have the best understanding of the goal. We're trying to achieve the metrics. We care about the standard operating procedures, but then you still need to connect to apis. You need your engineering team to get involved. Sometimes you need to drop down and do something with, you know, not your chef's knife, but your paring knife. And so this platform was just thought, fully architected by being so customer. Obsessed over the last two and a half years that, you know what, we have as a reward as a system that can handle scale in that way. Thinking about
 Three years ago when you started versus now, right? And how much you've had to reinvent or try and create new or try and like test out, and it's perpetual R&D in a way.
 I think that's exactly right. And if there's one thing that I feel like has helped me,
 You know, have more good ideas than I otherwise would have its spending those first nine months at the company, you know, working as an agent, product manager and agent engineer, and just being so close to customers, feeling their pain, you know, having to tell them directly face-to-face, when the agent did something, they weren't expecting getting to celebrate and go out to dinner. When it, you know, hit some business Target. Yeah, those those experiences are kind of, you know, in my neurons in a way that I feel like is just, I'm just so grateful for and I think anyone building a startup, the more you can kind of feel what your customers are feeling. The the more integrated, your decisions will be huge win, I remember a conversation. I was having with a buddy of mine who was saying
 look man.
 we have found the biggest lift on our AI systems from just Gathering the whole
 Floor of the company together, no matter what their job role is, and having a labeling party and getting a bunch of people, and we just get together and we look at the conversations that we've been having with the AI agent, the agent, and the user, like real conversations, and everyone just labels across like five metrics. Did it? Do this? Did it do this? What would you give it as a score and by the end of it, the business side of the house, understands the AI so much better.
 And they can say like oh yeah, okay I see what's going on here and then you catch all these anomalies that you probably. If it was only Engineers looking at it, they would have never caught because it would seem like yeah. That seems fine. But then you have the subject matter expert looking at it. And they're going, why? What? No we can't say this. We shouldn't be saying this. This doesn't make sense or it or sometimes it's just like this is stupid. No, right. So I I think about that and enabling the low code no code is almost like another way of doing that same thing.
 Yeah, that's exactly right. And I think what we've seen working with hundreds of customers now is when we bring together the business side and the technical side,
 I wouldn't say it's the only way you can get results, but it's certainly a heck of a lot easier. And it it's the only way you can get really like the best results because these two stakeholders are so involved. And we've done that enough times. Now where we have some of those repeatable processes to bring everyone in the room and make sure that all of the different viewpoints are represented.
 The other thing, this is kind of like a pinch. Me moment from working at Sierra, but I don't know if you're familiar with the book unreasonable hospitality.
 Yeah. Why have I heard of that though?
 I think.
 What? Yeah. Why do I know that it's not? It's not a Greek guy. That wrote it. Is it his name's will get Era. I'm not sure get all his actual Origins. He's from New York. He ran a restaurant called 11 Madison Park for a while which was yeah, they got, you know, they became the number one restaurant in the world is a spoiler alert like the five mission Lynn star where it's like, you could only get three, how do you have five, right? And it's, you know, this beautiful Ballroom environment in New York but was kind of a you know, pretty good middle of the road Bistro for a while and he just, you know, along with the team there took it to the next level in terms of service and hospitality. And he's one of our advisors at Sierra and helps a lot with our, how we think about tone and language. And so it popped into my head because what you're saying of like get the whole floor together and have an eval party or labeling party. We've also actually gotten to do that with him, where he'll come in to the
 Us and spend an hour. Just looking at conversations with us. And we say, you know, what, would a three Michelin star restaurant do in this scenario? Yeah. And of course, you know, sometimes they would do things that are not within the budget of our customers, but sometimes they would do things that are totally free. And so it allows us to think about aspirationally, how can we make an agent, where it feels like it understands you. The way, the person, the host, who greets you, when you go to 11 Madison Park or one of the best restaurants in the world and that kind of feeling of service. And I think that's one of the reasons why it's fun to work on is yes. There's the part of, you know, companies are hiding their phone number and we want to just bring it up to a baseline but then there's all so that part of how can we actually make the relationship that you have with your businesses that you know, good and great. And you know something that feels like you're going to a Michelin star restaurant. Yeah. Do you remember any of the
 things that he said like oh we could try this or maybe they would be that were the free ones, right? I do I do I remember it very vividly because one of the things that stood out kind of to your point actually is that even though he at that point hadn't had as much experience with our technology.
 He had such an intuition of what a good answer would be. And so I, you know, had this picture of, you know, I understand each part of the stack and that helps me throughout the stack. Yeah. But then, I would put him in this other category of just like Savant at the one thing that matters. And so we were reading through a number of voice conversations and listening to them and hearing for different tone and awkwardness and
 The ability to kind of just connect and and drop the barrier. And what actually stood out to me is there was one message and a long I think it was like a 45 minute conversation and there was one message where
 the agent sounded really empathetic and like, clearly connected with the user and we're going through each and being hypercritical.
 And I think on that one.
 you know, it was less of the, I'm so sorry that this is frustrating and more like
 Man, this sounds really tough. You know, like we've been working through this and we can't figure it out yet. And it was a very difficult, technical troubleshooting for like a basically banking, or like Financial Services application. So not an easy problem to solve,
 But what really stood out was that ability to just connect and be like, I hear you. I see where I see you like.
 Let's try and figure this out. Yeah. And the, you know, I would say I would give us, you know, maybe a constructively, like a B minus on the particular conversation that that we were reviewing, but in that particular message, it was like, that's what we want. And I think someone like will and and some of the people that have really good taste which is a one of the few like appreciating assets you know in the labor market right now. Maybe the that really good taste often comes out when you're like not necessarily criticizing all the bad things but being like that, that's what we want. And so I was really impressed with his ability to kind of put his finger on those moments. Those bright spots that we want to scale. So he tells you that. And then what do you do? How do you incorporate a lot of that in and away that it's not just like you're absolutely right? Right. So yes this is where the full stack understanding becomes relevant. Again classic there's a number of different ways you could do this.
 We've had success.
 Or I should say one of the ways we've had success actually in this particular case is with fine-tuning of models to phrase things in a certain way. The a lot of the base Foundation models have been trained primarily for chat
 Achieving AGI, doesn't really care if it's written or spoken. And so I think when you look at where the frontier labs are going, they're actually going sometimes in the opposite direction of a low latency conversational voice experience. Yeah. And so having a little bit of control at the model level for style can help a lot on that particular problem. Now, when we do have fine-tuning, if it's with data. You know, that's in any way. Derived from the particular customer, then it's a customer specific model and if it's more just you know, General tone and style, it can be useful across customers. But you also have to balance the fact that
 Anything that is being put in the weights, could be regurgitated. And so you have to make sure that there's nothing in those weights that any of the users, who would interact with those weights, wouldn't be able to see so the that process as you can imagine much more labor-intensive. And so it's really those specific circumstances like the style of voice, where it's very specific, very high leverage, very important, where it makes sense to kind of drop down to the weights. Most of the time, I would say the solutions come at a higher level in the agent architecture, or in some of the underlying task prompts or, you know, changing the model itself, those kinds of things. Yeah, it's only when will comes in for the day, right? Like that piece right there like shit. I guess we're gonna have to find two, right? And you want to make sure it's durable too. Because, you know, if like style is something that most brands don't want to change too often. Too markedly, whereas if you're fine tuning, this new promotional offer into your weights then two weeks.
 Later, when the promotion ends, your model is out of date. So the right tool for the job is definitely one of those things, we think a lot about this is probably a good segue Into The Ensemble of models and how you work with that. So, it's actually mind-blowing to look at one of the conversation traces, with the Sierra agent. If I, if the crsa agent says hello, how can I help you today? And I say something like, oh, you know, my, I'll try not to use Sirius XM. You know, my grocery weren't delivered and I'm not sure where they were, you know, what's going on here?
 Between me finishing talking and the agent responding, there might be 10, 15, 20 different models that get invoked. And some of them, you know, might be as simple as like an embedding model to do retrieval augmented generation. Some of them are Frontier models, maybe even with some reasoning tokens to make sure that we're able to handle a complex reasoning space. Some of them are fine-tuned fast but cheap classification models to just you know, understand the task at hand and it would be very slow to run these all in series. So sometimes there are certain models that need to return a token before the next model can start. But most of the time this is happening in parallel. And so I think what's really impressive is the ability of the agent architecture to break problems down into tasks, that can be handled by different models. And then selecting the right models for each of those tasks and doing it super quickly and we call
 That whole process kind of our our constellation of models that we use to respond to a message in a way. So it feels really simple, but I think, you know, my Google background showing underneath the iceberg. There's just a lot going on between when you type something in or when you say something and when you get a response,
 Okay. So this is wild, man. Tell me more about the way that you are. So you're doing everything async yes. Basically, you're Gathering, it's that same input data, right? But then it just
 Spurs out, and there's a bunch of different variants of it. And you do have dependencies on certain parts of these this output. Like, does it already know the taken path? Because I can't imagine that it would know. All right. Well I
 How do I, how does it know that I need the dependency in any? Like I don't understand this break it down for me more. So this is one of the reasons why I think voice is still an area where we're doing extremely interesting things from an engineering perspective and where we're still, you know, significantly ahead on a product perspective.
 And it's because latency is so important. So to give you an example, retrieval augmented generation, like if we need to access a knowledge base to answer a question, the agent will often make a decision to look up the knowledge before. It even knows or simultaneously while it's deciding, whether it would be a good idea to use the knowledge and so oftentimes, if you're just building something naively, you would think. Oh, should I go look that up? Okay, I'll go look that up now. I'll give you the answer but what an agent is doing because it's tokens are you know, more parallelizable and you know less expensive than ours. It's saying just in case I need to look something up. I'm going to go do that. Meanwhile, I'm going to use a smarter model to reason about whether it's an, even a good idea to have gone and looked that up, and then if I decide, yes, I should have looked it up then I already have the information but you're using that as like a tool. It's a tool called that gets invoked. Yes, conceptually, yeah. So the look up tool would be
 Running in parallel with a classifier to decide if the lookup tool, was even necessary. And then you already have the information and that's just very small microcosm but there's tons of speculative execution throughout the each agent turn. And then you kind of like, you know, and this is one of the reasons why like that was not a term. I was familiar with when I started working in Sierra but we have a number of people that have, you know, worked on building compilers and you know, very complex systems from scratch and kind of understand these concepts of software engineering, you know, our bread, our CEO was one of the principal authors of tornado, which is a one, I think, the first maybe still the most popular, like async driven python web server. And so we have this, you know, 20 30 years of software engineering history and conceptual understanding that was very new to me when I started but it's like a kid in a candy shop for someone who's just kind of a geek. Yeah that speculate I haven't heard that but it
 makes a lot of sense like it's better to
 Have it and not need it, right? And to need it and not have right? That's exactly right. And our agents are always thinking that exact same thought. And so then this is only for voice or this is for everything. Well, I don't think we would have been forced to build it this thoughtful if it weren't for voice but now everything is powered by this. Yeah. And
 You know, sometimes like email, you probably don't need this. Yeah. Right and you might just want to save the money on your little rag lookup and just wait, because a five-second email response versus a three-second. Email response is not a very big deal, but in voice five seconds and, you know, 1.5 seconds are very different and so you want to make sure that you're doing everything in parallel. Yeah. Because real time is, it's always been a hard problem in ml in general. I know that when it's whether it's like real-time fraud detection, or real-time recommended systems right now, real-time voice, it adds this level of complexity to an already complex thing we were talking about how complex the voices and that like Rich medium, right? But how we all have our own ways of talking and now
 To add on to that.
 This whole piece of we need to make sure that we're getting the right information at the right time. Am I thinking about this correctly with decision, tree type of thing? Like that style? I think conceptually if a decision tree would be useful to a human, then it might be a useful concept to one of our agents. Similarly, if they standard operating procedure would be useful to human, it might be a useful concept, but the ways that our agents are architected is probably more similar to how you, and I would learn.
 How to complete a task or how to help someone with a task, then sort of a decision tree in the sense of traditional software and some of the Legacy chatbot systems. So it's useful Concept in that it models a flow that you might want to follow, but a lot of times, I think our agents are more correctly described as kind of goals and guardrails where you say,
 You know, the goal right now is to help the agent. Reset their radio or help them make a payment and you mentioned, fraud detection and recommender systems. As other things were real-time matters because there's often money involved and like click through rates matter, a lot and conversion matters, a lot and that's true for a lot of voice conversations as well.
 so for example, if you're
 You know, thinking about, whether you want to maintain your subscription to a streaming service, or whether you'd like to cancel, and the agent can make you an offer for a 50% reduction for three months, but they take too long, thinking it over. It starts to get frustrating and you're like, you know what, I just want to cancel. So these things matter a lot. And so the goal might be, hey, you want to, you know, save the customer from canceling but some of the guardrails there might be around the types of offers that you're allowed to provide and the experience that the customer should have and you know, making sure you're telling the truth and only the truth and all that stuff. And so
 You know, decision tree flow, diagram Etc. These are all useful concepts for just thinking about operations. The one that I think is the most aligned with our architecture is probably this goals and guardrails. Yeah. Architecture. And it does make sense now,
 The constellation metaphor in a way, it's like a web of different models and different ways as opposed to some straight path. That you take a decision. Tree on this is gonna go, you know, to the side, I won't say, it'll go over people's head with the side but I think like there's kind of the model of the atom, where you have energy levels for each electron. And then there's the electron cloud and it is useful to understand, energy levels and think about when light hits Adams, how electrons will change energy levels? But it is more accurate to think about the electron cloud. And so that what you sort of model with the web is probably more accurate, but decision trees and flow. Diagrams are still potentially useful constructs to think about how an agent should behave and then we go back to the heat Maps. Yeah, that makes a ton more sense of why those are so important. You have this web. That's so intertwined and you want to know where
 Things are going wrong and you're trying to debug that could quickly turn into a nightmare. That's right. And, you know, ultimate expression of that, is just the llm itself where, you know, there's some interesting research around model introspection, but in general most developers don't know how llms made the decisions they made. And so what we've had to do is build a system where, you know exactly why a decision was made and you can fix it without, you know, you can plug this hole without juice squirting out the other side. And so that's, I think, you know, the sort of Special Sauce not to extend the juice metaphor too far, is kind of being able to have both at the same time. So with no coding code,
 How do those two mix and match? So when Sierra started, you're primarily a platform and most of the agents were built by employees of Sierra in collaboration with our customers. And as we've scaled, we've found that a lot of these Concepts because we understand them from doing them, hundreds of times can be abstracted and actually implemented through no code tools as well. And so you know within the last six months I'll call it most of our agents are now being billed in no code.
 But it is, you know, the fancy word I've learned in the last few months is isomorphic with the code, so you can go. It's never a one-way door to choose to use code or choose to use, no code. And what this means is someone from a customer service organization at one of our customer, companies can go and build a journey themselves, and then they can say, oh, it would be nice for this particular tool to have it implemented in code because it actually needs to use an API in the specific way with streaming. And I just don't want to go through the process of, you know, wiring that up in. No code. It will be much more idiomatic to just have my engineer, right? That thing, and it will integrate these folks are when you say tool, like, we're talking,
 A tool called for the agent or we're talking like oh this tool this program that I'm used to using as a tool call for the agent. Okay. There might also be areas where you you know most of this you at this point you can set up with no code but a situation where you might have an integration and you already have built that integration out in code. But you want to store the metadata, you know, through like environment variables basically. And so what's happened over the last six months is this has gotten gone from being mostly something. You do with our team, to mostly something that our customers do on their own, with the support of our team. And so, we still have that kind of high touch consultative, highly accountable model because we think it's just effective, but we also offer the control and customizability that you mentioned at the beginning where it's just like, here's the product, go for it. And so, we've landed on kind of The Best of Both Worlds, where you can build an agent yourself, you can use our no code.
 Platform. You can also use our code platform as well, and you can use the two together, and it's kind of like the product ties instantiation of what you said, which is when the customer experience or the business org and the technology org are working so well together, we just try to like make that a product instead, you know, having seen it, work so well as a process. And so that's another thing where I think that technical depth and understanding
 Of the code was necessary to make the no code project or product so robust and extensible. Yeah. Because if you
 Try to start talking to the business side of the house about like, oh yeah, our evals are failing here or right? Like there's a certain level that they just don't care, right? And so I imagine you're abstracting a lot of things away from
 that type of user with the no code part. And you're allowing the
 Software developer if they want to figure out like, oh let's go write a tool or let's figure out how to make this work, in whatever way with this API, then they can do that. But for the most part you're like, yeah, yes. I just care about like, can I have it do this? Here's the, what did you call? It goes and guardrails. Yes, here's the goal, here's the guardrails. That's all I want to give you right.
 Yeah, it's exactly right and we work with companies that have, you know, very robust, change management processes and they have their own concept of releases or continuous integration and deployment. And so being able to fit into that on the code side while also fitting into the quality assurance and review, oftentimes which involves, you know, large teams doing review, filing issues, making improvements has been a huge accelerator for the business because oftentimes, you know, when we were mostly a developer platform, we had companies, we would sell to where they're like, hey, we really want our operations team to own this, and we love your product, but
 Just can't get on board with that over the last six months. Now that we have, you know, equally good product for operations and CX teams that we have for developers. We've seen it be much more of a, you know two thumbs up from all parts of the organization.
 The amount of reviews that you need to have and the amount of like meetings that you have to align on. Yeah. Somebody told me the other day, they were like, man.
 Launch a model with one click, right? Like one, click deploy, and like you get laughed out of the room in the Enterprise if you have that because the one click part is not the hard part like it's all those meetings and all that alignment and all the reviews with the regular or the lawyers in the everybody that you have to talk with beforehand.
 Before you get to the click, right? The hard part, right? And the business side as well, usually has the outcome in mind that we're trying to drive here. And so having them on board integrating with their change management. Processes is actually huge accelerator for the deployment in a lot of cases where I believe you can say, oh, things are moving, so slowly, it's taking us months and months, but when you're actually on board with them, you get that same Force but in the other direction. And so we've had customers like you know, one of the 10, largest businesses in the United States, we went from the you know, basically first meeting with them to live in about three months.
 I think that's a good place to end.
 Demetrius. Thanks so much for having me. Yeah.
 a one thing I didn't have on the list is
 our, we just launched we just announced year two of our apx program, which is our program for new grads, kind of combines engineering product management and Entrepreneurship. That's pretty fun. So, I helped kind of conceive of that program and get it off the ground. And we have five people in the first year.
 They're amazing. So we're doubling down on it for the second thing. They stayed at the company. So yeah, yeah. They're they're like three months in and so, one year program, okay, we had it as 18 months and then things were moving so fast that we were just like,
 okay, this can only be 12 months.
 Way dude. Wait. So this is somebody that got kind of gets to like parachute into meetings and is now know they're like a full-time. The way it works is six months of product management, six months of engineering. Half the apx is start on one half, start on the other and then they kind of flip and you're working directly with customers building agents. And then you have kind of some very large customers that you're working with, where you're filling that role as well as some smaller customers, where you're kind of the end-to-end entrepreneur doing all, the coding customer management product management and it's a really good group, I think, because it's so multidisciplinary, it attracted a lot of people that want to be Founders and that are just awesome. Yeah. And you get the jobs, you get to learn. Well, you're doing it. Yeah. How did you think of that
 Um, so our two co-founders, Brett and Clay were in the first and third class of Google's APM program back in like 2002 or 2003. Yeah, it didn't Brett. Create something with Gmail or some, some, I think it's co-founder created Gmail at a previous startup and he co-created Google Maps. That's it. Yeah, Maps. He was. Yeah, the one with maps, right. There's the he's holding on enough podcast. I probably don't need to because everyone asked him, but basically rewrote the whole front end which was the, I guess. Complicated part in a weekend after lots of different Explorations and I think is proud of the, you know, reduction in the binary size that they got out of that nice. So then you saw that they did it and you were like why don't we do that? So it's so bright and Clay were class one and class. Three. And just remember, it really fondly and then I actually started my career at Google too about 10 years later.
 Are also in the same program. Oh really. And we have 10 or 11 people in Sierra who started as apms at Google. So we had a lot of appreciation for that program, a lot of excitement. But then we also wanted to kind of reimagine it in the era of AI, where you can be a bit more of a generalist. You want to be super technical, but you also want to put your product hat on and think. And we thought about what are some of the most successful people in these roles its future entrepreneurs that are going to go, you know, start their own company to four five, ten years from now in Clay's case, 18 years from now. Yeah, and so we wanted to create a program that we thought kind of honored both of those influences. And that's why we have kind of apx, it's kind of just the multi-disciplinary intersection of a lot of different things. A lot of times you get,
 Entrepreneurial.
 Folks that have so much ownership.
 That they like, have a lot of opinion on how things should be done, and then I've heard from friends who have not necessarily the same type of program. Yeah, the similar things really like oh we want like an entrepreneur type to come but then after they have them for a while they're like actually we don't want you to run the company. So do you see like how do you battle with that kind of, oh the extreme ownership and I want to do it my way and I'm very opinionated, and this is how we need to do it because that entrepreneurial Spirit versus like, hey, but we're all. So we have the boss already. You you're not the boss.
 I think there are two things that stand out a lot. One is kind of creating the systems and conditions where people can have that level of autonomy and ownership. It works pretty well at Sierra because as an Enterprise company, we're working with a number of different customers. And so, the each agent is kind of a place where you can have that autonomy and ownership and customer relationship building and user researching. And so I feel like there's kind of a wouldn't call it a Sandbox because it's in production but there's a place where you can really, you know where autonomy is working as intended. Yeah. And then I think the other big piece is just having great leadership in the company where even if you yourself feel like a leader or someone with strong opinions, you have a level of respect for the direction of the company that thought that goes into it and kind of certainly in my case. And I think in each of the Apex is case view, our Founders view, some of our early employees as role models that you kind of want to model yourself off of
 Which takes the edge off of kind of, you know, being more stubborn, and those kinds of things. Because if you're objective about it, you know that you also need help need to listen to people. Yeah, that point in your career, I would hope. Yeah. Yeah. I think,
 The humility especially with respect to customers and also, with respect to some people who have done it a few times before, that was a big reason. I decided to start my career at a big company, you know, Google's full of some of the smartest people and you can find the right people that you want to learn from. Yeah, and I think one of the cool things about Sierra is you have the pace and size of a startup. But you also have the experience and accomplishments and wisdom of, you know, if you were to take the people that you'd like to work with at a company like Google and so, that's been really fun. Yeah, and higher percent. Let likelihood of when you do get a mentor, it's a good one because if there's a lot of people, there's also a probably a bigger spectrum of what you can hit. Exactly. Yeah. You have to be selective in a large organization here. You probably will get lucky. Yeah. Well. All right, let's, let's talk a little bit about this is a good night by the way. Yeah, I think it.
 Keep talking. Yeah. Can you hear me? Yeah, I think it's perfect. Okay, all right.