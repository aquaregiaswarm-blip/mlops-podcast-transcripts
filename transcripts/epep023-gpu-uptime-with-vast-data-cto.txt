A lot of times people started on a laptop and then the farthest they get before they go and ask infrastructure people for help is they put it on a desktop machine underneath their desk, that's as far as they get, and they're like, but how come I can buy this for at Best? Buy for $500? And you're telling me it's gonna take 10,000 dollars out of my budget to manage the support that. Yeah.
 Because the average person now has a sense on what AI could possibly do. The expectations are so much higher now yeah, why does it take so long to do this thing? That if I would ask you three years ago it would have taken months. I expected now immediately. Look at what it's possible.
 With generative AI now just because everyone with a phone in their pocket can experience it. An average person can experience it, right? So it's a it's sets, the bar a lot higher for how people have to, or I'm sorry to how the the people who are offering services to the higher layers and the app developers. Now, they're expected to be able to Vibe code something in a weekend.
 What might have taken them weeks and weeks and weeks just to prototype and get to a place where they can show somebody something. The expectation now is that you could do it overnight and iterate on it quickly enough that you could have it to where it needs to be in a very short time span. And in some cases, it's true. But, you know, even even just pet projects that I work on. I might get it to a demo stage in a weekend, but there's so many edge cases, Corner cases data is very messy and I think that's like, one of the challenges that we see people struggling with in, like the space of customers and clients. That my organization deals with a lot of times, they move a lot more slowly. We have actually a couple different breeds. I would say of client. There's some who are sort of Leading Edge and a lot of times, the model Builders are thought to be Leading Edge. They are in some ways, but they also have to manage billions of dollars of infrastructure and there aren't that many people in the planet who know how to do.
 That and most of them are older. Now like it's not like the kids coming out of college, are not figuring out how to go and manage a 10,000 or 100,000 GPU cluster. It's a lot of responsibility.
 If you can mess up really bad. Well and mess ups are so expensive. Like we there's one one of the people that we talked with has a they manage a large gpu-based farm.
 And they measure everything in terms of minutes of GPU downtime, and it's always millions of minutes because they have lots of gpus. So, if they have an issue, whether it's during a training run or whether they're sort of doing pre-training processing or doing anything, if there's a hiccup, like if somebody fat fingered a file and they deployed it and it takes everything down for five minutes, ten minutes you multiply that by the number of gpus and that's the number of GPU minutes and there's a actual cost associated with that.
 A very big cost. If you're talking hundreds of 1000 gpus, you're giving me anxiety just by thinking about that. Well, then you multiply it by depending on the cards or buying its 30 grand a card, and you pack a bunch of those into a machine. And now, it's like, oh God, but I want to go back to something that you mentioned where it's like, the expectation of me, being able to Vibe, code something over a weekend and then I can show that to someone. It's a little bit parallel to what you were talking about earlier, with me, being able to develop something locally and maybe it is in the predictive ml days. It's me developing a model locally and then going and bringing it to the team and saying, let's deploy this. And the platform team is sitting there like, wait, what? And the person who developed it? It's like, yeah, this cost me, you know, a few hours and a couple hundred bucks. Yeah, my laptop. Yeah. Why are you telling me? It's about to be
 10 grand if I need to deploy it. Yeah I think the realization it's actually not so dissimilar from researchers who were sort of building scientific experiments and coming up with hypotheses in a small setting with a small amount of data. I think when you expand the amount of data,
 It's not just a matter of having to process more. It's that the amount of variety that's in that data is going to get larger and larger, and it, it isn't so easy to manage. And so, the, well, the other one that it's oftentimes surprises me is people don't think about parallelism when they start. They're not thinking about how is this going to scale? In terms of the, the processing that I'm doing? Can I shart it across multiple instances of database, multiple instances of storage, multiple instances of GPU? In my thinking about how much memory I have to move back and forth between machines because ultimately and, and so, so our engineering team builds, you know, parallel systems but the every time it's funny every time we get a new client, the first thing that happens is they complain about how slow it is because if you buy something new it's that's what you do. Like all right I want it to be faster and usually it's because what you're doing is a little different or you're not used to
 How to use it or whatever. But if we find issues on our side, it's oftentimes because there's a bottleneck in either a piece of code, or how we're starting something we thought, oh, we never thought about sharding it in this way and this granularity because it's hard to. It's hard to think. In terms of parallel programming. It's hard to implement something that can scale as a programming scales. But oftentimes the
 I don't know if it's the platform Services team or the data architecture team. At a lot of these research institutions, they'll take what the scientists like part of their job, besides sort of managing infrastructure and making sure that they have services available is to help the end user developers. Scientists researchers, whoever it is to help them understand, okay. How do I get the most out of what I'm using? Yeah, because if you run a job, let's if you have 10,000 gpus, your disposal, but everything, you're running ends up bottlenecking on one. Then what's the point? Why not 10,000.
 So that's like a and I don't think you see that until you have scale. Like if I if I can fit on my laptop or even on a few relatively large servers, I'm not, you know, I'm not spending my energy thinking about late and see in that way. I'm thinking about either time to First token or time to something on a very much on a much smaller scale. Maybe I'm not thinking about how many thousand users I can support simultaneously. Maybe I'm not thinking about sort of how in routing if you're building something with Asians, how you're routing things to make sure that you're spreading your load appropriately.
 And, and then we have to start thinking about costs. Like, I think a lot about
 Model routing in terms of choosing the right cost-based model associated with, you know, what, what needs to be done. And that's I mean because at first it's kind of an experiment, like a thought experiment. Let's think about it. Oh let's answer the simple questions with a cheap model. And if it doesn't pass a test or if the re-rank or so does not good in waterfall, it, that's somewhere else. And so you think about that sort of hypothetically, but then, when it actually starts happening, the and this is where when people deploy in, let's say, you know, a cloud provider where they're renting by the hour, that's where you start noticing the cost escalations happen in very unpredictable ways because now you're using these more expensive resources, much more than you thought you were. So
 It's it's like the unknown unknown.
 Of technical debt. Yeah, you don't recognize it yet because you haven't even realized that you're going to hit this Crossroads at some point when you get to a certain scale that you now need to be thinking about these things. But you're so oblivious to it that like, yeah, okay, we're just gonna do it and bring, you may know, or have an inkling that you're bringing on technical debt. But then, when you really go to play at scale, your your platform team comes to you and says, you know, maybe we should be sharing this. Yeah, yeah, technical. That's an interesting one like
 I'd love to say that we have an accumulated, any of course say that with a half straight face. Um, I think that
 You know what makes me excited about more development teams using AI for their day-to-day work? Isn't necessarily that they'll become more productive. It's that like the tasks that that usually are really boring are ones that we could probably find a way for them, not to have to do, right? I can take a senior developer and set of having them go and spend their time refactoring and going in and documenting their code, they can spend their time talking either to end users or to someone Upstream, to understand the requirements better, because ultimately, it doesn't matter if you're building agents here, you're just building like a basic application. There's never a fit at first
 for the user Community. There's a fit for you and your minds, right? Like, oh, this is exactly what I think it should do but whether you're trying to sell something or whether you're trying to provide a service, the requirements Gathering is such a huge part of it and like, I try to get my team and the rest of the people on sort of tangential teams to focus more energy, up front on getting as many requirements as possible. We have like, a lot of Engineers who want to go show off the thing they made like, that's great, you should show it off. But if you're gonna spend 30 or 45 minutes showing something off want to eat shave off, like 20 minutes of that, and just sit there and say,
 What would you want it to do? But get in like the actual details. Don't don't spend time up here because like they'll just tell you what you want to hear. If you're up here you have to get down to the level where you ask them, what ifs you think about worst case scenarios. You think about all these choices? Because once you hit the Go Button,
 if it doesn't work like to bring it back. Yeah, you got a mom test them. Oh, have you heard that book or have you read that I've heard of it. I haven't read it. No, you got to give all your engineers that book. That is the quintessential. Like when you were building something you want to ask in a way that isn't giving these leading questions. Like, hey, would it be cool if we had XYZ? Yeah. Instead, it's like, have you ever felt any pain around doing this interest, okay. And then, and there's a signal there if they say that. And then a lot of people might say, yeah, I felt that pain but they haven't and so you can ask questions like, so, have you Googled how to fix that pain? Hmm. And if they've Googled about it and they've said you, like, when you really hit a nerve is when people are like, oh I'm in this, you know, online Forum. I'm in this community. That's all about that. Or I Googled it and I found this or that, whatever it may be. There's a very clear signal when somebody really has
 Pain around some that hasn't been solved. Yeah, that's a good point. I probably take, I, I probably do something similar, I just haven't thought it through. And that in that way, I have often times a skeptic or pessimist side of me that, like, I don't try to expose it in that way, but I never liked it when I showed something as someone, and they like it. Yeah, I want them to say what's wrong with it. It's so hard though because people, you like, when we're looking at it for someone to be able, to be honest to you like that. It's almost like, I feel like I'm gonna hurt your feelings if I tell you the truth, right? Well, I think that's a vulnerability piece there. Like, I feel like if, if we are cells become vulnerable and someone's presence it, it's not like, it gives them permission to become vulnerable, but it gives them the sense that they could probably all. So start sharing more about what, what they actually feel. This is a safe space. Yeah, we can. Yeah, let you. Yeah, I can see that I do.
 Think you inadvertently are putting a lot of pressure on someone to give you that if you show them what you build because they know that you've put in time and hours and so it's almost like, yeah, cool. This is great. I get a yeah. And so that I don't want to tear down what you build. Usually the way that it manifests in me is all say something like
 Oh yeah. And could you do this or could you do that? What about if it was like this and yeah, yeah. It's it's it's a
 it's fun. I actually enjoy having conversations with people have different personalities because it helps me understand a bit more because ultimately,
 People who are building applications agents, anything that's being built. Ultimately it's because somebody wants it. And and somebody is still a person.
 So far, right? And so because of that like there's not there's not one kind of person. We're not all machines. Yeah. Or I was gonna say you can just
 Have only people giving you feedback that are Dutch, they'll give you the straight and narrow they don't care about it. They're very direct on their feedback and I think you'll be fine. Then you get to know Dutch feedback. Go get a Holland and ask people what they think. Yeah, let me give you this quick demo. But I also want to touch on the idea that you lost over a little bit of the boring stuff. Hmm. And how, that's really where a lot of value can be brought because nobody likes doing the boring stuff. I also think it's boring because it's kind of hard.
 Um, I even think about impersonal life, the stuff that I set aside because I say, oh, it's boring or it's not interesting or it doesn't solve a big enough problem for me right now. It's this kind of it. You could think of it, even as technical debt in some way.
 And I think something like like if you're if you're working on a problem or if you have a new idea and you want to create something at least for me, I like to think about, okay, what do I what do I want to make? And I'm gonna Focus all of my energy around what I want. I'm not gonna and and if something gets in my way a little bit, along the way, I'm going to just find a way to move around it and keep moving along until I get to the place that I want to go.
 But that doesn't really help when it's time for other people to use it or other people to interface with it because all of those things that I went through, they're probably gonna have to go through it too. And so when I think about the boring stuff I think about like you start on your laptop building something and then it's time to go deploy it for real. So then your platform team has to go and think through all the things that you didn't want to think about anyone. Think about any of those that I don't want to think about starting or scaling. I don't want to think about the server crashes.
 When does that happen? That happens.
 Right like, especially if you come from a mindset where you've been deploying into the cloud unless you're cheap. And we're only using spot instances and you had to think about that, right? If you were deploying somewhere, where all that stuff is taken care of for you at a small scale and when you want to go and do it for real, someone has to think through those things. What happens when a server fails? What happens when a link fails between two different locations? What happens if your user has a slow connection and they don't you can't send back to them quickly enough you thought about timeouts? Have you thought about all of those boring things that end up like killing an application and killing a user experience? Have you
 done much work on like chaos engineering. So, you know, you're like the third person in a week, know that up in a way because it sounds very similar this idea of how can we think about the ways that it fails? Well, let's just like chaos. And just so, so, yeah, there is a client that we're talking with who wants to go deploy large scale systems and they asked me this question. If we do that regularly and we do but not on purpose. We
 You know, we have to build large systems to test, right? I don't have millions of gpus but I have lots of stuff that can simulate it. I don't have millions of servers but I can have potentially hundreds or tens of thousands of servers for a period of time to go and do things with and
 Because because Hardware, because data center space, because bandwidth, because all of the things that are physical are finite, we end up having to shuffle things around a lot because one team wants to go and build an app. And we say, well, you're gonna have to wait until Monday at midnight, UK time and then you have access for four days, then you got to give it back and that process of turning it over, and giving it back means that I'm going to call you up and say, okay, it's been four days. You're like, oh, I'm almost done, we're taking it. And so then we have to shuffle everything around and then everybody's scrambling to figure out. How do I, how do I make sure that like think about it in the terms of, like checkpoint restores? Right. How do I make sure everything that I'm doing is ready for that last moment. Notice where I wasn't planning on it,
 That's yeah. You want to squeeze as much juice as possible out of it? Yeah. And I think so, so chaos, engineering, I'm there are QA teams within our organizations who do things like that. We have some people, I wouldn't call them black box testers, but they're people who are less familiar with how our systems work that do dumb things and that's just their job. They are the chaos monkey, right? They're like, well, how come I can't do that well, because you just don't do that. No one ever do that, but I did it right? What a great job.
 Yeah, but then they got to file the bug reports. Like, what did you do? Oh, I don't know what I did. Write it all down. Like, I I and the thing is, like, I I'm so I'm so resistant to like documenting bugs, foliage, just like to write. I, I click this button. It did this thing, I didn't like it, or it failed, or give me the stupid are and okay. So we're the logs. What should be pretty reproduction, step? How many times did you reproduce it? I'm like, oh, come on, guys. Can't you just like, can't you do that? You figure that out like a perfect use of AI. It actually is, um, and I think, at first, a lot of the community on our side was a little resistant and there's probably more than one reason for that. Some of them are a little bit older and so like there was a trust issue. It's funny. So 12 or 13 people on my team and probably if they end up watching this, they're going to get mad at me or whatever, but because I forgot how many other were. Yeah. But but there are some who are
 Super forward looking in terms of using AI for as much as they possibly can all the time and they're super eager and they're out there with it. Sometimes I have to look at them with a skeptical and say maybe you're leaning a little too heavy. It's okay. Like I'm not gonna stop you but I'm just like you know, there is like a reality that we're also trying to work on and then there's others who are so skeptical that I asked them I have a thing. I'm like, kind of a jerk of a manager sometimes I'm like every time I have a one-on-one, I'm like, so show me something new. You did with AI this week that you didn't think of doing last night, right? Whatever it is. I don't even care. It could be personal. Like I use, I took a picture of something and asked you to
 Figure out what it was right. Whatever it doesn't even matter what it is. Um and like I think because I'm just trying to get people not necessarily use it all in for everything that they do. But just to think about it outside the context of what they hear about. Just just every time I have some kind of thing that I don't feel like doing. I'm like let me just try this, right? But I do think it does take dedicated time because if you just try stuff and it doesn't work the first time, that doesn't mean that it's bad. Like, in my opinion it means you just didn't construct what you were doing and develop your requirements. Well enough for you asked to do something. I actually gave a talk on this recently and how that is such a bad ux when we see that something doesn't work, but we have no feedback on. Was it? Because our problem wasn't good enough for us because it's actually not possible. Yeah, and we don't have any Clarity on that. Mmm, I had, I flew over here from Portland a couple days ago and they didn't it. They decided not to have
 Wi-Fi on the plane. They didn't tell me. Until after the plane took off, like, I couldn't text anybody and let them know. And like, sometimes I like to just zone out and not work on the plane, but sometimes I kind of need to. Yeah. Right. But I thought was funny. I don't know like what your opinion on this is if I have internet access. I see how slack on your screen. Slack is probably where I spend like 80% of my time. Know, um, if I don't have internet,
 For the first bit of time I get I get a little nervous and frustrated but then I spent the rest of the plane besides I watched some silly movie or whatever, but then the rest of the time I spent just really thinking through something that like we as a team need to get done and creating a prompt to try and create a flow to do it. And if I would have had internet access when I was trying to do it, I probably would have gotten really lazy about it. Yeah. Right. I wouldn't have thought all the way through as much as I possibly could because I had instant access to like you know, one thing or another and I'd say oh I'll just ask him to tell me what I should do right 100% and actually that was one of the things, one of the product.
 Things that been Young Who I interviewed from Source, crafts said that, they took a stance on, with their coating agent. Was that when you hit enter, it doesn't submit it because he was like, we want to subtly, tell people to like keep going on their prompt and so you have to do this shift enter for it to actually get submitted
 That's interesting because there are oftentimes we're all hit the enter button whether it's like in cursor or whether it's even just using it like a chatbot.
 And I immediately go. Oh man. Maybe I should have changed. What? I said, I'm too lazy to stop button sometimes not every time. Yeah, I am the same way. It's like, well, let's just maybe it works. It's close enough. Yeah. Maybe I don't have to try that hard. Yeah, it's yeah, that's a funny one on how much you got to work at it but again like I think there's another thing with the
 What did I want to say around? The boring data. Yeah, and how and and the messy data and how I think
 before we were talking about how you
 Really can't understand until you've lived it. Hmm, the messiness of data and Enterprises and just big companies. Yeah, there's there's whole Industries built around cleaning data.
 But then ultimately cleaning data, just puts it into a form and someone some persons deciding what that form is. Yeah. And that doesn't mean that it's clean for the next person who comes along right? And, you know, now a lot of times we're we're telling people, we're being trained, I guess you could say to keep as much as possible because you don't know when you're going to need it next. And there's this feeling, like, if you don't have it and you, especially when I talk with organizations that aren't
 Accustomed to being data-driven organizations ones who are in manufacturing or ones who are in retail or even in finance where the product that they sold wasn't data. But now that there is an increasing realization that data itself has value to it. There's this thing increasing desire to keep more and more of it, but it doesn't mean that they know how to how to store it. Affectively, it doesn't mean they know what formats to put it in. Again, there's this expectation level that. Oh, if we dump it somewhere, there's going to be some magic easy way to just extract value out of it later. When I don't think about it that much right. What a disaster? Well yeah. But I still have this. Hope in the back of my mind there's going to be this amazing thing. That's going to come along somebody the other day. The other day is probably months ago. They we were talking about how
 You know, a lot of organizations can only extract value out of like this very small percentage of the day and they have, right? They could have, they could have documents, they could have 100s of millions of documents going back decades.
 And they're really only extracting value from like a very small percentage of it. And then, you know, the, the sort of CounterPoint to saying, oh, well they need to extract more is like look like it's just like, in his case, he was saying, drilling for oil, there's oil that you can drill for this really easy. And so until oil gets so expensive, that you're gonna go spend the time and energy to go after the hard stuff, you're not gonna bother and even the model. Builders are kind of thinking in the same way because they think, well, you know, the tech our techniques will get better over time. And so what why bother going too deep, right? A lot of a lot of the big models basically trained on calm and crawl data for well, I mean they still do but that was one of their primary sources of data for the first bit of time and that's easy to get. And depending on which sort of export of it that you use, It's relatively clean like the news. Feeds are relatively clean and duplicated, and all this other stuff. And so it's easier to deal with the easy stuff first and the hard stuff later.
 Later and I think Enterprise organizations like if you think about like when we talk about financial services companies I'm not talking about the ones who are sort of Leading Edge in terms of how they're using AI or creating AI first practices. I'm thinking about the ones who've been a bank that's been around for 100 years. They have they have a challenge with regulation also. But extracting value out of that data is it's it's going to be affort for them. But the thing is, they have so much of it and they, and especially the retail banking World. They have so much about people's transactional history, and their buying patterns, they have something of value. They just
 You know, a lot of work, a lot of work and the techniques haven't necessarily caught up to the, to the difficulty that it takes. So I think it's about finding like a middle ground. In terms of saying, you know, we want to get, we want to be able to understand our clients better, we want to be able to have a data product, we could sell to somebody, but let's not just over. Let's not over hype ourselves and thinking that we could take our whatever 100 petabytes of data in a cold archives somewhere NBA to offer some service on top of that, that's ridiculous.
 It it reminds me of the whole big data is dead movement and I think it was the mother duck guys. That that made that big. Yeah because it's like the majority of this stuff that we're using is not big data. We may have big data but what we're actually using is very small data and so how can we I you're building on that by saying because small data is pretty good for what we need right now and figuring out how to use that big data in a way that's going to be.
 More valuable than what we're getting from the small data. That's easy and quick. Yeah, it's a lot of squeezing for the juice. Yeah, I think there is a I went to like I went and shifted
 Sort of companies a while ago and switched over to one of the hoodie distributions back when he was the big great thing. Right. And I think, I think that most of the people that I interacted with, were dbas who were trying to pad their resume with some new skill set, and there was a lot of Hope.
 There's a lot of Hope for all of these, this ecosystem of tools that we're going to basically change the way that data warehouses operated and changed the way that organizations looked at data. I wouldn't say that it didn't live up at all to its promises. I think there was a lot of transformational change that happens but it definitely wasn't the thing that solved data problems and that's why I don't really see Hadoop as it was as something that organizations are continuing to want to Foster. They're looking at other ways of managing data. I think that like databricks for example, did a really good job kind of coming in at the right time and coming up with the way to basically take the idea is behind the Big Data movements and then apply them in a more practical way to things that people are actually using right and it, you know, they I interacted with them a lot back when they were they were just a training organization. If you go back what, like 10 years, they train people on how to use spark and at
 Time I saw. How is that a business? Like in? I don't know if you ever went to any of their sessions but those were probably the like they, they're high level 101. Sessions were like, deep, Scala and Java development as like the one-on-one intro to spark. And so I'm like, okay so there's a really high bar to getting into this. I thought, okay, I don't know how this is the business but as they got more and more developers in the camp of spark, they realize that we can offer. Well okay. They probably already knew this all along but they started offering a service and I think in a lot of ways, they developed really good ecosystem around it.
 We came at things from a slightly different angle, which was we started with problems that were hard to solve for the research Community. When I say research, I think about a lot of the sort of government-funded labs. I think about, you know, sort of Institutions that their job is to basically process large amounts of data either for experimentation purposes or for drug Discovery or for something, right? And so they had challenges around processing, large amounts of data. So we didn't start, We Didn't Start by trying to to create Frameworks for them. We started by sort of being the backend lower layer and then as we start to move up the stack, more and more. Now we look for what the Frameworks are. Like, I don't want to, I don't want to tie myself completely to spark because they're all, there will be transition there. I don't want to time myself, completely to sequel, even because while that might have been the way that everybody interfaces with structured data,
 I think that is it necessarily the way that people will in the future. And so like I want to make sure that the lower layers are solid enough that anything we put on top is going to be easy to do, but I also want to keep looking for what the next sort of way of looking at Large Scale, data processing is and my mind always goes to like what are the parallel Frameworks that are emerging, right? Well it goes back to that.
 The platform engineer is now going to have to have the data scientists or the researcher as their customer. Yeah. And they are going to come with requests and requirements continuously and so the platform engineer is going to want to provision those requests and be able to offer them quickly, to whoever their customer is. So how can you make sure that you have a plethora of different
 Ways to offer whatever it is they need. Oh all of a sudden, it's not pandas, it's polars. Cool, we got that too. Yeah, yeah. And I think the well I think to me it feels like the the skill sets of all the people who are focused on infrastructure platform engineering data services, like
 It's kind of like the same analogy I made earlier where I want to look to developers to get closer to their end users to understand the requirements better.
 And the only way to do that is to make it so that the things that they used to spend most of their time on, they don't have to really spend their time on it like a platform engineer. Shouldn't have to figure out how to provision a kubernetes cluster. It should just be like, there should just be a playbook for that. They shouldn't have to figure out how to manage the networking components in between everything because really what they want to offer as a service. They don't want to offer metal or containers or any of that they want to offer a service and but to offer the right service, they need to make sure that the layers that they are responsible for are either. I wouldn't say self managed are managed in a way that makes us think and spend more of their time interfacing with their customer. Whether that's a data scientist, whether that's a data engineer. It depends on where they sort of see themselves in that in that world.
 and it's a good time for everybody to think about, well,
 You know, like, you know, because I I've dealt with like, classic it people for forever and a lot of times there's the grumpy people, right? The people who they get a ticket and they just go crap, this person wants something again. Now, what do I have to do? But really to kind of get ourselves further in our careers or in like, you know what we're doing and fulfilling ourselves with, it's really more about figuring out. Well, what could I do? Better for them so that when I get a request from them like it's not that it's easy for me to fulfill but I understand them. Well enough now I understand what their mindset is. So it isn't like I'm on the other side of a fence.
 And really what I try to do whenever I meet with people who you sit on one side of the fence, the other is well, how can we get both sides? A little bit closer to each other? How can I talk to the data scientists and data, engineering teams and help them understand that you should think about what the infrastructure and the platform looks like because it'll help you do your job better. And then on the platform side, you should understand why they're doing what they're doing, not just what they're asking you for, but why do they want that? Because sometimes a platform engineer says, they might be able to say, well, wait a minute, your real goal is this, you're asking me for that? I think I could probably give you something else that's going to help you to do it better.
 Because this person is not an expert of their their realm, but if you being bring people closer together, they don't have to leave their worlds but they should try to get them as close together as possible so that when they have a conversation it's not only something that's productive but like it just gets them all sort of helping each other to get to the same place, right? I've heard it put and I really liked the visual.
 description of you can look at it like there is
 A slide with a clear, distinction of two colors. Hmm, like two boxes on the slide.
 Or you can look at it as a gradient.
 Yeah, and the two colors are very clearly, there's a line where one color starts and one color stops, or there's a gradient of that. And I think what you're just describing is, let's get to that gradient State. I think we are in it. We just have to recognize it and say that that's what's happening. It's just like, people talk about like the Spectrum. However, you want to think about what that means. I don't think there is anybody who's not on a spectrum of some kinds like, there's like we're all there in some way or another, right. Like different parts of ourselves.
 Aligned with different sort of values align with or are are sort of more or have more propensity to behaving a certain way to thinking a certain way. And so it's like if we all go into it individuals, go into it, realizing that, okay? You came to me with the problem part of me felt like that was, you know, you being lazy when you ask for this, you know you asked me to provision you a database and you asked me to provision you, you know, a place to store data, you ask for me to provision you, some GPU hours, whatever it is.
 There's a part of me that feels like well that was lazy. You didn't explain to me all the other specifics that you need to do that, but then there's another part of me that thinks. Well, that's because you don't know. And if I help you know,
 And then when you come to me it's I I have a much higher confidence that you thought through the things that I'm gonna have to think about if people start to think about what the other person has to go through because like it's just like if someone makes a request they had to sit there and write it down. It's not like they just said oh I want this and like there's a process that just think it and it magically all love that maybe I don't know. It sounds a little frightening but like someone had to think through it. So it's like okay well that person and and the other thing is that when when you're a platform Services team or an infrastructure team or another team where people have to ask you for things like you as a platform person, have to realize that if the way that you interact with your user Community is negative, they don't really want to ask you for anything. Yeah.
 And so it's like, you know, and and that's why making the life better of the people in the middle if you want to call it that
 Helps the people up above get what they want, not just faster, but they just get like a, they get a better experience and it's, and a lot of times people focus on, you know, being able to iterate faster and, you know, sort of being able to, to fail fast and, and to get MVPs out the door as quickly as possible. But it also is good. When if I understand holistically what you're asking me for, I can give you something. That's probably more comprehensive so you're not going to come back to me and ask for another thing, right? Oh, you want a database and you want to bucket and you want to container?
 But you haven't really talked to be about networking. You haven't really talked to me about clustering. This you say you want to database and you said that you don't care how big it gets, but you just told me that this app is supposed to do X, Y and Z. Probably we need to move on to something else, right? And so that way, the pain is late is lesson for this person because they don't have to go read you everything, and maybe they're responsible for migrating data, back and forth. And the person up here feels like I got what I wanted, even though I didn't really realize I had to scale and stuff. They like, I'm I and as they scale it they don't have to make more requests, right? So I think about things in terms that's like that to me is an optimization but you're talking about basically is
 It being empathetic to the others need. Yeah that's all and go for
 Also, one thing that's very clear is there's no technology involved in that, right? That's not at first. Yeah, it's it's just like a human to human type of or potentially like culturally in the organization. Hey we go about things like this. Yeah. If you are so lucky to have it be a cultural piece, but I remember a lot of times in the beginning of the mlops community a lot where
 It was almost like ml Ops was synonymous with solving problems with tech. Hmm. But we forgot about, hey, there was this whole devops movement, and a lot of the devops movement was cultural change. Yeah. As much as it was like, bringing Tech into the game. Yeah. And this feels a lot like, yeah, let's remember that. No matter what we're doing. Still there should be this cultural or human piece to it, where we're just trying to figure out and be empathetic with the other person to recognize what they're looking for because as you said it so eloquently.
 I'm an expert in one thing. You're an expert. In the other thing. Let me help you. Help help you get what you need. Yeah. And I you know, because I
 It's hard to pull this off properly and you know where I work, it's easy because everybody can talk to everybody. There's not like really walls built between the organizations. I mean, as you scale, like, when I started there was like, there are two people in the states and they're like, 30 people in Israel that's it. Now we're at like 11 or 1200 people, spread out everywhere.
 um,
 And silos have developed in their way but they aren't because we've done it from a cultural standpoint. We've always kind of kept like a wide open. We could you call it reporting structure now it's all about? Well, how do we build ourselves for scale? How do we get to a place where we can be more effective? Because when you grow really fast as an organization, a lot of times you're moving quickly and you're not thinking about the technical debt that you're accumulating not from a software standpoint but from an organizational standpoint, that's like organizational debt. It's the city. Yeah, it's the same basic thing and I like I but as long as there's like at the core of all the people's belief that they don't have to create walls between each other, as long as they just know that some in some way. And but it has to be for a lot of people who come from other organizations, where that wasn't how it is? It takes a bit of unlearning.
 To be able to get there. Um, and it and it isn't always easy. It's not like, oh everything's great. I can just ask anybody for anything. It means that everybody's asking you stuff all the time.
 Right.
 The implications of this type of what it means that everybody's also like trying to help each other all the time. And so it's it, you know, for me, it's the only like I can't operate at places where I have to go through all of the process, right? But then when I go in their interface with customers who have very well-defined process,
 It's it, you know, you can't you can't break their walls down. You have to find ways where they can punch holes in it. At least to look through the other side and make sure that they can get, you know, that they can fit this whole sort of dynamic nature of working together into a process that still regulated and conforms to some kind of practices, right? And so like like you know, and then if I talk about like, what are software products, do a lot of times, they're just meant to make it easier for the infrastructure and platform engineering teams. It makes it easier by making it. So they don't have to manage as much at the lower layers so they can offer more and more services up on top. We don't like we don't iterate as quickly necessarily as some of the, you know, some of the some of the people at your event last night. They're iterating very quickly. They'll do builds every day or even maybe more frequently than that, right? That they're either deploying to prod or putting staging on. We're more conservative in some ways because the platform,
 Can't be unstable.
 You have an app that impacts 10,000 users. That's the big deal. But you have a platform that impacts 10,000 apps. That's another thing, right? Yeah. Um, there's a big multiple on that and and so we're trying to make it so that the people who have to manage the platform because those are the people who sleep in data centers. Those are the people who, like, they live, they live in maintenance Windows. Like, that's their their life, is, like, the next maintenance window. Like, like I spend a lot of time, like traveling around and meeting with clients different places and it's it's invariable, or it always happens. That will be out for dinner. Will be out for something, they'll get a sub one page, they gotta go. They're in the car and a laptop. We're on training, a laptop, they're doing stuff. I mean, I sometimes in that place, right and last night after you did the release. Well, it was, it wasn't, it wasn't like that. I mean, mostly I'm I I try to get it to the place where, like, I so so my team my role
 Oftentimes interfacing between sort of the customers engineering, the sales organization sometimes product management. Like, I kind of go with within all of these groups but oftentimes I'm I'm the Black Box tester. Before we release right? QA does all their unit tests? They do the regression smoke, test people on my team. Go focus on functional areas and go and try and do it the way. A customer would do it. And then like usually the last week before release I say, okay now it's like stable enough. Let me go. Let me go play with it. Let me pretend like I'm dumb and set up for the first time. I'll go through the docks and make a comment every line. I don't know what this means. I don't like it's just like one of those things. So like the last week has been a bit of that because I just don't you know because I what ends up happening is if a client tries to use something that we've just built.
 The first place they're going to come is to my group to try and figure out how to make it work. So who's me? Know how it works? I'm like hey how Works in B how can we make the docs better? How can we make the US better? They don't come to you. Yes. So they can get what they want out of it. It's just the same basic phenomenon that happens between the platform and the app team. It's like okay, when the platform team is ready to offer a service, let's say go, oh we finally have containers as a service or whatever they offer like when they roll that out, it behooves them.
 To be able to make sure that they thought through what is Joe over in finance gonna do with this thing. So that, that way when the service is there and he hits the go button on his app that I don't get a F1 call on Saturday night, right? So, our world is definitely in the world of people who are supporting the, the sort of people who are making the applications. And the best thing that we can do is make sure that they don't have to wake up at midnight, right? That they don't have to worry about it as much. That we don't have a such thing as a maintenance window to fall into if we have to update software, do some kind of expansion of systems that we can do. So without it being disruptive to their users because ultimately their customers who you know who are relying on these Services, they end up complaining to to this team and that team like their their buffering, the complaints, that would just come to us, right? So we do much better to make sure that they have what they need. Yeah, I feel like I distracted
 You a little bit on how you you travel around and you see the customers and they're the ones that are sleeping in the data centers and they're the ones that are yes everyone calls.
 And they're the ones that are having to do this. So, how can you make their lives easier? Well, I mean, for us, I think the way we make our their lives easier is to understand their lives as well as we can.
 To really, and then I mentioned earlier, like, requirements Gathering.
 I think that one of the things that we have done in the past and you know, it worked well for us at first as we took a sample set of people who said they needed. Something we built for what what they said they needed and we tried to apply it to as many people as broadly as possible. And at first, I think that that works like we can, you know, especially if you're solving problems that are really hard to solve,
 Then the the people who start to use it at first or they're fine with some blemishes, they're fine with some, you know, inconsistencies of like how things work but as the number of clients users customers, whoever is that scale? It's the challenge that we're at right now is like, well, how do we make sure that we're making really the right bet in a direction, right? Like if you think about like one of the metrics that we measure in terms of our success besides Revenue, everyone measures Revenue right is uptime of our systems, right? Like that's like we're very we focus on that very, you know, very closely. And so you know, we're always trying to strive for six nine, seven nines, whatever, right? And I think that the goal and, you know, if you look at how those numbers are calculated obviously like it's not like the simplest thing in the world, but ultimately the way we determine, if we are meeting that
 Is did the customer ever have some kind of an outage that was related to us, right. And it's not only the platform that we look at, it's like like if a customer let's say they upgrade and the way that you do something in the new version is slightly different right? Like the API, you know, the apis are the same but maybe the behavior slightly different because we've added some functionality or something like that if that causes them to have an issue, that's still our issue, right? But the only way to know that is to really know what they're doing.
 It's not enough to know. Oh, they need the API call to return a 200. Like that's not enough, right? You need to know, not just the what's coming back to it, but then, what are they doing with it afterwards? Who are their consumers? So when I talk to clients, who are platform engineering teams, who are infrastructure engineering teams, of course, I talk to them about what they say they need, right? But I always try to get a little bit further and like who's asking you for stuff and what are they asking you for? And you know, why they're asking you for it? Because if I can know that then it makes it much more likely that if I give you if I give you something that works, that it's not only going to work for you, it's gonna work for them and then that means that you have less reason to worry about what you're doing day-to-day, right? Less reasons for them to come to you and then you to go to. Yeah, basically, the water I'm trying to, I mean, it's not just protectionism a little bit of it is right? I'm trying to protect
 Ourselves from escalations, right? Like my I've gone. I would say that my role has evolved over probably 20 something years, but it's always been in some escalation kind of role.
 Like, I don't know why, so you've gotten good at trying to minimize those, but I try to minimize them before they happen. Exactly right. You're preemptive like, and and like that, that is a hard thing because I deal with a lot of support Engineers, a lot of escalations Engineers like, on our side. And on the customer side, right? Everybody's an escalation engineer if you're on a call with them at midnight, right. Like that's not that isn't like the regular app developer who's doing that. Like if someone who's providing a service like I worked at Amazon before AWS but we were on corporate systems right there. So we'd managed like tens of thousands of servers and everybody had pager rotation and like, even even app developers had page rotation. But from my standpoint, I only had like a certain sphere of influence that I had to worry about, but I had friends if they had to get on call because something failed. That was a problem for me too. So I tried to like help make sure that whatever they were using was wasn't going to give them a page like
 It would it would be a problem for you too because you couldn't finish your night or because they hang out. Like you want to get a beer, right? Like I thought and they're probably pinging you like hey, do you know? Well they might do that too. That like from from that standpoint but I even think about it in terms of like look when I was first started working there. I was like what? Like 22, 23, something like that. Like I didn't didn't matter as much to me the business. What matters to me was like I had enough money. So we can go out and have fun and no, we can't have fun. Yeah, sitting in a bar. I mean, I'm not saying we didn't do that. Like, like, usually fixing stuff ones with the beard next to you isn't the best practice. Not a fun Friday night.
 I wanted to hit on the
 the gigantic GPU clusters and how
 rolling updates happened. Well, I can tell you our experience. Yeah. And I'm not gonna name names because they're
 Like the some of them would let me name names but I don't like to call people out that way, right? So
 some of the data centers being built now are being built very quickly and power is not always so reliable.
 In fact, it's the opposite of reliable, right? I think that it's too easy to think. Well, I don't know how closely you follow these things. Like how many gigawatts are getting deployed and Texas and Norway or like oh like the Stargate projects or any like
 And the reason I pay attention to it in part is because it affects me personally. But it's also just because it's like an excruciatingly large amount of capital being spent very quickly and I'm like,
 Like one of the data centers that we worked with a larger model builder on, they built in like 120 days and there was a building but they had to fit it out with all the normal things you put in a data center but it was a gigantic data center. I don't know. Hundreds of megawatts, right?
 100,000 of gpus and they want to make it, I don't know, five times as big or whatever crazy thing, right? But when people are running fast in that world,
 The the effects of something going wrong or magnified immensely and so power has been like one of the biggest challenges and where we've been very successful is that unlike other platforms that offer the data services. We provide we don't worry so much about what happens when the entire data center goes dark. We don't worry that we've lost any data in the process because of how we've created an architecture to deal with that and so I think was that I so fully. So basically like okay, let's say you're let's just talk about basic stuff. Let's let's say you're a client, you copy a file to a file server. That goes over the network, the file server receives it parks at somewhere.
 For performance. It usually doesn't park it straight on the media. That's going to go to because that takes too long. So maybe it puts it into a buffer, maybe it puts it into a into a card that has some battery back in case there's like some kind of a power outage. A lot of times most file systems, let's say, would use a journal of some kind journals. Unfortunately have to be replayed which means when you turn everything back on, you don't get to do anything while the replay happens. If there's any inconsistency found in any part of the metadata structures. When you're mounting the systems, then you have to not only replay the journals. You have to do a file system check and they only safe way to do that file system. Check is when nobody's writing to it. So now you're just waiting, everything's offline and that could be ours, not a big systems hours times all the gpus millions and millions of GPU minutes. Someone's getting fired. That's all that means. Right? And like or a team. Yeah, well hopefully not because then we're gonna do the next day. I don't know, but, but so from our stem Point, we've always looked at it. Like it's kind of like, when we're
 Talking earlier about the person who's like, developing on their laptop and they're like, nothing's ever gonna like, what do you mean fail? Why don't think about failure? Why is that thing? But we had to, because
 at first the places that we went into, if I think about like the doe Labs, or NASA, or NIH or any of these big HPC based research organizations
 They're used to dealing with scalable file systems that have just big problems, right? Like if if there's a massive power outage, they know there's going to be some kind of like day long waiting for stuff to be okay again, which you know, it's not like it was good when they had 10,000 compute nodes that needed to access data but it's much worse. Now when the gpu's cost that much more and so and especially there's this whole race, everyone's trying to race to build the next model to to get one step ahead. Every it's dizzying and so because we're always in that race or they're always in that race, we're kind of there with them. It's very important that if there is some kind of unpredictable thing that happens that we can recover from it very quickly. So, like the one of the data centers that we were working on, they would have power outages randomly almost every day, we're not the whole data center. We go, hold data Hall will go. They people usually split things up in a data Halls where they'll have like 10,000 gpus over there.
 And 10,000 over there and 10000 over there and there's power different Power feeds coming in all of them, you lose one of them, it sucks.
 Right, but it's not the end of the world. Like you still have most of your capacity and most your GPU is still online running and so like, but when you bring that one back up you don't want to wait that long for your gpus to be able to do something with it. Right? And so you know we of course don't like it when the power goes out all the time, we get tons of alarms, we get all the support Engineers, trying to figure out what's going on. But we've gotten used to it now because we've seen this is becoming more of a regularity because again, like a lot of times in these places are built out, they're not necessarily building them out with full redundancy for everything. Because all the money is going to gpus, like, none of these people want to spend the extra money on the other stuff because they want to buy that extra Little slice of gpus to get them to a usable State. And so sometimes they cut Corners in those ways. And so we provide a platform that can deal with that kind of issue. The other part of it is that when we started out like, it's funny. I was like a
 User conference last year. And one of our customers from NYU had told me that basically they were used to their systems if they had some kind of upgrade they wanted to do like a software upgrade to get new features or to fix some bug or whatever they would have to take down time for their systems to do it and I never heard of that nowhere. I worked before had ever had a problem just doing software updates in a non-disruptive fashion. And so, I just it was a very foreign concept to me, but then I talked to all my colleagues used to work with other places. Like, oh, yeah, we would take outages when we do upgrades, we tell the customer to plan for, you know, an hour to two hours, to 10 hours worth it down time, just to do a software upgrade. So they never want to upgrade and I'm like, but if they never upgrade, how do they get the bug fix? How to get this thing? Like, to me, it's a foreign concept, but it isn't for a lot of people who've been dealing with the low level infrastructure for a long time and so being able to offer new features and services to people with without requiring that they have to take some level of downtime or lose like a large.
 Image of their performance for a period of time is a big deal, right? And like, like, again, like we created an architecture that kind of disaggregates, the state layer and the logic layer to make. Sure that when we're making software updates in the logic layer, we don't necessarily have to do anything at the state side of things and do so in a rolling fashion. So there's always a large percentage of performance available in the entire system is available during any of those things. So it doesn't matter if an upgrade happens in the middle of the day.
 You don't have to take a maintenance when to do it, you can do it anytime. And so, we try to like we've, we've created that reality for the high performance compute, and now the large scale AI sort of community. And we're we try to bring it to more and more people because it feels like it's a hard problem for us to solve at first, but we had the benefit of spending a lot of time up front thinking about the way that other systems and platforms have been built and we just didn't, we didn't actually Implement any of our code for a long enough time. Like we like when our when our original CEO and founder and our first, the developer actually alone who spoke last night, he was the first code reading developer at vast. When he first started they spent a solid. I don't know how long if it was a whole year or some percentage of a year, just writing down what they needed the architecture to be like just thinking through the architecture. So before they wrote any code, then they wrote code for
 One plus years, before we deployed anything to any even Alpha customers because they just wanted to get everything that the foundational layer is solid as possible before anybody was going to rely on it. And so, we were, you know, because of that, it's actually easier for us to do new features, it's easier for us to build new things because the foundation solid enough, that we don't have to go and refactor anything down here anymore. Like we can all do it up at the higher layers. So
 the thing that sticks out to me, the most on this, is that
 As if gpus weren't unreliable enough, oh, on their own. Yeah. Now you're talking about how unreliable the power is. Well, I mean, like if you want to, if you want to deploy a hundred thousand gpus, you need at least 100 megawatts worth of power to do it. Where are you gonna get that from? Yeah, it doesn't exist. That's why you see all these gas turbines, being rented or bought. That's why you see micro nuclear coming up. These aren't reliable proven ways of doing power.
 How many electoral Engineers out there like the I say, like, you know, had like during covid, like the traveling nurse thing was like there's a thing that was a profession that could make good good income doing it now. Traveling electricians. They go relocate to some crappy place for like three to six months. Yeah, it's a day, doesn't it? Yeah. And and then they end up, you know, basically working around the clock and making a ton of money or whatever. But the thing is, is that there, you know, they're not doing things necessarily according to the standard practice, they're trying to find the fastest way to get the most power online as quickly as possible, then when the data and, and that's why it's kind of interesting. So, we we sponsor and attend like a large supercomputing conference. Every year, it's called super compute. Really original original. Yeah. Um, but it's mostly historically been sort of what I consider to be classical. Old school, HPC administrator and infrastructure managers, right? Like people who had to build out each PC systems. People who
 Stand everything down to the cables being used between all of the racks of servers. And that's that isn't that, that isn't a skill set, that's being cultivated for new College grads that isn't that. And that but the irony is that all of the big large-scale, AI projects require that skill and so there's a smaller and smaller number of them. Because most of them are getting older, they're in their 50s or more because like a lot of the HPC environments are, you know, sort of, you know, classically lower paying jobs with the doe or other places and so, wow. I mean, it is it because it's Hardware too, that part of it's hard where no Hardware is that interesting to most people, right? And unless, you know, you like want to build some cool gaming rig or do whatever and have little neon lights on it. Yeah nobody wants to be plugging in at this point to that one wants to think about that. They don't want to think about polarity of Optics. They don't want to think about like what the signal rate is on a transceiver. And whether it's compatible like, you know, Nvidia is great about
 Releasing, you know, a new cars every year that people have to figure out. Okay. Now how much power do I need to Rack, right? Like it used to be like 10. Kilowatts in Iraq was enough, then he was enough now. Like 100 kilowatts in Iraq is is like pretty normal 250 is. Now we're seeing some of the places and a lot of people won't understand what that means, but it hasn't escalated gradually Jack straight up.
 It's like and then you think, like how do you get that much into a rack full of servers? And and and and but then and then you have to think about the cost of what one of those racks are right? You could have easily multi-million dollar racks of servers that take up like you know like this chair with the floor space, right? And it's just sucking energy sucking energy processing data doing all of these things. And then now you got people who are managing like hundreds of those or thousands of those in a single building and it's going offline intermittently. It can write and they do their best to make sure that it doesn't. But they need to have the platform that's reliable enough. That if something goes wrong, it's not like starting over, right? And so, I didn't quite catch is the whole thing there with what you're doing.
 The value prop is that it's not just starting over.
 So basically look at it like this, let's say you're in the middle of a training child, hopefully checkpointing. That's like a thing, right? Yeah. My buddy Todd was telling me again not to derail this one but he was like, checkpointing is a fascinating art because you don't necessarily know. Should I be checkpointing? Every second, should I checkpoint every day? Like it's a cost analysis. Honestly, you have to sit there and do a cost analysis. But basically, you do a checkpoint where you're dumping GPU memory and state and it takes some time nowadays. Most people doing what's called asynchronous checkpointing. So it doesn't necessarily impede the job
 But when you when you checkpoint you're saying I want to take a little bit of a performance hit and time hit on my overall job to make sure that if everything goes to crap and I've been going to crap, could be like a few gpus failing, right? The wrong GPU is failing, the wrong time. And then there's like a certain amount of restart that has to happen. Let's imagine the whole data center went out, right? And let's say you're checkpointing once an hour or whatever that means, you probably have to go back an hour. But what happens when the system that holds your checkpoints isn't on line for another couple hours now, you're screwed. And then once it does come online, you still have to read back the checkpoints and that takes time. So it all ends up coming down to time. And I think that, like, in the way that people have dealt with this in the past and they had less reliable systems is they would say okay well percentage of our gpus are going to write to this project points percentage, right to that, that way and I'll lose everything. They come up with all these different points. Yeah, they come.
 With more complex strategies because they can't rely on the single platform. They have to split it up into pieces but when you split things up into pieces then you have to orchestrate your jobs around having all of these different pieces. You have to manage like it becomes, much more difficult to operationalize. Everybody wants one place. They don't like it. You know, it's like it's like even even when you're, when you're thinking about impersonal life, you don't want to have 10 different places, you have to look for something every time you want to look for it, right? And one of these ten places. Yeah. It's it's much easier if you know where everything is going to be and you don't have to think about it in the in the wrong turns and things you have to think about it in terms of scale too. Because as you were mentioning earlier, your friend in the finops world, they don't even necessarily know what their forecasts are gonna look like. Well, having a platforms that can scale.
 In different dimensions. Sometimes you need more performance in one sense, and sometimes, you need more capacity in another sense if you're fixed and how you can scale that becomes challenging. Like, that was one challenge that people often have with Hadoop was they would have jobs that would run slowly, but because of the architecture, they had to also add significantly more expensive storage along with it. Because everything was tightly coupled, right? Every node had some amount of storage and compute in it. And the only way to get performance is a shot across all the nodes very evenly. And so, if you need to add more performance, you had to add more capacity and reshard and like, there's all these issues and layers. And so we again, looked at that and said, that's not the way to do it. That's why we separated, what we call logic from State and disaggregated things, so that you could scale the performance layer with having to scale the data layer. You can scale the data layer and not have to pay the cost of scaling, the performance layer, if your needs change. So, part of building out a platform that's going to meet,
 Unpredictable needs is having the ability to scale and multiple Dimensions without having to go tell your user Community. They have to go Point somewhere else now, right? And are you also thinking about it as far as like,
 We've got the gpus. But what if folks want to use the AMD gpus or the tpus? And so we're not so picky, right? And I think that we, I, I'm not gonna say we're not playing any favorites. Like obviously Nvidia is they're big. We like them, they honestly, and they actually have taken quite a large proportion of not just GPU estate, right? They, they bought a company called mellanox which is the high speed networking interface, that most of the GPU Farms are using. There's other vendors in that space. But if you're buying the GPU, like, if you're buying the gpu's from them, then they can toss in the networking along with it, or what they would do, is build out a reference architecture that says use these networking switches. Use these networking cables, all this other stuff because and then if I'm basically a cloud service provider that's trying to build a GPU Cloud, so I can rent out gpus to a customer.
 If I buy the gpus from Nvidia I'm gonna get much better support from them. If I'm also buying other parts of the stack from them and so in that way like they they control a lot more estate within the Data Center and they make their their influencing the decisions of a lot of these people who are building out these scalable systems and then so you know, there's that side of it. But in terms of if a client wants to use other gpus, I mean, you know, you know, whether even even Intel makes gpus right, we haven't seen them as much in terms of popularity, but we're not, you know, we we kind of try and take a more agnostic approach to to looking at it.
 I would say that like for a lot of inference use cases, I don't necessarily know how important it will be to have certain gpus in the future. I think for training
 Nvidia, definitely has a Leading Edge in terms of basically creating Cuda and creating the world that people live in, when they're trying to come up with how to do training. But in terms of inference, I think that they have projects, right? They have a project called Dynamo, which is basically they're sort of inference focused Suite of software Stacks but I think there's a little bit more flexibility in the inference space. And, you know, I'm looking forward to when we like because from our standpoint we see people doing a lot of training and we see some inference. I think that the transition pointing it is Shifting. Yeah. And and we don't know what the power draw with the workloads. What those look like as much.
 As we do for training, they're probably much less predictable. Yeah, they probably scale in different ways and, you know, it's, it'll be interesting. Yeah, it's funny. I remember reading a Facebook engineering post back in the day talking about how they the traditional predictive ml stuff that they were doing.
 Was.
 Lots of bursts, it was like, short fast bursts. And now this generative AI stuff is really long, intense, heavy training, and so the, the workloads were very different. And if you think about the inference, it's more on that like bursty side, it feels like to me then especially it's not like a 40-day training job. Yeah. Yeah. I think what the challenge is for people who are offering gpus as a service or the people who are buying gpus and trying to maximize their utilization, the challenge is figuring out how to keep them as busy as possible. But not take the risk, you know? Because the other thing is that we, we talk to clients a lot about GPU, failure rates because they're not negligible, right? And I think that is because of how hard things are getting pushed. Like you see failures happen, much more frequently. I think people who are Building Systems on top of that, where they agentic
 Or not, I think, I think thinking about failure before you go build a whole application, stack is probably a good practice, right? Things are going to fail and I give a talk in London, maybe it was two years ago, no.
 And it was like an AI Centric conference that I was at and I asked everybody who is, there's probably 200 people there. I asked everybody, if they knew what an Nvidia dgx was, which is a GPU server, nobody knew zero.
 Like most people knew what a GPU was but the specific number or well, specifically didn't know what a djx was. They they kind of knew what a GPU was. The thing is that most people were at least of that conference, they were consuming based on having a service available to them. Yeah, they didn't think about infrastructure which is good. I'm glad that they get to live in the world. Yeah. They live in the world where they don't have to think about those pieces but now that we're at a place where the scale is much larger like those are the pieces that cost all the money. It's not like and that's unfortunately the way that this world's operates, right? So we have to make sure that we're using this very sort of expensive resource the best we can and knowing ahead of time that you're in a deal with failures because infrastructure will fail. Yes, of course software's going to have bugs too, right? But, you know, in the world of there's no bugs, there's no bugs, right? But but even Hardware is this magical Fantasyland know. I don't know. I think it's there somewhere. One of the Architects said, well, you know, if I don't write any codes,
 No bugs. I'm like, yeah, but I need you to write the code. He's like, well, stop complaining about the bugs and like, I don't know what to do. Do I like this guy already? I'll bring it by, he's fine.
 It's making sense. Yeah. But but anyway, yeah, going back to the this idea of like the magical Fantasy. Land Of No Bugs. Yeah, infrastructures gonna fail. It's still gonna have problems. And, and, and even if, you know bugs, you didn't necessarily think about what it's like to have variable levels of latency between different things. This special, now that, you know, you can't fit enough gpus in the one place to train some of these models. Now, I mean, they want to build gigawatt level data centers, but that takes time. So, in the meantime, while they're in the race, to make the next model where they're in the race to build the next application, they have to find ways of using stuff, across multiple Geo distributed places, whether that be within a major cloud service provider or in a data center, the renting or whatever they're doing.
 They need to be more flexible. Developers need to be more flexible application. Architects need to be more flexible and thinking about. How do I make sure that when I'm running? Even if it's not training, if it's any kind of application that it can tolerate, what happens when I need to request data that's somewhere else. And so, one of the things that we've also done is try to find a way, I can't defeat the speed of light, like it's not possible, but we can cheat a little bit, right? We can get more predictive and how we prefetch data that's going to be loaded in for an application or job. We can allow the scheduler to give us hints so that we know what data it's going to need so we can move it from physical place to physical place.
 In a way, that's a synchronous. And that by the time, the job needs it or the application needs. It, it's already there, right? Like we spent a lot of energy coming up with the way for people to create like a global mesh. So the platform can extend beyond Four Walls of a data center into a place where you could have some stuff that's deployed and cloud service provider a, and in a Data Center, and cloud service provider B in multiple geographical places, and it will still function and you can start to help them see the right way to interface with it. So that the application is not I wouldn't say able to tolerate it but takes advantage of it right? Like when you use Instagram and you upload a photo and it's already uploading as you're running the caption. Yeah. Yeah. I think
 Ultimately, it's funny I interviewed for a job like forever ago for 25 years ago maybe now and my buddy because it was. His dad is gonna give me the job. He's like trying to get me prepared for the interview and he's like, he has, he said, to me, he's like, what's the most important part of a network? And I was, oh no. What's the most important part of like a Computing environment or a Computing Network, or whatever? And I was like, well, it's the switches and this and the, you know, whatever I was trying to think of he's like, no, I'm like, well, what is it? He's like, it's the user. That's the most important part like the. And so, when you think about like, whether it's apt design for a phone, whether it's app design for a large scale, sort of Enterprise app, like none of it matters. If the user doesn't get what they're asking for and I think we regardless whether we're at the lowest layers or closer to the top where they're interfacing directly with the user. How to remember that? Because ultimately that's success or not success, right? Like that. Like you could say yeah we gave you
 Seven nines uptime and the performance is the fastest you can get anywhere. And it's like, yeah, but the user couldn't get what they wanted. Yeah. And so then they, they complained, right? Like, that's the ultimately. What it comes down to. Yeah, man. What and that is.
 For anything it's not just for software. Just when you're interfacing with folks or you're working with folks, you want to make sure that they understand the value that you're bringing. Mm-hmm. And if they don't understand that as the user, then there isn't any value. Exactly. So then you have you haven't accomplished your goal, okay? And I think even if, if whether I'm plugging in cables in a data center or whether I'm designing an application to transform data from one format to another like no matter what I'm doing, like there is always like someone on the other side of it somewhere.
 And, and really, like that's like whether it trickles down to me or not. Like if I think about that when I'm doing something, if I think about that, when I'm educating someone on my team or one of our engineering teams to build something, if I think about that, and make sure they're thinking about that, then there's a much better chance for to actually be successful, right? Like, if you get a product requirement, do you look at it and you're like, okay I'll check this box and not box and not box and not box done. If they're if they're not thinking about the mission of the user then it doesn't really accomplish the goal even if they check all the boxes. Yeah, right. Yeah. And so I don't know like it to me it feels like like most of my time is spent interfacing with clients and trying to figure out what they actually want and then sometimes trying to figure out what they want that they're not asking for
 Because oftentimes when people say yeah, my leg hurts like, well, maybe maybe just stopping it with a hammer all day.
 And whether they're not asking for is for you to take that hammer away from them. That makes sense. Oh, that's classic. Is there anything else that you want to hit on? Well, I'm curious in terms of your thoughts like, you know, you started. Basically you have a community here in the city. Well, I mean that's the event that I attended is here in the city. Like what's interesting for you, like what's what's new for you that you're actually excited about
 Oh, there's so many, there's so many levels to that, right? And I think I mentioned before we started this conversation with the full stack Ai and all the different ways and areas that I'm seeing, people interact with AI now, because obviously, it's on everyone's agenda. It's on everyone's road map and everybody's thinking about it or, or doing stuff in it and
 I would say some of the coolest stuff that I've seen recently and this is high recency bias. Yeah, like yesterday. Yeah this morning tag me exactly. I really like what my friends soham and Neil are doing with like prompt optimization and prompt compression in that regard because what they're telling me is like yeah you got these agents, they go out and they do stuff on the internet they come back and they've scraped a web page 90% of the data that they come back with is absolutely useless but it all just by default gets thrown into the context. Yeah, yeah. And then the llm call has to figure out was this used for was it not and you're paying for that? That. And that's the whole thing. Yeah. They're like hey we want to save some money. Yeah, check this out. Here's what we created. And and so I think that's that's a cool one to look at. I think there's also
 I like this. Give me a second. You see your hump compression?
 Like, I'm just trying to think of what that means.
 Yeah. Go ahead. What? I understand from it, from the
 10 minutes, and I've spent with it is is
 there's a lot that you can do, you can take out words or you can take out whole sentences in a prompt that are not really that
 Informative. Okay, they're not very effective. Like you can take that out. Take out tokens. Let's just call them. So because that's where they are here. So you can take out a lot of tokens and still get the same result. Yeah, yeah. That's good to think about. But they're doing it with like another model is, of course, stripping out the cheaper models, exactly? Yeah. She model and actually, yeah, on on the cheap one that you were talking about early when you're thinking about, how you get surprised with Cloud bills because you're thinking, yeah, we'll just have this policy where we try to answer the question with a cheap model. And if it doesn't then it goes to a bigger model and a bigger model and a bigger model until we get answered, right? Yeah. And it reminds me of back when Chacha BT came out. I interviewed this guy who created or he was a researcher at Stanford, I think you created Frugal GPT, and it was basically a way to try and
 Concatenate problems. Or if you have the same prompt, you can ask it in a different way and get the same answer. So that it's much cheaper. One of the strategies that they introduced in that paper was hey, let's try with an open source model first. Let's create a router and maybe like a
 Classifier model that will say, oh yeah, this can go to a cheap open source model instance, or this is a little more complex, let's send it to the bigger model because we don't think it can get answered. And now is when I'm seeing that idea really getting put into practice like, yeah, that's yeah, I mean stream in quotation marks, because we're still super Niche on this, right. But it's people are thinking about that idea much more than when it first came out. And so, I liked seeing that. Yeah.
 I like seeing I mean, all the GPU stuff that's why I love
 nerding out with you about it because I feel very
 new in that area. But I do recognize that like you're saying, there's a lot of folks who have been working on hardware and building data centers and their job is the most important thing ever right now. And there's not a lot of new graduates that are going into that area. Not as much as like my son, he went to school for welding.
 And because he he probably saw too many late nights and me being in front of a computer, really, like freaking out. He's like, that's not my game. I'm not going that route. So he went in my hand. Yeah, no because and it's much more well suited for his personality and what he wants to do. But it's a very hot commodity world to be a welder or someone in the trades now because it isn't what people are going to school for. It's not looked upon in the same way that it used to be in terms of it being like a career.
 But the but, you know, there's a world of supply and demand like they don't have robots doing, all that stuff right now. It's gonna take a long period of time. It's just like the drilling for oil thing. It's gonna be too expensive to automate most of that stuff for a long time. And so like I think there might be a, you know, sort of a Resurgence of people kind of looking into that world. I don't know that there's going to be a Resurgence of people going into be infrastructure, engineers and people who are doing those. So we have to get smarter about making it easier for everybody to do it. Yeah. Yeah. That or just pay him a boatload and then there will be a resurgence.
 Yeah, if you I mean there are I will say that the the well-funded model Builders are definitely paying pretty. Well when it comes to hiring people who are used to managing large fleets of servers
 You know, but that isn't like a never-ending Road, right? It's not. You can't count on that. Yeah. Actually, if you're just going into it right now it's like yeah, still. Yeah, that really gonna be a thing and it still isn't interesting to a lot of people. Yeah, right. Also, I think, I think there's like a breed of mind. I would guess you could say where you want to fix problems that nobody else wants to fix, right? And that isn't like that. Like, a lot of people want to think that they're going to come up with some new ideas. That's going to solve like all these amazing problems, but they usually think about it in the higher level of, we'll call it the stack. You know, usually think about it down here, right slogan in again. Yeah, the whole Act of plugging things in isn't as satisfying sometimes
 but actually, you know what, I was gonna say that I'm really
 Stoked about these days or that I've been thinking about these days really quite a bit because I had to write a talk and so originally the talk was gonna be on what have we seen in the community over the past year and how things developed what are the kind of questions that are being asked that kind of thing like a Trends type of talk and then as I was doing it I was like wait a minute, there's this thing that kind of bugs me. That is a lot more close to my heart. Yeah that's this idea of
 The ux of agents. And I kind of proposed this idea in the talk that everybody wants to be an agent and nobody wants to be a tool. Yeah, and so that is creating this horrible user experience for us because we have to go and interface with many different agents. Yeah. And it's just like, a little better software 2.0. Yeah. Yeah. It's like, okay, I'm gonna go to your website, and then I have some chatbot that is an agent in the background. Cool. That's horrible experience for me, people. I mean, I think it's this idea that in Asian would offer more value than a tool in terms of differentiating from something. And you don't want to give up that relationship with your customers. Yeah. Because now if you're just a tool like who is the gateway to the internet? Yeah, because they're gonna be the ones that capture all the value, right? And now you're gonna have to figure out how can I get my tool which is really my product.
 To be consumed by your agent.
 And yeah, that's where I think there's this huge tension that's happening. And so for us as consumers, the better
 User experience. I argue is that we interface with one agent that can go off and do anything on the internet. Yeah. Because I don't want to have to go and find the place. Yeah, I want to just tell my agent like go file me a claim for this or whatever it may be. I want to learn from the agent and then have the agent act and do things and be able to have it.
 And check all of my stuff. Mm-hmm. And do things on external services, but it's my agent.
 But that means that Amazon now has to like maybe it's just an easy tool. Yeah. It's just in it's just an API interface and like you're not forget to see their website. Doesn't look amazing though. I'm gonna say,
 It's okay if that happens but they they don't want to do that, you know. Maybe Amazon's a bad example because they're
 they're gonna throw billions of dollars out the Gateway. So they're the number one. Provider agent or tool whatever? Yeah, be. Well, you open up your phone? You're gonna have like the top five apps on your phone. Whatever that is right? For a lot of us, it's some kind of communication app. And, you know, for others, it might be, you know, something to either buy things or potentially, you know, like in opening eyes world, you would just only just have to be just like right. It's like that, right? And I think I can see value from myself and having that life where I just open up my phone and I only have one thing I have to think about it. But there's also trust issue in terms of wanting to have a little bit more control over my experience. Well that and now all of a sudden I have to trust that the
 Prompts that I'm putting in and everything that's going into that context, window is a being executed properly. And be like, what if some of that stuff that I want, or that I put in the context, window is sensitive, how do we know that that's not just, like, now floating around the internet and we've got data Brokers on my context windows. I mean, you probably will, which is scarier, right? So I mean, the EULA is on these things are. Probably I don't read them all right? Nobody, that's me. Nobody reads, the longer making the less, they'll read them longer. You make them the more you're trying to hide them like yeah.
 That's an interesting thought process though because even we like like we offer sort of differentiating software and services.
 But ultimately, the people who are consuming would just like to have a relatively simple API interface where they get the thing they want, right? Yeah. And how do we differentiate in that world? I think that
 having reliability and consistency like because that's like the definition of a tool to some extent. Yeah? Right. It's hard to make a tool, maybe it doesn't seem like a differentiates but in some ways it kind of does you have a tool that you could always rely on, you're always going to use it.
 So I don't know, like it's not as sexy sounding because like an agent seems like it's smarter and can do more but ultimately if you have a tool, if you do something really well and you can expose it in a way that's very consistent and reliable.
 That has value. Yeah. Well then the
 thing is is like, are the agents going to be able to
 Place a value on that and go back to it, more and more, which maybe they are. I'm not arguing, they aren't. Yeah. It was a little bit of a trip when I went to San Francisco. And I told these folks who were creating a MCPE like
 Glossary or mCP registry. Yeah, it was. Yeah. I was saying, hey, you guys should have used a reviews of the different mCP servers and they were like, we're gonna have agents reviewing, the mCP servers in saying, how useful the documentation is from the agent angle? That was like,
 You're kind of cosmic here on this agent, reviewing the age of thing, but I could see it. And then you're like, well then I'm gonna have to have my agent or my tool. Mark it to the agents and and I start going down that road and I'm like this is now crazy. Yeah, like the it's not even my head hurts. It just like it's in a place where I lose track of where I am in the universe. Like it's how can you even comprehend? It actually brought something about privacy though, which is really interesting in some ways because
 I think the thing that people forget about when they think about scale is security and privacy, like a lot of the clients that we talk with.
 Its again, you start with your laptop, you make some cool little graph Rags thing on your laptop and it works. Great for all your stuff. And you're like, now, I want to roll it out to my whole team and then they're like, yeah. But I don't want you seeing my stuff and then it gets stuck and I think that that's a place where people have been stuck, and that's another area where we like, we try to focus on. Okay, how do we create an interface?
 At every layer of infrastructure, then ensures that you can have sort of lineage governance in authorization.
 Not just for Source data but also for the derivatives and then ultimately, if you're performing some kind of rag search or the vectors labeled, so that it knows who you're supposed to be and all of these other pieces. Like those are things that there's lots of different solutions for that are disparate from each other but they're focused on one area Or Another. We're trying to kind of be where the ground layer, let's say, and if we can enforce it all the way down, so that individuals don't get access to other data, regardless of how it came in. Then we've gotten to a place where now you can scale this thing that you build, right? And have some level of security like, everybody's like, people like to talk to me about security and I hate talking about security, I'll be honest like this. Like the security, like here's the thing he's easy to implement, then more people do it.
 And so the requirements may be very difficult but if you if you can, this is why I like to focus on the foundational layer and make sure that you don't have some other way in, because if you, if you implement security to policy layer up here, but there's another way in to where the data is, then you haven't actually solved the problem. The only saw the problem for everyone who's going up here, right? And so that's why like, I think that scale isn't just like am I making or you know production, I think applications isn't just, can I make sure it operates that there's failure? Can it operate if it gets bigger and bigger with more users? Can't operate when there's more user communities?
 Where I can ensure that they're all safe, right? That's like a hard thing to do. It's like when
 Germany went invaded France.
 In World War Two you know France was like we got you weren't Never Letting you come an inch into our territory ever again and they build all these barricades and then trim he's like well I guess we could just go through Belgium. Yeah. I mean
 Wow. Okay, that's on the warpath.