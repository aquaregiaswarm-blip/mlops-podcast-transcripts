Slow data is more when I want to emulate a decision-making process. A lot of things are Beyond sort of prompting, but if an agent or a system observes you for long enough, it can pick up on the intrinsic patterns of how and why you are making certain decisions.
 the whole small language model kick that you've been on and then there's this other idea like
 I use as someone that works at a company, I have the internal uses of AI that hopefully, I'm enabling with the agents. But then I also have just like, when I interact with the chatbot directly and yeah, usually all interact with Gemini and ask it questions. Okay, there's different use cases. Where you're doing general purpose stuff, you go to Gemini you go to open AI you know you want to summarize it document. Yeah, I don't message my colleague to summarize a document for me, but when I want my colleagues opinions on, Ace is compliant with what our company is doing. Like, if I'm gonna adopt this, I'm going to push this out. I go to my compliance office, of course, he knows information about the company, nobody else does. And that's that's what we want to capture in these models. Why do you need a small language model? Or why do you just need to find tune model for that as a post to some rag based system or something? That is is a little bit more.
 Simple to set up. I could say for lack of better word because I know you're trying to make like this fine-tuning, much more simple to set up. So I don't want to like
 say that it's not simple but it feels like if you're trying to fine-tune small language models, you're adding a bit more complexity.
 I think we've taken care of adding the more complexity part for you. So you don't have to really, you know, take the engineering overhead of fine-tuning models. And I think fine-tuning and drag are complementary at the end of the day when you want to add static memory sources to an llm to refer to during in France, you could do a rag, or you could do an agent, take memory framework to supplement it. But the model itself, what should it be sending? As a query to the access system, is it aware of the overall context? One of the issues with Asian Tech rag, is a lot of times because you're doing only semantic similarity, framing the right question of framing, the right intermittent questions, become really difficult and that's where you want to do. Fine, tuning on large contacts. That's all your Enterprise data. You've collected so it knows what right questions to ask for the rag to go and retrieve memory because finding you find tuning. More does not evolve as fast as drag data sets of. All right, drag data sets. You can add contacts every day but then what questions should and data.
 Be retrieved from the rag system is what a fine tune model would do much better. Instead of if you just use like a vanilla base model. So then you have some kind of framework that you think about with fine-tuning. Certain data versus, let's throw that into the almost like Fast data, you've got the fast and slow thinking, or you, how do you look at, like,
 We're going to make that a fine tuning Thing. Versus we're going to make that a rag thing. You do.
 This is a rag thing when there's a lot of factual information that needs to be recovered or that needs to be given out. So, if you're doing customers something like customers support, then, you know, a rag agent or a rack system is really good because you can refer to similar semantic queries, and you can really quickly get around and retrieve them and then sort of give it to the user. And as new use cases, get added as my database is growing, it's plugged into the rag and I can recover them and I can give it. So I'd say yes. So that's where I use fast data. Slow data is more when I want to emulate a decision making process, right? When you want to sort of see, okay? What considerations go into making this decision, it's not really black and white, it's it's you consider multi-variable. As you make those decisions and fine tune models are really good at emulating, how you would think to make those decisions. So what are the more Mission critical operations? You know? And for those we go for fine too and models and then ideally in the best case scenario you would have them both working together because then the fine-tuned model can
 Refer similar cases, draw, inspiration from them. And then say, okay, this is what we've done, but the problem I have is completely new. So I'm gonna, I know what our framework and our embodiment of thinking is here's some things that people have been doing now based on all this info. Here's my suggestion. Or here's my recommendation because I like to think of models really as just humans, like how would you do? Like, okay in my if you ask me, I have notes, I carry my notes with me everywhere. And my notes are like my rag, you know, I have ridden things written down and then someone says, oh let's talk about vaccines. Sure. I have something about these vaccines and you should do, but if somebody asked me, what's your opinion on getting vaccinated, okay? It's something that I've thought about. It's something, I've known something I've gathered from multiple sources, that's what my fine tuned model, kicks in, right? So it's the different kind of problem. Statements, you have different approaches, you would take. Thank you for getting this.
 Podcast band on YouTube now for mentioning vaccines, I appreciate that. It's not perfect.
 Okay, but we were also talking about. So I like this how you thinking about?
 The different decision-making process and almost like, what my values are versus. There's this fast stuff that I can reference, and I don't necessarily need to always have that. In mind, I can reference it. I know where to go to find it. Yeah, and
 We also mentioned about the what were we calling it? Like, the AI workers, the AI Workforce. We didn't really have a good term for it. Yeah. Because it's it's so difficult to put our term to it. Like, what do you call them? It's almost everything. An AI assistant and AI agentic work force and none of it sounds really appealing and none of
 Us. And the issue with the isystems is there are low Trust Systems in a high trust environment, right? People don't like to read documents written by Chacha GPT. Like we were talking about this earlier you when when somebody sends a dog across to you and you see those double hyphens between the text or emojis Galore and your internal classifier goes like nah I'm not gonna pay attention but then you ignore all the effort that went into writing the document. Yeah. Well, it feels to me whenever I get one of those is like all this person. Just phoned it in, they prompted it. And now I have to be the one that spends my time on this.
 Jargon that got output. Yeah. Yeah. It's so true and that's where I think.
 Wait, it's coming back to the coming, back to your point around and I'll come back to this. In a second is when you mention the AI agent, AI Workforce example, right? I think
 Making it more human.
 would solve sort of this problem of also making it more consumable because when when we talk about these sort of Concepts
 Of AI assisted work or AI assisted workflows or AI enabled workflows?
 You also want them to be not only think like a human but also behave like a human, right? So a human would send you a slack message about something that you asked, and the worst kind of humans would send you a slack message that just says, hey, you around
 I hate those. I don't give you any contacts or anything, and it's just like, no, I'm not. Anyways, sorry to derail that know. And and I think a lot about building, these AI agents and Enterprise agents is about building the interaction design around them. You can build the best model. Like open AI is gt40s, are their great models, but they're interaction design is, is not something that makes them makes people comfortable in working with them, right? We developed these biases towards them and we've sort of as a society developed this bias right now about documents generated by charity, that we will not trade and you said rightly, it almost feels like there's just throwing it my way and they want me to review it. They've not even taken the pain of deleting the Emojis.
 So I think a lot about this Workforce, why does the technical part of? It is also like a huge design aspect and the nomenclature aspect. Like what do we call an AI Workforce Enterprise agent thing? Yeah. It's it's it's it's, it's something that even we're still figuring out where we point the finger. But how do you plug in the small language models into that? And I've heard it referred to as almost. Like if you look at the jobs to be done framework and you look at what I do as a marketer, I'm moving around data and transforming data. And ideally, you can get an agent to do some or the most amount of that data transformation, moving presenting it in different ways.
 So,
 Enterprise agents or small language modules, working with agents, right? I think it's important to Define what an agent is.
 An agent is essentially I think in my opinion three parts. Once you have the intelligence layer which is more of the decision maker, then you have the memory layer which learns and remembers things and the third bit is the actions. What can the agent do? Can it perform something? Can it read kind of write? Can it make a phone call? I think it's these three things together that's sort of make an agent in any environment in any setting. Now small language models fit into the intelligence layer of the agent, right?
 And small language models of the Shelf are really not that intelligent. I mean, when I say small, I mean anywhere between, I'd say one to seven billion parameters in size rights and they're not really very intelligent of the Shelf, but they're really good students and they're really, really good at absorbing knowledge. If you teach them the right way, right? How you train when somebody new joins your company or when you have an intern Fresh Off University coming in and you want to train them and how the organization Works? They're fresh, they're ready to learn a small. Language model is like that. If you feed it, the right data of how you perform certain processes, you can find tune it to emulate that behavior, and it's important to use a small language model and not a larger one here because small language models are easily trainable. They require much less compute. You can fully find tune them in a set of just building Laura adapters on top of them, which you end up doing with the
 Larger models, but smaller ones, you can do it entirely, that helps you instill, much more deeper insights into the model itself. When you are doing these fine tunings, you can run RL on them as well. So if you want to do reasoning thinking you want to run some grp or chains on it, you can do that effectively cheaply and fairly fastly as compared if you do it with a much bigger model.

And for slms working in Enterprises, it's essentially about capturing process knowledge. You just said as a marketer, a lot of your job involves moving data from one place, to the right place and then deploying it. But you do a lot of thinking in the middle, right? And this thinking is in your head, but if an agent or a system observes you for long enough, it can pick up on the intrinsic patterns of how and why you are making certain decisions and then instill, all of that knowledge into a model. And that's what we try to do. When we find Tunes, small language models, is, is instill, these intrinsic patterns into them, something you cannot achieve with prompting. Like a lot of times people confuse that can we just prompt them but then a lot of things are Beyond sort of prompting. Well and this is where that like high trust low trust comes in because if I am going to let some more observe me at my job, first of all, that makes
 Me uncomfortable, just thinking about it.
 But second of all, I really want to make sure that
 I am not giving up trade secrets from one angle and the other angle is that I'm instilling the right things into the model.
 True.
 I think it's I also hate being monitored like nobody wants to be seen. What you, you know what you're doing when you're doing but creepily, it's becoming the norm that we are letting sort of observers into our ecosystem, you know, when you go to a Google meet or now even a slacker, there's this AI which is Creeps in and it's listening and it's making notes. I'm like you're so it's slowly sensitizing us to the fact that there's going to be these latent observers behind the scenes collecting data on them and it's only going to say grow from here. Yeah, we are Microsoft launched products where they sort of record your screen and and they collect information. You're even wearing the Medical classes and it's becoming more popular like pendants. That will record your whole day. Exactly. So. So constant Deja capture is becoming a norm but the most important part is where does this data go? And
 What really happens with that data, right? And this is where we've got to be really, really careful. And we need to give individuals whose data is being collected, the authority and the option to control where this data flows and how it's being used. Right? And and as we're as we're building Prem, that's one of the things that we're doing. Very, very carefully. Is when we help you build, these small language models or even medium-sized language models build on your data.
 Our promise to you, is that this data does not leave or ecosystem is only exposed to open source models that we host and we run. And then we have like a seven-day delete policy after that that once your morals are trained and fined tuned and you walk away with them, we delete all of the data from our infrastructure from our logs. So then, you know, and you're confident that it's not being used in a manner that you're not aware about, and that's the most scary part. I mean,
 not knowing where your data is going is is worse than knowing that somebody is doing something mean with your data. And that's what I think we're very careful about. Yeah, and so, getting back to the capabilities that you're trying to unlock with this almost like virtuous cycle of
 Observer seeing how you're making your decisions picking up these patterns.
 And then creating workflows or agentic workflows out of it, like, how does what's that next step of? Okay, I see that you do XYZ whenever you pull up Google ads.
 Now you're creating a workflow or you're fine-tuning a small language model that can reason on Google ads like yeah.
 Land the plane for me. Great. So I think this
 there's three things in building this virtual Workforce that we talk about its data collection.
 It's model fine-tuning or knowledge, distillation in particular, and then it's using them in action. So we cover data collection right data collection can happen on your Google meets. On your notes, on your slack notion process documents, just watching your screen, just watching the screen. Exactly taking screenshots understanding. The steps that you take to reach from point A to point B, that look like success for you. That's the job to be done. And how are you doing the jobs? That's data? Collection is data parsing and then there's building the data sets, right? So imagine, we've built a data set to fine, tune. Another than usually data sets to find tune. A llms are conversational data sets. So there will be like, hey, I'm at this stage and on, I see this. What am I doing next? And the user replies? Okay, I would click on this. So it's a data set for a specific task.
 Or it's a data set for your whole day or like, what is that data set? Look like and how do you curate it? I think that data set is for your role and your job. So if you're a marketer and your Demetrius, it would be demetrius's model. It's dimitrios is way of operating when he is doing some work. So, it's like, your digital clothes, I kick, it's your Sidekick. It's just like was always with you, right? So, this data set, really captures how does dimitrios work, and then why he does the things that he does. So that's the data part of it.
 Then on the fine-tuning part of it. So with Prem we've built this product called Prem Studio, wherein you can feed in all of this data and then we take care of buildings, synthetic data for you, that can be used to fine-tune the slms and then also, selecting which slm is the best for you to find tune and then running the jobs for you as well. So we do all of the mlops monitoring and sort of taking care that the gpus are provision, you know, all the different. If you're doing any RL, we take care of running, RL experiments as well. So that way you can train a bunch of different open source models. And then once you get them back, we evaluate them on some of the data set that we held out as our test data set early on and the goal at the end of the whole training process. Like, what's your training objective, right? Your training, objective, is that if given a situation and certain context about the situation, as the input to the slm, the slm should predict the next step of what needs to be done.
 Right. So that is what we do now. How does this go into action, right? Until now, Asian take interfaces have been really chat. First, you know, you talk to an Asian and gives you some information back but that's not again that's not how to use more than just talking like that action oriented. So
 See. So now the next part is having these action having these sort of models deployed and giving them access to a set of tools. So if the set of tools that you want to run this model on-prem and then give it access to like your calendar, your Gmail, maybe your slack, maybe your GitHub, right, and then you control the permissions of what the model can do for you. And then you just execute and you say, okay now it's running. It's always on.
 We can give it an email address or we can give it a slack handle. It can join your slack Channel as one of your team members. Then in action when you send it a message or when you send it and email, it will emulate how you as an individual would be responding to it, right? And it would do that action, if you started an email, it would read the email. It would think how to meet yours is going to respond to it, right back the response, and send it back to you. And that's where we see it first. You can send it a document to review, maybe somebody sent you a five-page or you send it to him on slack and say hey can you review this and tell me what you think about this or is this compliant or is this something that you know aligns with our companies goals objectives?
 That's phase one is where it's still conversational but you're moving to multiple channels of conversation. You're going Beyond just like one chat you are, you can set it a voice note and it can understand the voice note and reply back to you and text, right? But it's how you would work with a co-worker, the next step after that, which we see coming. And let's say about a year from now is when you start giving it control over your systems and your tooling where the model can take control of a digital workspace and start doing things in browser on your screen, using the tools that you use on a more day-to-day basis to perform more solid actions Beyond conversation for you. And I think that's very important. It's I'm super excited about all the work that's being done for computer, use for browser use. I think they're really, really great Frameworks and we see some really good models coming out as well. We've seen the Agents come out to do it.
 But then a lot of the frustration of the people who are using these agencies, like he's not doing things, the way I would do it or how I would do it. And that's what we want to solve for and that's what we think is going to be the next evolution in this is
 How you sort of delegated tools to do stuff on your behalf in almost feels like you would need many small language models in a way that you're not only going to be using.
 One for Demetrius and it feels weird referring to myself in the third person but you're not going to have that. As this is my small language model and it's my one that's been trained and retrained and continuously retrained on. It's almost like this is my Google analytics. Small language model that my big brain model can call as a tool and or there's the web browser model that can be called as a tool in that way. Is that kind of how you're thinking it's going to shake out?
 The yes, there would be two ways there would be almost a hierarchical structure of models which would be experts in certain things so you could look at it as a mixture of experts but decoupled almost make sure of experts like in one. We so we decouple them and we have lots of small language models but you would almost have like the social media side of Demetrios the social media expert initially when we are having a less amount of data, we would keep it confined to a singular model, right? Because then otherwise you become too thin across if you spread across different models, but as the volume of data grows, yes, you would want to split it out into different sort of individual language models that can take care of it. But on top of it, you may have your vision models which are parsing the screen and understanding what's on the screen, where do I click? Where do I press? So that would be the sort of layering on top of it. Is to understand context to understand different tools. Maybe we have something that can take control of your phone and do things on
 Your behalf on the phone so that would be the layer.
 And then that would parse the information and then give it down to the ideal model depending on the application you are in that, okay? Now how would Demetrius maybe, you know, do marketing on telegram on his phone, he's in these five groups. What do we send? We've just launched a new to show. That's always been about chilling. It's always, that's, we're on telegram, it's just chilling. Well, one other piece that I wanted to touch on was how you think about the differences between the workflows that are almost hard-coded? And when you observe me doing something multiple times in a row
 It's almost like you know that I'm going to do x y z and there's that next best action and you don't necessarily need to have the agentic capability. Be this open space that it can choose whatever it wants as an expect best action because you've seen me do it this same way five times. So and so it can be a hardcoded workflow versus oh just go figure it out agent. And then you have that reliability a little bit more. Certain you what are you talking about is almost like you can build process Markov chains where
 A Markov chain is essentially a set of events happening and then a probability connecting them saying, okay, this, if these three things happen, what's the probability of us going into, either of these one or two ways and if there are certain chains which are like not to Divergent and they're always going straight. Yeah, you can be certain that if these four steps were taken, this is what the next step is going to be. And I think that's going to be more on its gonna, this is gonna sound meta but if if you were to run an analysis on the data not to not to sort of emulate how you behave, but to understand. Okay, what patterns do I see in this Behavior? I see a lot of noise or a lot of different distribution for when you are working on Twitter because you're doing like 100 different things but then when you go to Google ads, maybe there's just one workflow that you are always doing that and the distribution of data and that looks fairly fairly just linear or it's very it doesn't have a high amount of variant. It's really tight and in one place.
 So I think it would be interesting to run some experiments, just on the data set, that's collected to explore or to surface what these latent patterns are. And then maybe
 To see if we can control the inference space when the model is running in France. Based on these inputs maybe there could be some work done with memory Frameworks or some confidence course being passed that hey, okay. If I'm at this step has the meteors just done something like in the past. How many times has he done something else? It's about framing those questions retrieving that information, and then sort of taking the right step and controlling controlling, let's see, your answers space during and Friends. Well, the other piece on this is that a lot of the things that I do are not just specifically done in the browser. And so there's taking data from the browser, and then again, transforming it or downloading it to my local computer and then putting it on a program that I have. I'm thinking specifically about when I edit this video. Yeah. And I'm going to be taking the data and then putting it on to the DaVinci Resolve and then I do a few things, I'm going to import the different vocal tracks.
 And the different videos, maybe do some color correction, but I'm also going to put them on. One timeline is going to be just the full thing with a few edits and then there's going to be the clips timeline. And so all of that is very menial work that I every time I do it, I'm like I really wish at least like some kind of a template could be done here because it's not necessarily that it's a template within DaVinci Resolve
 It's not as easy as that. It's it's like take these that are in this folder, upload them all. So, upload these other, the intro music, and then create these different timelines and find the different clips and then the clips are going to be verticalized. So, there's all these things that I know could be.
 Templatized. But
 I guess the question that I'm trying to ask is there's different abstraction layers that you play at and that's just for one of my workflows. I imagine somebody that is a dentist that's trying to figure out their systems to work with and the insurance that you can pull from and trying to
 Charge their client.
 Uses a whole lot of other systems, right? And so,
 how can you enable the agents to take actions when the distribution of systems is so large? Yeah, I think when you move more into working with custom software, it really starts getting challenging with less examples to train or fine, tune a model on and then delegate to it. 100% responsibility to be autonomous and work on your behalf because you are making not just a big plan of execution. But at each step in the plan, you're making a creative decision of what it should be like your video. Do I do like three seconds, what title font do I use color grading at the lighting was bad that day and my other videos of this kind of color grading. So you're making a lot of like these Atomic decisions as you go along the process. Right. And this is where I believe I believe this is also a lot of creative work like there is creativity in every field, engineering medicine video editing. It's a very creative.
 Process.
 In such Fields. I think it's really going to be human augmented agents that run so you wouldn't give them complete Authority and autonomy, maybe you would make a plan for them. You would say hey okay I want you to now edit this video.
 Here's the plan. I want you to do the next following 10 things. It's a first is, okay. Figure out a good title sequence. Then, first five minutes, I want you to focus on this two on this 300s. Maybe you give it that whole plan and then you let it go and do its thing today. We rely on these agents to make the plans for us as well, but I think it's it's not the right approach because when they fail and they fail miserably, a lot of times, there's not a lot you can do about it. So we need something where, where me and the AI agent have like a common playing ground and then something we can both read on. We can both Riff on something. Maybe the Asian can add to the plan and say bro I don't think this is a good at this, so you buy on the plan for a while and they're like, okay, now the plants ready? Let me go and try and execute, and maybe it's going to stop at some point. Maybe you get a notification saying, hey, these, I've done these four things. Do you want to review and maybe this review? Step could be a part of the plan saying, okay, step one, step, two, step three.
 Review, step 3, step 4 review. So you work with it instead of just delegating and then going to bed and hoping it's done for some for some domains you can do it. But it's not always like now you've got like coding agents, you've got Cloud code would sort of go and you give it a sort of issue and it creates a PR for you to write the code for you, but you have to review it and you have to go back and forth sometimes with it and it'd be the same with these sort of you bring the same analogies to these different spaces and these different tools but it's just that these are more information sparse areas, they're more creativity, which areas. So we need to think of Frameworks of how humans and agents would work together here.
 and I guess the other thing on the information sparse piece, is that
 A lot of this stuff doesn't have apis that you can just ping. Yeah and so integrating with these tools is so hard because it's not just all right we have an API or an mCP server. Yes. And so how do you even think about that? And that's where a lot of the I think people get excited about the browser use or the computer use because you can bypass the API and you just go into the GUI. However I think anybody that's played around with computer. Use is like yeah, it's cool. But it's also very hard to make consistently do things. So first off, I'm bullish on computer, use and I, I completely acknowledge that.
 The interface is we have right now for tooling Jazz apis mcps. They are not for its a consumer software or consumer products. They are more for SAS all SAS tools. Have an API which is very easily consumable and because they were built for that purpose, but Premiere Pro probably doesn't have like a kick-ass API, you can edit a whole movie on, so exactly, because it's not made for that thing, it was never made to be used with an API, right? It was made for somebody to look at it to see what's on it and then make those decisions and
 I think this is by a computer, use will really become the norm for a lot of operations that we sort of work on, with AI agents.
 And yeah, as somebody who is sort of always playing around with computer, you as I completely acknowledge that sometimes it's too slow, sometimes it rears of path. Sometimes it gets stuck on really dumb things. Like, bro, it's right there. Come on, just scroll down the damn page. Exactly. I and this is where sort of purpose specific training data is going to become super important and this is where fine-tuning will come into play. You cannot prompt it. You can always prompt because you prompt will explore because there's so much context it has to go through, right? If you want long tail tasks, it needs so much contacts and this is where you want to do. Process, find tuning on this model, I see this. And then I click here and then I do this. And then these are the chains. I think I why am I clicking here? Why am I going there?
 You know, I always think there's going to be tools specific models that come out. So computer, use model fine-tuned on Photoshop, right? Imagine if somebody at Adobe, sat down and collected and made this data,
 The query being I want to, you know, add this Hue to my image and give it a 1970s Vibe, right? And then there's a screen recording of five minutes of a great designer doing this. That's your data point. Yeah. So there would be these process specific models or sorry software specific models that would come out that would then help you do it and then you can find to them further on your style. Okay. This is the base model for Photoshop. I'm gonna make a Demetrius version of the Photoshop base model because that's my style and my wife and then I make it run. Well it also makes me think like then where do you plug that in and how do you interact with it? Because we've seen and
 we know that the identification of the internet and Sass is coming and it's almost already here and certain ways like if you're dealing with cursor, if you're dealing with lovable you just talk to it. Yeah and then it gets done and so in Photoshop
 Think Photoshop has kind of tried to do this, but it's more with image generation where you can generate an image. Yeah, I haven't used Photoshop in a while, but I, I also let's think about like, Premiere Pro. And I want to edit this or
 Create a few Snippets or whatever. I can, I just talked to it and then it does, it create a new timeline and then do this, or I don't even need to be that specific because it already knows if I want to create Clips, it's going to create a new timeline for each of those. But am I talking to
 Photos or premiere.
 Directly, am I talking to and overarching agent that then will use Premiere as a tool and like, where does that abstraction fit in, right? Because if you're thinking about it from the Enterprise perspective again, going back to, we've been talking very consumer ish but
 If I now am in the marketing position and I'm trying to do these three things that require me to use a specific tool that we have at my company.
 Maybe there's the API for that. Maybe not like you were saying, like SAS there's great apis because that's how we've been dealing with them but maybe it's local to my own computer and that's how we have to use it. And so do I have my agent that is powering
 Or my sidekick. That is now going into each individual SAS tool and grabbing the data, transforming it, bringing it into the next task tool like, or is it within the SAS tool? I tell that tool do this.
 Yeah, it's something. We've been thinking about a lot and I think where we've come down to is that is going to be an intermittent layer, which is more at an operating system, level in the set of the application Level, you would have, let's say,
 A dynamic model orchestrator, who would given the task, of course, plan on what sort of models, it would need to use to reach the final goal, right? So if on your screen there is Premiere Pro open or you wanted to eventually open Premiere Pro and do something that the planner would, this would be like an intermediate agent that's running in the middle, you would give it. That instruction is job would be. Okay, I first, come on move. The cursor. Open Premiere Pro, or use the CLI to open Premiere Pro and then behind the scene and say, okay next step load the Premiere Pro model in memory, start using that foreign friends and then. Okay, now look at the screen Premiere Pro model and tell me, I want to watch this goal. What do I do? What should I do next? And then once the task is done, that model gets offloaded and then maybe you are you want to publish on YouTube? So like the YouTube specific browser use model gets loaded in and step one. Open brow.
 Are go to youtube.com step. Two career step 3, create a title clear title and Demetrius the style because it's fine-tuned on how you would give it a title and that's where sort of this personalization. Because there's a whole thumbnail. One, there's a whole, yeah. So this it's going to be this family of models. And we're 100% confident that it's going to be a billion models. Fine, tuned for specific people and applications that are going to be live out there that will get hot swapped at runtime and then we use for inference.
 Boom. Yeah, right right, bro? It's right there. Like