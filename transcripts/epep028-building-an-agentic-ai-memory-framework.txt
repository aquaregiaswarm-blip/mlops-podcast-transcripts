So imagine memory as a tool something, which is still debatable. If the AI agents actually need a mechanism to forget. Imagine it's not us who are controlling these trekking parameters, but it's an agent with a vision memory, should be able to communicate properly with the textual memory that it has access to from day to day.
 You dove into the memory world, for the past five, six months because you build out cortex, can you give me a lay of the land at the high level. So, when I was starting, I think at that time, there was not anything, very specific, there was like GPT, and there was the land which level is like quite popular at that time. What piqued? My interest was a.m. kind of came out at that time? It's like around, I think five months ago, five or six months ago. So, also, like Amazon community had a very nice reading group discussion on am, and we just like discussed the whole paper there, which was very helpful to understand, the things, even better. One of the key ideas I saw in Ammon was
 Let's say your inserting something into the memory or like database or whatever, a sort of a collection, you're saying, which the agentic system will have access to. So, the key differentiating factor, was it sort of forms relationships, I'm having this talk with you right now. And currently, we gonna have this talk, like, I knew that in my mind, so let's say a few days back. So currently I am connecting this current state with my past memory because it's sort of interconnected. And if you see, there's a relationship between these two memories, it's like, we can also like name, these relationships, something like, is there a result of that? So, current state is a result of the previous state that we were discussing about previously. So something similar like, mm does is
 It takes different different memories that you want to store in inside the whole memory, collection, or whatever you say, and it sort of forms relationships between them. So if I dive a little bit deeper,
 Let's say you are inserting something in the memory, you take that and if it's like the first thing you're inserting, it just insert it directly but before inserting you just analyze it a bit like sort of come out with a summary of like what it's about. So we are calling it like context. Then we also come out with like, keywords and tags. So like, what are the main key things in this? Now, by the way, this small memory can be as big as possible or as small as possible, that's
 On the client side that we're giving like and that's like on how you actually use this memory system, that's what AM was trying to do. And, yeah, in a way it's, it's like a Knowledge Graph. You've got this chunk, and then you have metadata around it and that metadata connects to other pieces of metadata. Yep. Yep. So the metadata doesn't directly connect but you have these sort of metadata and there just so currently let's say you have like few memories already in place then a new memory comes and it's sort of does a semantic search between all the memories that are in the collection and let's say it takes out like top K of the memory. Now once it has like the top came memories, it asks llm with their memory representation so we don't use the whole memory reviews, the summary and the key words or like tags and whatever other materials store, it can even have the timestamps and then
 we asked the element with the new memory that's coming in that, hey,
 Do you see any sort of relationship between these existing ones? Which we found to be similar to the current coming memory. Now, if you do then just connect them. So what I mean by connect them is
 update the existing metadata and also give a nicer metadata to the current coming memory. And that's how the whole graph keeps on forming. So it just sort of makes a Connections in between these two and at the time of using using of the memory. So like let's say aquarium comes in now, we have to look for like the most relevant once from the memory. So what we do is we just Analyze This query with an element. So the one differentiating thing I think in Ammon is
 On every insertion and before like every retrieval we do an element called because we are trying to pre-process and mm doesn't really focus highly on the latency side but more on the quality of the memory that you are getting out. I was gonna say it. Sounds very it can do a search Problem.
 Yeah, yeah, for sure. So currently we just take out the metadata thing is and
 Now we just literally we do a semantic search on using two things. One will be the what the query was. And the other thing will be the keywords from the matter someone from the query that we extracted. So we do two retrievers parallelly at the same time and then we take those two results and just feed it onto the context, and
 Do whatever we want with it, like pass it to another them to answer something or that's very much on the personalization side, right?
 Yes. I mean, you can literally do anything with that. And this is like the most basic core part of Amen. Where it didn't really perform that well, compared to the existing methods that was there. But what was striking to me? Was the relationships forming in between. Okay. And I was kind of trying to think very deeply on like how humans think about memory and how we can actually improve it using this relationship Foundation because I the only place I saw this relationships in place was in graph rag.
 So but I I currently feel that in graphic, we have all of these like different nodes and we compressed down information way too much. So that's that's one of the issues and that was not there in the ammm thingy. Then you got inspiration from a man you thought deeply about what and how memory Works within humans. And then you said, let's take it another step and let's create our own memory. And yeah, I was I was like a brainstorming with
 few of my friends and like,
 Whoever's was like, in this space and was reading papers, basically, and saw that.
 So currently I was trying to I think I used like deep research on like to understand basically how human or things, specifically, from the memory perspective like on a very high level and also a bit lower.
 So they have this thing called like, long term memory, and short term memory. So,
 I mean we have recently seen in the AI space or that element space, the short term memory. It's it's nothing. It's just the recent window of the chat that you're having with the
 Is entered the conversation assistant or something that's one form of short-term memory, but I wouldn't say that's a short-term short-term memory, because it has to be a bit bigger than that. So, but about long-term memory is this is something crucial. I think that's where all the magic happens in the long term memory. So,
 The relationship forming and like everything storing nicely. And this whole big graph that we're storing in inside.
 That is part of the long term memory.
 So and we don't expect to long term memory happen like as soon as possible. So I mean, it can always keep running on the background. It's it's something we don't expect to happen instantly but it will, it will take its time. But as you as we are having this conversation, we are building onto things constantly in the back of our minds. And it's not like, I mean, I'm using certain parts of it, but that's from a short term memory. So, short term memory, sort of like a window. It's constantly updating updating updating but in long term memory, yes. Just storing everything like kind of dumping and
 While we are dumping things are producing parallel in the background, which is extracting lots of Merit out of it and interconnecting things in between. Yeah, I remember taking a online course of while back now on and it was called learning how to learn. Well, and it talked a lot about this, how we can create memories because that helps us learn. And some of the things that it mentioned was the more that you access
 From the long term memory. Yes, the more solidified it becomes as something that you now know. And so the frequency and that's why you do like flashcards when you're trying to learn something because you're trying to remember it and you can or you can maybe you can and then you flip it over and then you remember it. Okay. Cool. Yeah. There it is. And so it accesses it again and
 you basically do that until you now.
 Know it.
 And then you can spread out the frequency.
 So if you're trying to learn something and you're struggling with it, maybe you're doing these flashcards every day or twice a day, three times a day but as you then don't need to flip over the card. To remember something.
 you can space it out and do it once every three days once every five days once every week and so it feels like
 What you're talking about, it has a little bit of that inspiration but the other piece that I think is interesting is that you're you're also mentioning. We've got this long-term memory and we're able to throw things in it. How do we weight it?
 And how do we know that things are important from it? Because for humans we have something that is like oh the more frequently that we access it the more important or the the more solidified it becomes in our memory. So I have used these, like, Anki flash cards. I think it's quite popular. Like, everyone is trying to get learning something. I remember, like, trying to learn Japanese. So I was just like learning here. They're gonna character through like angular's. And I mean, the concept of space certification. I think that's that's the dumb. So happy that so that's quite popular. And
 So this is something very much seen in humans specifically because we tend to forget, we tend to forget things a lot and this is something which is still debatable. If the AI agents actually need a mechanism to forget or not. Hmm. So there are a few people who actually believe that. Yeah, a systems need to forget because information gets outdated. We have to prune the things out. Yeah. And there are lots of strategies to remove things out.
 And also some people believe that, no, it's an agent. It doesn't have to exactly act like a human, like, just dump everything. And this is used the most important ones and archive, maybe it's in a way. Yeah. Well, also the other piece, I remember that you were mentioning too was how humans sleep and sleep is a huge factor in how we are able to bring things into our long-term memory. Right? Exactly. Exactly. So yeah, I mean there are papers like where they say that human keeps on processing, when they're like, sleeping, it's
 The thing, like, the term is kind of consolidation. So, like human memory, consolidation happens when you kind of arresting or like when you stress levels are like quite low. So, and your brain is like, not I guess multi-functioning and doing a lot of things together. But yeah, so yeah, it's just doesn't need to sleep so it can do so many things in the background. But when you're thinking about how to consolidate different memories, how did you go about that? Because as you were just saying,
 you're inserting memories in with their certain metadata and then you're constantly updating this knowledge Graphics. So cortex is something which I build on top of aim at first. So I took all the inspiration from am on how it was happening and I thought, hey, we can actually improve this thing, and there's so many possibilities in here. So what I did the first thing was, oh, before I mentioned this, I have to also mention this that, have you ever used obsidian? Yeah, yeah, Force. So, they used one method called, I think, I think I'm pronouncing it wrong, but it's like that I stand something like that.
 So, what it is, you can reference things in any page from anywhere. So, at the end obsidian gives you this whole interconnected graph where you can check that check like different clusters on what all things you have mentioned in which page connects to which page. So your whole writing journey is kind of captured in a graph and what all are the interconnected webs in between that comes out for you to see so you can get the whole bigger picture.
 So, even paper like, mentions a lot of words that you guys then and sorry if I'm pronouncing that wrong, but whatever. Yeah, so mm, just forms like relationships in between them. So, but I thought is currently
 We value things differently all the time. So our values and everything like depends constantly on
 A lot of actors, it might be our own biases and for our previous memory was, what have we seen our life? What we have like gone through
 every day I think in our life, which is totally different for every single person,
 and by person, in this case, I mean,
 Memory.
 Okay. So yeah, currently when we are like what the key change, I think I made was
 I sort of named the relationships that each memory is being connected by.
 So what I mean by that is I had some key terms. So initially I was just like experimenting with what if we just name it extends by or something like
 Definition of or something. So, I had some hard coded key terms in here, and I tried to extend it extended more. So, that was there. And also like there were times, like, reciprocal of something like defines. So, mme defines this memory and now, but we don't really know that how much it defines. Is it like? So if we talk about it, mathematically, zero being the there's like no definition between each other and one being like fully is the definition of another. So one being that definition of other so it can be scored. So we can actually score that. What is the relationship strength between these two nice? So, and this is something we don't really do by, like, we don't do like manually or like any sort of instantaneous thing in the pipeline. So while we are forming this meta connections relationships between
 Is memories through an llm. When we are asking the LM process, we ask it to also give a score
 And only score it if it's like, very confident that there is some sort of like High.
 Lee weighted relationship is present.
 So that kind of gives you the whole over weight. I mean, whole weight of the whole thing and
 the other thing is also we ask it to like name the relationship out of these possible naming schemes.
 So that's just a big set that we have and it just yeah I learn basically choose that how it is connected to each other. So does it extend or is it a definition? And there's one more other option that is? Yeah, should you be merging to Memories? So, sometimes in our memory we actually tend to even merge things into each other. So and I I kind of feel like that. It's it's very important. So that's some feature. I also added there
 And yeah, sometimes we can.
 falsely remember things because I think a lot of times
 We will merge two memories and then we'll remember. Oh that was maybe if I'd been to a place twice. Yeah but it was a long time ago I mixed up which time I did something. This is all experimental. This is I I just wanted to see like what happens at the end.
 so,
 There were like, few soft few types of merge that we had something like an update, which you just said. So an update, what happens? We just concatenate different memories into one and it just becomes a new memory.
 Yeah. Yeah, by the way, we are maintaining all the history in the metadata, so, okay, if you need to read separate them at a certain time, if we can do that, and did you take any different approaches?
 From Amen, on the LM calls and the search and retrieval style. Yes. In in from email, I mean they just had a simple prompt where at the time of inserting a memory, they used to process it first and then insert. And what I mean by insertion is like it forms relationships between the top most similar memory that it could find in the database.
 and at the retrieval, it just used to take the query and then
 just take the query and do semantic search on the top most,
 And it takes the top most K memories and also goes one level deeper because now we can see for all of those top chem memories. What are the connected other connected memories? And you just take them also into account, okay? We will be like less similar to the original query that you have. Yeah, I think these two ways like the key factors but something which we added in cortex was
 We added bi-directional connections between these two. So
 There was only a single connection between the memories I as far as I remember. So I changed that to like bi-directional connections because
 It doesn't make sense if one is going that to only one side because for every connection that is represented in the graph.
 It shouldn't be only that, it defines this. I mean, we can even have a backward connection saying
 It is defined by. So that at the time of retrieval, if this one comes up, so this also has some thing to give, like, more context to the model. So that at the time we travel, we can use this. And this together. This is what we call depth in graph Flags. So we can actually customize, like, how deeper to go, how many connections deep to go. So, generally in practice like it's it's nice to use just a depth of one or two, because three gets like way too much sometimes and too much noise. Might come up, come out.
 Were you vectorizing this also? Yes, it's a, it's a whole vectorized data set only. So, I mean, we just use a single Vector DB there is no graph rag this, sorry, there's no graph DB that we are managing for this specific use case, Okay? Because at the time of History will be just doing semantic search. So yeah there's that. And by the way, what I'm talking about right now and that's that was like the Intermediate part of Cortex like when it was like just coming out I was experimenting there. Others V2, I there will be improvements of it. All right, let's talk about that. So currently there are people are like coming out with these AI assistants or agents where
 And they have to do multi-domain tasks. So, the domain is not really connected to each other, it can be connected, somehow. It might not even not be connected. So, let's say, you have chat GPT right now, right? Or like, any sort of AI assistant, which you use to ask for a lot of different things.
 now it can be about your work, it can be about your personal life or it can be somewhere in between because
 Your friend might be working as a co-worker for you. There has to be some sort of distinctions or like,
 Collections. I would say that we currently automatically have as a human in our mind and we know how to separate them and also like sort of form connections between them.
 So I kind of visualize this and I like did some research on the same that and this is sort of like high article collections.
 That's, that's what we are like going towards right now. So
 The existing systems, whatever we are like, seeing in the AI agent space for memory where only focusing on the flat memory structure, that's what they're calling. So what happens in a flat memory structure is there is no sort of like hierarchy or
 So, when you say flat hierarchical structure, are you talking about something that is
 less like,
 Notion where we have all of our different files or any file structure, where you've got your file, you click into another file and you click into another file and it just keeps going down the line.
 That's not what you have right now. And that's where you think it's going, or is it because right now, as you mentioned, it's more like obsidian where everything is just on this flat connected space. And you have clusters over here in clusters over there, but there's no hierarchical way of doing it. Exactly. So yeah, exactly. You explained, it very nice. So just like, how if I system works? So in file system, there is always this, like hierarchical structure. So, first of all, like, if you're searching for something in your laptop or desktop, you're looking for, let's say if folder, which has a very high level overview of like, what you're looking for, then you'll go inside of it. And then you look for
 Maybe a very specific things. So sort of this is like the concept of categories and like subcategories. So imagine in high level you have like a lot of different topics in your mind like work. It can be personal life. Now all of these different topics have like sub topics internally
 Inside work. It can be your current company that you're working at. Maybe you have a side project that you're also working at and it's making money for you and money. Also maybe is connected with like Finance. It's like maybe bigger Topic in general in your life and finance even connects with money, but
 It has also a sort of triangle for each of these like top to bottom structures, we can see sort of like a triangle farming, which has like multiple things connected to each other. It's it's like a tree basically. Yeah. Just this is something that humans I think use like deeply because when we are thinking of something we sort of think I we think like very fast but we sort of think through hierarchies first.
 And kind of connecting things together. So we go down from top to bottom. Also, we are taking into account or short term memory which which creates some sort of biases on like, how we are kind of traversing, the whole thing.
 but,
 This is something which is missing on the current systems, it doesn't really represent these hierarchical collections or the topics directly. Okay. So
 So this is something we should represent all so, and take into account.
 And sort of build like a hybrid search, which uses both of the both of the previous way we were doing like retrieval and storing and also it makes use of the whole hybrid thingy. What I just told about the collections. So in cortex we like we are saying it. It's
 Smart auto collections. So what is that enable them? I is it just that it's faster, search know it's not fast research what it enables the higher quality search. So it gives you much lesser noise compared to what I mean. Flat search will give just to give an example. Let's say you search for something like
 fix this.
 No fix. This can mean literally anything. It can mean like fixing your car or it can mean. Yeah. What is this? Exactly. So things just like what is even this? Yeah so this it means so many things in your life and if you use a flat tire Care model it can just fetch out the fix your car or like, I don't know. Fix your friends brain or something like anything with fits and the metadata. It's gonna grab exactly. We are kind of providing like the whole. We are providing an option to give context. Also this actually needs. This is ultimately a context problem. Yeah. So when
 we are kind of doing retrieval, there's an optional context parameter, but overall
 It should. First of all go through the what are the top level collections are, what are the top level keywords are? I will talk about it in terms of two, two ways. One is like, let's say, you're inserting some sort of data, so memories these memory systems in general, I think kind of has like two key functions. One is insertion. Another is a retrieval. So, imagine you just have, like, something with your constantly inserting, or it's like happening in the background and the background. It can constantly keep on retrieving and use that however, you want in your agent systems. Keeping these two things in mind. If we talk about insertion for, let's say this auto collections thing, which we have in cortex,
 so,
 When any memory comes in, let's say you have some existing memory already in place and when a new memory comes in it kind of categorizes based on what the user Persona and what are your priorities are this. We can actually write down initially. So based on that it kind of categorizes that
 If that memory represents just on High level like work or if it represents work then kind of subcategory can be.
 First job. And then some more there can be some more subcategory like python. Maybe it's something related to python that you have,
 Are trying to, like, store in your memory now.
 Sort of in this way we like every single memory when it like comes in, it's sort of creates like all of these.
 Topics and then its subcategories only if it means something I mean it's optional it can just be a very high level thing. You also that I hate my job. Yeah. So that's like just something which is like connected to your work. Yeah. And it doesn't really have any other smaller subcategories to it. It might by the way. So something it can have like let's say emotional aspect of it. So job then emotions.
 now, we form all of these like small small categories and after it reaches a certain threshold, we checked like what are the frequencies of all of these different
 Memories and what are their categories are? So if it exceeds a certain threshold we form a collection out of it. So now this is the collection and anything. Whenever like we we by the way I didn't mention that. How we are kind of forming this categories.
 so, at the time of,
 Getting the metadata out of a query. If you remember, so in mm, or in or, or in cortex, you're making the llm call. Yes, in LM goal, we have also asking to give it a category specifically, and with some context, which is optional to take into account that, hey, it already exists with these try to keep it minimal and Noise free. And so that it doesn't really
 Give you any kind of category because you can name one thing in many different ways and that, that won't be good for us. So how it started, it should kind of like,
 Keep on going on that direction and not really diverse a lot. After this, what happens? We asked the 11 for the different categories and their connections. I mean, not connections the categories. And this up category is just named them basically. So we check the frequency, we form all of these, like small Collections and when we are following, when we are creating these collections. What we are saying that, hey, now we have this, let's say 15 or 16 memories together. We are forming this collection.
 Let's give it a description, like what the whole thing is about. So
 Now, the description will be sort of like, what are the key things that we are keeping in the memory? So this is something that happens in the background. By the way, it's not something is actively happening when you are like using the memory system. So it keeps on running on the background which keeps on checking that if it has reached a certain threshold or not. If it did, then start a background process to get a collection out of it. Where
 You give it a summary which we are also calling as a description and give it a query helper. So what query helper is
 this is something that will come at the time of retrieval. It kind of
 It is a prompt. So it's it's a meta string. You can say which will help you to create a prompt on how to query this.
 And so when you're making that background call and you're putting it into your inserting, in a memory, you're doing both at the same time, one for the hierarchical structure. And then also all of the stuff that you were talking about before with is defined by and what the score is. And so it's one, one llm call that will give you all of that. And then you can parse that out and say, all right, we have everything we need now for both of these. Yeah, these two are happening, parallel in the background, so it's not really synchronous. So don't they don't really like affect the latency together. So one we are calling as the global search.
 This. It searches things like globally and the other we are calling as like auto collections search. So this is like a very constrained and narrowed down search if you look at it. Yeah. So at the end, we take some of this and take some of this and only take the most important ones that matches the most with the query, like, what actually we are looking for and just feed that alligator. And that is a
 Memory retrieved item. You can say, so
 Yeah, to continue about. I think how I was
 Talking about the retrieval of the auto collections. So we sort of like form this query helper, which is like,
 How how should you even go about querying this collections? Because
 now, if the query is like fixed this. Now, if it matches with the collection, python sorry collection work. Let's say now in work, the query helper would be
 based on the description and does it really help to even query? So there's like two options, one is to query or even not query.
 So, now, if you actually want to query this whole collection, then how should you modify this query? Because in rag, there is this concept of, like, query expansion or rephrasing, where you actually rephrase the query based on what the context is, but sometimes like fix this might be related to the previous 10 tons that you are talking about because if you don't provide it, some sort of context, it can't understand. So
 Query helper takes into account, like the context and this new query, and it checks, if it's relevant to this collection or not because it has access to a description also. And since it has all of these things, it will generate an answer in yes or no. Like let's say if it's yes then if it will modify this query with fix this thing about python let's say so it will kind of modify that whole query to be.
 Retrievable or like searchable. So,
 okay, so till I, since I mentioned this point, so there is one key thing that is at the time of History will, we are taking this.
 And we are doing two things. One is on the smart collection side. We are doing two things. One is
 We are taking this query and sort of doing a semantic search over the different subcategories and collections that we have. I mean over the whole collections that we have, let's say you figure out four top collections out of it. The most similar Ones based on its descriptions. Now you give it 30% importance only. So now if we form sort of a composite score because currently, we are giving it only 30% importance. Now, we are giving 70% importance to what are we querying inside? All of these top kick collections. So inside all of this topic collections, like each of these collections might have, like, 15 or 16 memories or like whatever the threshold you have set.
 Now among them we do as semantics search through the modified query for each of them, by the way.
 Now, we are giving this 70% importance and finally Buy.
 Two important scores like 30% and 70%. We are finally coming up with a composite score for each of the memory points.
 And then we started and then we see like what are the most relevant ones? Let's say you only select obj out of the final composite scored memories that your retrieved. And then you take this into account from the auto collections
 retrieval and you take into account the whole Global search retrieval also and then you just select, I mean, however much you need and you just give it back as a
 As something like, which element systems can use. Yep.
 That's that's like, the whole overview of it. I guess. What about like
 When you want.
 Time based questions or recently and I say tomorrow, I'm doing this. But then tomorrow becomes last week, currently, I realized this a bit late while we were like building cortex, but it has support for the same thing. So, there are two things I can see right now. One is when we want to do these recent based queries. And when we want to do a particular date range based queries, so it might be something like
 do you remember that? What happened on March 20th from between March 2025 to April 2025 like on the first 15 days? Yeah. So
 So that's like one one way and another can be something like, hey, what did I talk about? What did I talk today yesterday? Something like that. So there is one step that we are. We are wanting to do. So for all of these like date range based queries where you are expecting them have to options. One is to like provide a date range and another is to kind of
 I mean yeah we are calling it like temporal weight so what temporal way it is,
 Now the weight can be anywhere between 0 to 1 and what's 0. Like what temp will be 0 means is you don't give any sort of bias to recently. So
 Currently it's just happens like normally how it was happening the whole hybrid search, but if the temporal weight is like one point zero. Now what you do here is you you do the retrieval pay from just STM. So what I mean by STM is like from just a short term memory that you have. And since short term memory is like a window and now you give importance to the most recent ones only.
 So that's that's something. And now if the temporal weight is like let's say, 0.7 sort of. So in 0.7 what we do is
 We at the time of retrieval, we are going to a long-term memory and we are taking the whole query. And if you remember, we have always a limit at the time of search, that how far to look back, how like, what should be the size of K.
 So, currently, we are kind of multiplying it by some some Factor. So, based on like, how what your weight is we take, we create a factor and we multiply that so that we get even a bigger window. And now, we basically take all of this into consideration because at the time of
 Auto collection, search. We have this composite score mechanism, if you see so in composite score, it doesn't matter. If I mean, if you if a collection gets like higher score because it will only have like 30% importance, there might be 70% more importance on like something, which
 It was like lower down in the line. So overall, the composite score can give you like a
 better distribution. I can say, I think I'm understanding this.
 Is it keywords that are triggering? How much weight you're giving to that long-term versus short-term with keyword? Yes so we have like all of these set of keyword checks to do if I say last week that's a keyword or if I say last year, that's a keyword that returns, okay?
 Yes exactly. So recent would have liked something 0.6 as the K so recent I mean yeah we shouldn't like keep it more higher. So
 Last week, we can have something if a higher. So the the temporal weight is getting decided based on like what the keywords are? We have like, a huge set of keywords. I mean, this will be basically did because it's efficient, but, and even better method will be to ask him if you're okay with, as having more latency on the whole system. But that's something I think we all can improve and like, how we are connected currently deciding the weight, but the functionality is there.
 And there is also one more parameter where we can pass the date ranges. So it will constrain the whole search between only these two ranges.
 And it will use all of these con Auto collection thingy and the hybrid, the global search between a certain data range only, whenever like you're taking a query, you can always extract some data range out of it. Using the whole context before quoting the memory system, so that you have some date range to look around for. So it's seems like you've got
 a lot of data that you're pulling from whether it's the short term context and you're deciding how much short-term versus long-term,
 Versus the hybrid search or the file structure, for lack of a better word. I can't remember what you were calling it and the knowledge graph style. Yeah. Do you find that it all kind of collapses upon itself if there's a right or wrong answer, or
 Because I am imagine it all leads you to the same place. If there's one answer.
 But maybe when it's very fuzzy you can just get this blow of a whole ton of noise. Yeah, yeah first to check the fuzziness. We are kind of doing like when similar things are coming up. You obviously are doing like literally applications there. So because at the core the memories that represented as like an ID in the database so you can do direct applications there. Now
 how much noise to actually incorporate and that actually depends on your
 Limit. And what I mean by limit is like, oh, how many memories you actually want to retrieve? So you can always like donate down. So it can be like, I just want like two memories and that reduces the noise itself. Yeah, I think if, if you're like losing out on something, if you're like, losing out on something just increase the K probably. So you can get like more memories out of it and you can totally like shut down the global search, that will be super constrained and so you can just remove the knot. You can do that on a Case by case basis or you do that. Just oh, really? Yeah. So it's just a flag in the code base. So it's like, it will be totally shut down and only the auto collections thing you will be working. So, there you can get, like a much constrained, and if it's like,
 Like a case where you don't want any false positive so that will be the case, probably have you messed around with. I feel like there's potentially some cool stuff you could do where it's cascading. We're first, you try with one and if it doesn't work then you can go a little bit deeper and a little bit deeper.
 Maybe you try with just the short term memory plus hybrid. Yeah. Or if you can't find it then you add in the knowledge graph or and if you can't find that then you just say all right well let's try again with everything and see if we miss something or let's increase k.
 So, this this idea, this is something that I have in the blend. That is
 Currently, you see the whole cortex as something that human is using right now, right? And it has like a lot of these different parameters in it, but what I want to actually convert this into is sort of tool where it's not humans, that will be using cortex, it will be the Asian tech systems, that will be actually using cortex. So imagine memory as a tool. So, I mean, currently the mCP is like, mCP, trend is like skyrocketing so I guess it makes sense to call it as an mCP tool. But imagine it's not us who are controlling these trekking parameters but it's an agent because it so if it's an agent, there it is automatically processing your request and it is forming that. Hey, what the date range should be while calling cortex. So, it has cortex only as a tool. So, in that way, it can tweak all of these things and see, like, oh, like, what parameters giving the best result. Okay, let's
 Get some coffee from Tiago.
 And then we can. All right, we're back. Maybe we can talk now for a second about Context Engineering and how this all fits into that.
 Yeah, sure. We at Primm are thinking very deeply about how to kind of create agentic systems and we are, as we are, like, building one. Internally that we realized that
 giving all of these agents, these like different tools, but making sure that the
 Tool usage. And like number two is that these agents actually have is like highly highly important and making sure that
 there is only one thing on the memory side so that's that can be something like very crucial because now you're eliminating noise in a way if you only have one tool for memory then you don't have to
 go and use up.
 All of the this memory kind of search aspect if it's not needed. Yeah, that actually reduces like a lot of noise on the tools number of tools, it has access to. So there is like a paper out there that the number of tools that you use the accuracy of like the
 Task completion rate of an agent goes actually down. Yeah. So the graph is kind of like this, I would say. Yeah. And I've heard people talk about how much more expensive it is. If you now have to give access to all these different tools, your input tokens go up. Yeah, yeah. So like, there's just getting like more confused and confused with like so much noise of like different tool definitions and all. So, I mean, there are some strategies where we can eliminate that. So there has been very nice blog about the same Context Engineering, but Manus also so, where they talk about a prefix caching and how to
 How to just block one tool from the attempt to see, so that it doesn't really use them when it's not really required, or it doesn't even have that in its context. So all of these like new patterns that are emerging like as a whole, the whole Context Engineering thing. So, I mean, it was all prompting before but it's so much bigger right now because currently the way you use this tools and how you feed in all the information for the whole completion of a task is like
 Has become the more thing and like, more people are working on the same. Now, giving the whole memory as it tool to an agent, makes very much sense because we don't have these like static flows anymore where like a human will like for only a certain cases, like a human would retrieve on, what it's required because Asian can do the same thing. And
 We are constraining on how much freedom to give to the agent by working on the memory tool aspect itself. So
 Boy, how we are like building cortex is like we are reducing on how much freedom to give the agent who is using this as a tool that we can give it like a lot of freedom with a lot of different parameters or we can constrain it down to very minimal parameters. That's one way. I think how we can
 Reduce down entropy overhaul. Yeah, last thing.
 You're interested in Vision memory also.
 Yes. So this is a coming soon feature. I would say in cortex, I'm working on right now, so I think there are some nice
 Implementations done by a lot of different people. Currently people are thinking a lot about how to represent all four of senses or like,
 signals I would say as a part of their part of the agent to memory because currently if you see it's all texts like everything that is people are working with are just text but
 What I'm seeing the trend right now is people diving so much more deeply into the whole video vision.
 And audio also. So like just to see the bigger picture, I think we have to Target the whole five senses like how human C and feel and
 can experience different things to all of their five senses. It something similar has to emerge from the agent ecosystem. Also, because all of these has to merge together and have there should be a way that it's able to intercommunication. Like the vision memory should be able to communicate properly with the textual memory that it has access to from day to day, or it can be just some audio. Obviously, you can compress these down to only one domain, like, compressing down a video to only a text and it, just interacts with everything is a text at the base and audio. Yeah, but you're losing context there. So this is not a lossless compression here. Just compressing down the video and you're losing lot of complex. A lot of context. Even if like, you are explaining it, very nicely on, what the video is about.
 so,
 There is this nice thing that got released by memories AI. So there were working on large Vision. Models something, it was large language, memory Vision model something. It was like that where they are kind of processing. The whole processing. A whole video to make it more searchable, more indexable. So.
 now this indexable thing is not like that, it just converted into text but
 sort of like an embedding, but
 feel free to like check out the memories AI, but
 I think that's like the start of the things that we are going to see in the coming months. Like, let's say next six or 12 months where we are, able to properly index and store video data or like any sort of vision data or do it can be. And at the core it will be just numbers. It will be just vectors.
 Or like however you want to represent them because it shouldn't be text, because text should be more high level version of it. So at the core, it should be something all the same and which is which has like most of the contacts without
 Having any sort of like lossy compression, I would say.