I got into building clouds inside those data center. So I probably built more clouds and I care to admit to you. Some are great. Some are awful.
 Deep conversations are coming beware. So dude, you've been building data centers.
 Huge Investments.
 Big Time production. I don't know everything about it. Okay, absolutely. So just just for your audience corrective errors and president seal was high performance Computing. We're Canadian cloud service. Provider we own data centers facilities, in both Sweden and Canada, we operate GPU clouds that scale we certainly cater to again, a lot of The Sovereign mandates that you see in a lot of those Nations, especially Canada, being Canada, owned and operated. You know, we have a huge interest and obviously, a play Within the, The Sovereign economy of supporting Sovereign mandates for AI. What? That means, again, you have to look at the full integrated stocks, so yeah, my background, I've been building Telecom infrastructure, you know, right out of gate. Right out of school, putting fiber in the grounds for communications networks, building telecom companies from the ground, up, both nationally and then internationally
 After that, and when you're in that infrastructure game and you're building all these massive high bandwidth networks, you quickly got into Data Centers, right? So again, everybody knew that the network and the data center went hand-in-hand, like you can't have a data center without a network. And networks led to a data center somewhere because again, that's where alteration sits so that that got exacerbated when you know, super, Super Hyper skill, when I get old AWS is and azure's and Google's came into the market, so I do have to roll back the clock for a little bit. Didn't tell you that Continuum, we're just go back on that Continuum. When again, you know, we went from being a data center provider and then I got into building clouds inside those data center. So I probably build more clouds on a chair to admit to you. Some were great. Some are awful and then somewhere, right? At that cusp. When I get like the hyperscalers came in and took over the world, so the relevant public clouds. Became what we call our, we came what we know as Regional clouds and the
 Regional clouds. The non ews is the non-google. Still had relevance because one there were, there was a big customer base that just wanted again, a simple Cloud to access. But more importantly, there is a big customer base that wanted to know where the data was, right? So again, if I'm gonna put my data in a cloud again, I kind of want it, you know, within again, a domestic region and it only is to satisfy against certain data, residency policies at Enterprise or government might have
 So again, fast forward, it did some time at some large Fortune. 500 companies went back to venture I actually just Venture where we purchased power plants so we bought power plants, we operationalize and these are what we call combined cycle, natural, gas, power plants. And we did that in Canada and then I built an HPC facility actually directed to one of these fire plants. So, what we know as completely off-grid a data center, powered by its own power source and and then, you know, off the fence. So that the power that I was metering was going directly to my data center but again, it was my power generation, that was supplying electricity to that data center and that that's going back a few years. But now that's that's what you hear. A lot of the Big Data Center companies talking about. They're like, hey, I don't have access to energy where I wanted when I wanted at the price I wanted at. So, you know, how do I scale my data center by creating my own power generation and
 And allowing for infinite Scale, based on, you know me controlling all the elements myself, right? Not dependent on the the local grid not dependent on, you know, the region I'm in whether or not again, it has like say, renewable energy sources. So again, those are the things that keep coming up all the time. Like you were saying earlier when we were talking, you know, one, what what is that? What is that? Basic building block that you have to have for us? Well yeah it is power and land.
 Great, that's where it starts then now, I can look at the data center appetite in that market and then start looking at the data center strategy. So how do you look at that? Well, not that the now that with AI, like the, there's infinite appetite, you don't have to look at it. It is like, yeah. Because training when you're, when you're looking at model training again and it really changed the design philosophy number one, and it change localization or Geographic relationship. What I mean by that is again, look at how we build data centers around the world. We build a data center so that the data center is closest to the user, right? So again I'm building in like key markets and they're usually large population centers. So as as I chose the location from my new Data Center building and this is again Regional clouds or hyperscale clouds. I get I wanted to be in key markets and then if you look at the us we knew these NFL cities. So if it in the US, if there was a state with an NFL team you can
 Guaranteed, there is a cloud provider in that very, very first, right? And for Canada, it's if it has a hockey team. Yes, it is true. Yeah. What we don't actually have a lot of hockey teams, believe it or not, but but um, yeah. No. There are a few key markets in Canada. And, you know, you could, you could call, you could count them in one hand. But Toronto, being the big epicenter, Montreal being another massive Market Vancouver, another Market Alberta Manitoba is coming up as a very relevant Market as well too. So yeah, we do see again the growth in Canada, Quebec grew really fast for another reason is because we had very cheap hydroelectric energy. Oh, so one so it enabled.
 The build-out it. You did. Yeah. Because one there was a lot of it. So when Quebec started investing, its power infrastructure years ago, it was to enable industrialization. So they wanted the forestry guys to come in. They wanted the mineral mining guys to come in so they built lots of hydroelectric energy. Because again, those are industries that. Take a lot of electricity. Use a lot of electricity, it didn't really happen. So it didn't actually happen again. You were talking about 20 years ago when these investments in the infrastructure development started happening. But one thing that did happen is Data Centers, saw the opportunity and data centers came in really quickly so we saw a lot of the consumption and all the power demand really get in and up fast. And then the other thing that happened to was a lot of battery storage companies that came in from Betty, manufacturing perspective, came into the market, too. So again, this, this is more than the manufacturing side and to build batteries it there is a huge
 Um, energy demand as well, too. So electricity is a key element in developing batteries. And if you're developing batteries, you're doing it under a green flag urine mandate therefore you don't want to be creating or developing batteries with fossil fuels. So again, because Quebec was hydroelectric. All the battery manufacturers really enjoyed going to Quebec to to use again. Abundance of cheap energy to do what they could with renewable energy sources. So I like that, you are basically going full stack on the building out of the data centers saying we're going to produce our own energy. We're gonna make sure that we have the capabilities that we need. How are you producing that energy, besides the hydroelectric today today and Buzz we don't actually build and produce any energy, or sells what we have done is you know, this this comes from our parent company High digital. We found locations around the world that
 As that that situation, I'm explaining to you where there's an abundance of hydroelectric, energy one we wanted to really stay and remain a, you know, a sustainable company. Where again, we're using a renewable energy sources and in this case again, hydroelectric or geothermal. So Sweden was again, a big anchor site for us. It was a, it was a primary location for us and, and where we built some first facilities so that you know, again, we're using 100% green energy there again, come back again, another obviously a home base for us and then you know a lot of our GPU Plus or say that that's we offer to the market. Our based in Quebec and you know my parent company I digital just made a large acquisition. In Paraguay where we purchased a very large piece of land facility connected to one of the largest dams in the Western Hemisphere so 100% hydroelectric. Again it feels like if you build it they will come right. Yeah I think her planning a road map like you're creating that energy road map so that again.
 As you build out that data server structure again, you have that energy to back it up, the energy of scale with you. So again for for what we need to do, and cater to the market that we cater to we're building fully integrated data centers, which means that, you know, right now the the locations and the access energy and the hydrogen that I have, it actually caters to demand and for the next couple years later to whatever I need to do from a GPU Cloud perspective. So, data centers, you know, come in different shapes and sizes. Right? Again, the traditional data center that was talking about earlier, you know, we were building really sub 10 kilowatt racks, so I could, you know, I could put in any single Rock bunch of servers and I see him up to 10 kilowatts of energy in that rack. And then I think, you know, if you sit any of infrastructure talks here at the conference, you know, you'll hear that. That shift again. We're again quickly. People had to go from that 10, kilowatt record, sub 10 kilowatt Rock.
 To a 40 kilowatt Rock when the the h-series a GP is released, right? So you just went kind of anywhere from like five to six to even 8X depending what your your power consumption that rack was overnight. And, and then you quickly went to an 80 kilowatt rack really into like a three to six month period. And now, what we're planning for is 130 135 kilowatt rocks with the GB 200, with no view of slowing down at all it. Yeah, I think again data center design and data sir, construction will naturally limit the the absorption in the market. You know, if you talk to Jensen, he's already preempting. Hey guys, start thinking about, 400 kilowatt rocks.
 Yeah, and you get into other issues with that one. Yes, again power density is is a huge problem. You probably have to get out of this rack mindset. So a data center will not be the same data center that. You remember it like you know a few years ago and then the heat dissipation is a real issue. That's a real thing. And that's why we had to shift from ear cooled to liquid or water cooled because you can't get the same heat dissipation or hey the same thermal transfer through ear as you would with liquid. So again, you're trying to create that that thermal efficiency and removing heat off those chips as fast as humanly possible and at scale. So yeah it it's not again it's not a it's not an easy engineering feat to again that design data centers but also design data centers. So they're modular and future proof, right? Because again, I'm trying to plan for what that right next rack density might be and they're just getting more and more dense and more power hungry.
 Do you see a world where there's 400 kilowatt racks? Ah yeah. I and how does that look how do you make that transition? Especially when you're trying to plan for proof? And you're like, dude I just got to 130. Give me a little bit of a rest, so I we have ongoing joke with our Engineers is don't screw anything down to the ground, so put it all on Wheels, wheel them in and out. That's right. So, yeah, we're and if you think about this for a second, like the size pipes, we're putting to data centers for the plumbing. Just to move again, liquid, fast enough that volume through these servers. I mean, it's already massive. So, yeah, if you have to now, again, prepare for the future and say, okay, I need the right, Plumbing infrastructure in place and either way electrical infrastructure place, these things are just gonna get bigger and bigger. So yeah, it's not like, I don't think anyone has actually solved for all those answers. Except like I said, like, don't don't get used to one standard that's why I'm saying don't screw anything down to the ground. Like you could change it next year again.
 I remember that I made a joke. Oh yeah, you're in Canada and Sweden because it's cold there, right? And you're like, well, that's kind of true actually. It helps a lot. Yeah. So the metric that we use to determine your data center. Efficiency is something called Pua. So it's like your power utilization, efficiency metric. And in most data centers, especially cool, climates, we try to leverage what's known as free or cooling, right? So I want to use as much as the ambient air when it's cool, bring it into the data center. Use it instead of fire at My chillers and and cool that water loop if it's like liquid or if it's just here that I'm putting into the data center, right? Take the cold air from outside and use it. And yeah in climates like the you know we have and in Northern Canada and if we have Northern Sweden again yeah you you want to leverage that cold air again for 80% of the Year again you have cold air, why not use it? So then that way a drive down my Pua and you know, on average throughout the entire year.
 I have what we know is like a 1.3 Pua. So for every one, kilowatts of usable energy or a capacity to have my server, you know, I'm using about 30% more to cool, the environments and and manage environmental within the data center.
 Hear a lot of people talking about building data centers in the desert and the Middle East. Yeah. Does that just not make sense? Well, you it, you can do it. You just wouldn't use them much for your cooling. So there are other cooling techniques that you would incorporate such as an EVAP cooling. Yeah, definitely. You might have to fire up the chillers more often but they're innovating. I mean even in climates like that, they're always looking at Innovation techniques again, keep efficiencies really low and one thing that we see work really well around, you know what we know is Just Energy, plans is one if I do generate heat, I want to reuse it somewhere else. So the other thing that we do and we look at when we design data centers, especially if they're industrial parks. Yeah. Can I take the heat waist and then, hey, give it to my neighbor if they need heat for us. Yeah, or anything like that. Yeah, I think, you know, you whatever, whatever you can use that heat waste for. Yeah, go go create again, a district Energy System,
 With with neighboring businesses to to reuse that heat or another idea. And and you know we've did this we've done this historically. Like if you're if you're saying
 Near a large body of water, it could be a lake, it could be the ocean and you have the ability to actually leverage deeply cooling or deep water cooling. What you'll do is take again, cold water in from that water source and then run it through your data center. So again, there's another District energy type Technique, we do it in Toronto quite a bit. Like the whole all of downtown Toronto or most of downtown Toronto is on the district entry system, where we take all the lake water, pump it, through pipes and all the commercial buildings and and that's how we create the building's. Oh, same concept for a data center just again, more dense, more compact way to do it. So there's a lot of different chip companies here at the Rays Summit. I talked to you about this and you're like, yeah, they're kind of a diamond does in. They have their different,
 Perks. But you are standardizing on Nvidia, right? You're not doing any other kind of chips, you're not really interested in. It's true. Yeah. We we have, we have found a strong partner in video and you know that we we also get a lot of support from Nvidia too. So they, you know, they're really big on supporting their Nvidia, cloud Partners where we're one of them. So, you know, we're very, very fond of that partnership, you know? Certainly again, when you look at the Nvidia team, you know, they're they're they're, they're pioneering and carving through again, you technology fees, right? They have this Innovation engine, that's always going. And the thing, the thing I love about Nvidia is they're not afraid also to experiment and get people to come and collaborating spirit with them in the market. Are they the ones coming in helping you with the cooling and the design of the new? They have a very, they have a, they have a great team. He's out again, collaborate to say, Hey, listen, we want to build a standard and the reason why they want to build a standard, is they want to create a consistent experience for all the customers. So,
 Again, if you're going to spend a quarter million dollars, a server you as a consumer or me as a service provider and trying to monetize that definitely, you know, you want to deliver the best experience to your customer possible which means performance reliability. And that reliability is really around uptime because again, I'm spending lots of dollars to build my AA project. We'll listen it better, you know, the hardware better work so yeah, they do have a strong influence on. They, they bring in, as you know, reference architectures at the NCBS use and, and listen against standardization is not a bad thing because that standardization can also be updated when you find new innovation tanks, to make something better. So, it's not to say that you sent it is to lock into a rigid framework. Is to say that hey once we find a good recipe, let's all let's all fold a process, but when we see process improvements for the next iteration, we'll incorporate those today. Also let you know what's coming down the pipe. Absolutely. And that's where you can.
 Recognize that in the next three six ten months. We should also be starting to prepare for XYZ. Yeah, that that and and it it from two angles, one is the hardware perspective, right? Yeah. How do I have to plan my data center design, around that new technology coming future is telling you again, you're going more dense and then the second part is software, right? So again, you know, I want to say that Nvidia equally invest as much time and hardware and their software stock. So yeah, we're we get, we definitely get early preview of all these things. And then, you know, again the goal is like, how do I create like the, you know, the the best AI platform and democratize that for easy access to everybody that's innovating because we want to accelerate the speed of innovation in the market right now. So one thing that we don't want to do is slow down. Anybody that again is building the AI project and they themselves have to get to Market really quick because they got to see an Roi and they got a monetize it themselves. Yeah. But this probably
 A good point to talk about the hardware software bottlenecks that you were just talking about on the panel. What are some key points that you've been seeing out there on the hardware side? You know, this was more about keeping up with long lead times and Supply chains. So, you know, in some areas B and some businesses, you know, he got guys that are GPU Rich. That means they have a like Open Access gpus, huge budgets. A massive amount of capital. So you see a lot of wastage, you see a lot of unutilized gpus. But then on the other Spectrum you do have a big part of the market. And again, you see this was research. As you see, this was startups that don't have big budgets. So again, they're a little bit GPU, poor, I want more gpus and I loved innovate faster but the gpus expensive it's not cheap. So what we do on the hardware side again is we have a planning sort of consumer one from a data center perspective. That's probably the longest lead item because it takes a long time to build a
 Center. We're talking 12 to 18 months in some cases, right? So, I have to have that data center pipeline capacity, ready to even deploy or install a GPU and then obviously the GPU itself. Again you have to you have to have alignment with again your oems all the server vendors that that again or packaging those Nvidia gpus and then you when you install them and you know, we've got really good at this. It used to take a long time to turn up these clusters. They're highly complex. It's like wiring a brain and making it work with 1000 network connections. And you know again all the stuff just one is not in the right place and I know there's a problem. Yeah it sucks. It sounds like a nightmare know. It sucks. Right. So so again. Yeah, but we have, you know, we've got a model down where again, we can deploy really quick but when I say deploy quick we're still talking about weeks sometimes, right? So yeah and install the racks connected from a network perspective then commissioned the servers and then pressure test them. Right? So again again that that's making sure I get all the right firmers in there. All right, drives are in there.
 Um, and then I gotta get to OS and Patch properly, and then I go back to test it. So, again, yeah, that takes time. It definitely takes time and then I, you know, when I have a clean system and I could you I put in the market and then start to monetize it and then you throw the software on top of that. Yeah. And that that's the other part of the bottleneck you're talking about. So on the software side now as a as a service provider, what I want to do is offer some level of orchestration to my customer, too, to say, hey, number one. Let me make sure, again, I, you know, I put you on the the right platform from the right reason and whether you give a customer bare metal or whether again, I'm, you know, I'm giving him kubernetes to consume or maybe it's slurm. It is around again, me optimizing that platform for the customers use and developers. Again, you look at historically developers, love bare metal, the problem with that is again you have a large, it is. Yeah. Like and you see certain you see wasted shark to come out too, right? Because
 You know, people start to treat servers like pets instead of cattle and and then, you know, the whole devops movement. Yeah, no, it came back, it came back again. Right, people are hoarding gpus, right? People are actually holding on gpus as they can because again again you see this this cycle and even the hyper scale there's where
 It's actually hard to get a GPU sometimes, right? And then, you know, unless you're willing to lock into a long-term contract and people lock into long-term contracts, why? Because when they need the GPU, they want to make sure they have it. So, anyways, it's a, it's a behavior that we see in Market all the time. When again, there's a resource that that's highly desirable and when you need it you need it, right? So the software stack on this side is one, yeah, we do. See optimizations at least from a model perspective. So you look at um, you know, you look at compression write a really, really simple things that everybody from a modeling perspective, always tries to improve and and then you go down the stack to orchestration. That's where, you know, the surf provider. Now, I want to schedule workloads and put them in the most efficient places and to make sure I'm creating maximum usage out of my cluster because why, if I have wasted my cluster will, I'm not monetizing and making money. I need to to pay back the investment. I was talking to Paul yesterday and he was
 Tuning how for him? He's okay, paying a premium for a more managed service on this because it's so hard to get talent. That really understands how the hell these things work. No, you hit. You hit the nail in the head. And, you know, when you go to Enterprise, you can't go and sit down with the company and say, oh, how many gpus do you need? You can't have that conversation. Nobody is going to know how the hell, they're right. Yeah, and no one's, No One's Gonna know what to do with it either afterwards. So again, yeah, that that's where again. I think the token economy is starting to become a, you know, more more real thing. And these gonna as we start to shift away from guys that are doing Foundation models and you know, really and still going back to tune models. Because again you get into a lot of organizations where they're just taking proper priority data and they want to close environments so they want on on-prem environments. So yeah you will still get a lot of tuning happening. But then again you quickly shift to that inference side of the equation.
 And then, yeah, now you're abstracting the hardware, which is good, that that is actually the right thing to do because like I said, back to the the bare metal conversation that we're having, and trying to sell GPU hours, or trying to sell Bare Metal, you do see a lot of wastage there, right? You can't, you can't maximize efficiency very easily because you're leaving it to an individual or someone else and their behaviors to maximize that Hardware themselves and in multi-tenant environments. Yes, but as a service provider and it may sound counterintuitive that I want people to save money because if people are spending money, well that means I make more money. It's not true. I want people to have efficient usage because they get it extends, the life of the project I want to add value as a providers. So my service becomes more sticky as well.
 So anyways, that it's, it's actually great again for Innovation, it's great for the industry. And then me it's great for my brand because if I could send you a recommendation and say, Hey listen, look at, you know, look at my tooling, here's where you have wasted, here's where you can optimize or here's where you could be on a cheaper GPU. For the workflow that you're doing, I want to provide information to my customer. Are you also renting out gpus to some of these Neo clouds that are just doing inference, like the modals and the base 10s or did they get enough in other places know? We do have a pretty broad customer base and yeah, a lot of them are in friends as a service providers. So yeah, we do that and again though those guys are great too again because they're Downstream customers are more interested, okay? How many tokens am I using rather than how many GP GPU hours, do I need, right? So that, you know, again, I again, you do see, again, a huge shift in the market, so that but you still need a metric. That's why.
 Token is important. However, again like I said, the GPU our is just really, really inefficient and it was a little bit more hard to place in terms of me trying to quantify and how many gp's I need for again a specific model or specific project that I needed to deliver. Well, I know some friends that bought some gpus and one of their main decision criterias was the level of support that they were going to get because they knew it was gonna be so hard to just go in there and figure out how to make this work with their project and there was going to be a lot of learning.
 For both parties. Not just the team that was buying the gpus, but also the folks that were renting the gpus. There was a lot of times where they were encountering things for the first time, and it's like, all right, well, let's troubleshoot this together. I guess so. So we still see that even as a service provider and operator, like again, the new a new firmware from an oem comes out. And it changes everything. Then we got a rollback firmers because again, like getting the band with those supposed to get Oregon. Like I said, you know, you got to install patches or you can install, you go to you install packages in the right order just to get the throughput you need because this is around moving data to. If you think about it within a cluster like, you know, the network has to be operating it full bandwidth efficiency, your memory has to be at full band with the fish and see, right? And you know, this is where in the link came in because again you want the cluster to act really as a single server almost where again that GPU parallel processing again they could all talk to each other at again the maximum efik
 So you go back to what we know is Primitives Primitives again are your CPU, your memory, your disk and your network, right? And then you need that that high throughput across all those elements. So again, you know, there, there's one vendor that we use on the storage side of vast data. So, again, fast has been extremely extremely powerful for us because again, you know, you don't see bottlenecks to storage and its network storage and then orchestration, like, you know, we partnered with folks like Raphael who again, create massive orchestration automation for us, you know, even at the kubernetes level or creating Dev pods, for example, and, you know, it again, when you talk about customer experience again, this is where again, we want to make our customers, you know, easy to consume, or provide the infrastructure or customers easy to consume, or they hit that easy button. So that either, they're not think, like you said, they're not thinking about it too much. Yeah, I remember we had Moen on from Raphael and he was
 Talking about how they're this middle layer and it's constantly like the ground is Shifting underneath them because there's not a clear thing on, how many gpus are actually being utilized. How much of the gpus are being utilized. If there's rolling updates happening, which ones are we taking offline? Putting online, so underneath them. Nothing is stable and then above them. The demand isn't stable either. It's like I want 50 gpus right now. I want 50,000 gpus right now and so they're constantly trying to play this game of cat and mouse on. All right. Well we can connect these here and it reminds me of my daughter's like little Playbook where you draw the line of this is a mouse. And so then Mouse word goes there with the picture and then you draw the line here and it's like this is a cat and Cat goes there but you're just doing it at a ginormous scale with a lot of money on the line. I think the best story can give you is around, you know, historical technology Evolution's and I had, you know, I had the opportunity to listen to
 Geoffrey Hinton in Toronto not too long ago and he was asked the same question. Like he, you know, they kind of asked hey, what was the efficiency gain or like, what was the thing that allowed us to get to where we are right now? And I was surprised and not so surprised by his answer, but he actually said it was, you know, the Russian evolution in gpu's. So was the advancement and performance of the hardware?
 You know, because when you look at efficiencies and you look at like, you know, Evolution you see it across the entire Spectrum, hardware and software. So, you know, based on what you're saying, even with Raffi like you, yeah, again you do need the software optimizations at different levels, whether again, it's in the model itself, whether its orchestration layers or just Behavior. Like how do you create more education for people around their behaviors around usage. But um, the the examples that I wanted to draw to is like like, you know, you think about autonomous driving as a technology it's it. It's a solution is an outcome, but the technology is behind it were twofold. One, is you have that AI right AI, you know, making decision? This is almost like real time inference by the way, too.
 But here's a big butt. You probably would have got it and Geoffrey, and his right without the GPU, another, another example of that is OCR, so, it's Optical development in the camera, right? So if you think about a self-driving car, well guess what, if that camera did involved, where it is today you wouldn't have self-driving cars either. So it is a it's like that convergence of all Technologies evolving almost at the same pace and then reducing or lowering the barrier of entry for for that Innovation to start. And economic says a lot to do with it too great. So as a GPU at a price now that I could offer to the market, that the market could Finance or manage or fund to go do the things that we do today.
 The GPU.
 Played a big role in that because of the training, the camera played a big role in that you have this intersection in this convergence of all these different pieces. And so then when you look at it and you extrapolate it out to the companies and the businesses. Now, when you're talking about the economics,
 it is clear that companies need to be able to say. This makes sense economically for us to spend a lot of money, on whatever it is that we're doing.
 And so that conversation is now being had more and more. Are we spending money on gpus just to do AI or do we start to see that Roi from it and I think more and more
 People are quantifying what is the lift that AI is giving us we moved out of that POC phase and now we're not willing to burn a lot of money on the gpus just because we want to be AI literate. Yeah and so it's very cool to see
 No, no again, yeah, you struck a quarter with me on that one, too, and more so because obviously Buzz being a GPU and AI Centric. Cloud, provider means that again, yeah, we have purpose-built tooling. We have purpose builds software in our Cloud, for development of AI. But what we've done too is we've, we've offered a product in the market. That's a fraction of the cost of like a hybrid scale.
 A type offering. So again, if you compare us to like the aws's and Google's Microsoft of the world. Yeah, we we are much, much cheaper to go get that AI project done. We're quicker and more simpler to use and it allows you to fail fast, right? So, when you're in a platform like ours, you can, you could throw pizza dough on the ceiling and see if it works again. You're not, you're not running too high. I have a budget and because of the cons of the wrong Cloud. Well guess what? I can hit the reset button start over again. Yeah, if you were to go straight to, I'm gonna go buy my own data center. Try to figure out how to use the GPU figure out. If I got the right optimization technique in there to brought the right scale that that's dangerous. Venture. Yeah, that that's a really dangerous investment. So it's really good to at least starting Cloud. Get that. POV does see if you could build an Roi really quick, and like I said, you could fail fast. If the pizza dough doesn't stick. Well, hey, the pizza doesn't stick, right? So and then, yeah, once you have that, you may stay in cloud or you may and we've seen this a lot. We
 Create hybrid environments, where? Yeah now I do Edge into my own on-prem data scenario. I want to have my own dedicated stack. The economics may work better in that case, because I drive high utilization on that Hardware that I own and then I use cloud for bursting they use cloud for different projects. Whether again it is maybe just my inference platform that I want running cloud and I'll keep training on-prem or vice versa. So yeah, I think hybrid is a great future for everybody, right? Being able to figure out again, with the dollar should go based on how much Hardware own versus how much Hardware rent the hybrid.
 Narrative for the cloud, was always something that people like to have, but I don't know if it was ever a really strong need. Yeah, except for a few companies that definitely needed to do it for one reason or another, but it at the end of the day,
 folks like to talk about it more than they like to actually do it but here I think there's a if it flips it on its head because of what you're saying where
 you need it.
 Whether you are trying to get more access to gpus and you can't get it or you're just seeing that unit Economics work better when I do certain things on my own or with this cloud and this Cloud provides this type of service. So it's better for these use cases. And you have this, almost like new paradigm. That's emerging. Where hybrid is very common design. Yeah. And but I want to say one thing hybrid's, not easy to pull off. Yeah, so what, what we've done it? Why I think traditionally people weren't doing it. No, they were talking about it. And, yeah, we're gonna go hybrid or we like hybrid. And I remember somebody telling me that the CEO of databricks loved it. When people would talk about hybrid because they were like, yeah, everybody loves that idea, and then they end up using us and execution fails. Yeah, it's like, it's a great in theory, but not in practice. So, so, one thing I could tell you is that again, we look at
 A lot of the AI projects today, we see a lot of data movement and that data movement happens because you know I have my all my applications and hyperscale Cloud right now, all the data sitting there, you know, it can be an S3 but I need a specialized platform to do AI. You know. I don't want to pay the hyperscaler price to do it in their Cloud. So now you see again, a lot of data movement happening from my scale or to a platform like buzz and then, hey, I may train something, I may tune something again. I mean, I may run an inference endpoint but what I don't want to do is have to do with data back in. So I don't want to create a movement of data from one place to another, then another place to another. So, again, I think that's one thing that must have tried to do is, we've tried to create a holistic platform. It's an Enterprise great platform which means that you know I could take something from again its infancy from it. It's Genesis and that that's again maybe again even
 Holding a training model to how that turns into an app and hosts the app as well, too. So again, we provide VMS, we provide the storage Services, we provide the security services and provide the resiliency and really again it at least allows a user consumer to not have to move the data back and forth. So you could, you could host everything and run that app in one place. So, at least again, it goes back to what we were talking earlier. Like I want to create the proper customer experience is, I want to create the proper environment for my base, to be able to use my infrastructure without making it too complicated, right? And yeah, moving data is not easy and it's not cheap. That's what I've heard that when folks are going and shopping around for gpus. A lot of times you forget about that and then you are.
 Starting your project and you're like, oh, yeah, egress fees are kind of expensive.
 About, we didn't realize that it was going to be this expensive and if you talk about the hybrid model, there are ways that you're gonna have to get really creative with that data architecture. So that it doesn't end up not making Financial sense. Again, you're like, you did all this gymnastics to make it hybrid so that you could save a buck here and there, and then, it doesn't work. Yeah, no. It's it's again, a good points. I think, when we look at hybrid and what we saw traditionally, especially in Cloud was there are a lot of Enterprises and companies that
 Prefer to keep certain applications on Prem. And they
 They understood cloud and they understood that. The best thing to do with cloud is go Cloud native, not lift, and shifts.
 Then they're able to harness the value of cloud a little bit better. And then it became economically more feasible too. But yeah, everyone that just did a lift and shift to say, hey, I'm going to throw an application Cloud for no reason at all, that that wasn't a great idea and that became very, very expensive. So, again hybrid was more a force methodology previously, where again, I think some customers that needed to keep apps on from did that. And that could be compliance reasons too. Again, it goes back to what I was saying earlier on sovereignty and data sovereignty, specifically, where if, if you couldn't show that again, your data was in one place and it was secured and ring fence. The way you needed to be. Well, you were meeting certain compliance and controls that you had within an organization. So again, that that really kept, again, it, the co-location business live at. Again, a lot of data centers that were customers again, just had their own rocks, they had their own space, you know, traditional Enterprise it data, centers that existed in the
 Those are still there for that reason, right? It's around. A lot of it is around the data sovereignty and the the data residency requirements that they need to meet. And then yeah, you go to hyperscale and again, there were great, they were great front-end apps, that are great web apps, that love to be in, hyperscale cloud, and they were suited for Aprilia. But again, especially if you're using Cloud native techniques. So again come back to AI now and again AI loves on-prem massive amount of data that you got to train, but again, when you go to inference again is it's not again the same data set. However, one thing I'll share with you is like you, why would you create multiple data sets for different types of phases within that, that AI Journey, right? If I have my data in one place, I want to keep my data one place and I want to iterate on it. Therefore, if I have to go back in, tune it too. I'd rather not create a second copy of that data. So yeah, I think I think you're absolutely right like,
 The constant of hybrid sounds attractive, it's not easy to execute, it's not easy to manage and typically, if you get everything one place you you want to do that.
 What are you most excited for? That's coming down the pipe.
 Are feeling well I I see. So again, if you look at One Sovereign,
 Around the world and what a what a solver mandate is again, countries and Nations. They're saying, hey this and I I get that AI super important, you know, I hate to use arms race term because it rely it kind of refers to, you know, trying to acquire as many gpus as possible. But what the truth is, I think I think what a lot of countries have recognized is that they do have to have an AI strategy and you know, for for certain countries, that AI strategy means. Well, one is keeping a talent pool or growing, a talent pool is in the country, right? To help businesses to grow your GDP. Yeah. And and it it's super important because one, yeah, you don't you don't want brain drain too, where again, yeah. You know, you have your talent coming out your universities and schools just jumping to another country because of a higher paycheck as well too. Well and they can't get access. Yeah. So many cool stuff. Yeah. Work on. Ya know. It's it's it's super it's super. It's a big.
 Problem. And then for governments governments, that other big, you know, thing behind Sovereign, right. Government itself is going to be a massive consumer of AI. So again, now they do see it as a strategic position. So you have to adopt AI as Government, there's so many government departments and factions to inside of that. But again, what Sovereign is really it's you know, it's control over the infrastructure, right? Do I have domestic control of that infrastructure? Do I have domestic control of the operations? And that's all digital operations, too. And the last one is data like that, that Sovereign piece is really a data story. Like is my data itself Sovereign as well. And now you can talk about Sovereign Ai. And again, the way the government supporting this and Canada has been great for this, by the way, like, you know, the first thing we did was we elected like a minister of AI that brilliant. Yeah. We need a guy that that's hyper focused on this like, you know, fueling Innovation, fueling the economy around AI itself, and then we create a grant program. So you know that and you hear you hear about the headlines all the time, too, right.
 I'm, you know, you just allocated 100 billion dollars. So again data center infrastructure and AI Saudi, you know, they stood up Humane and, you know, they got another, you know, x billion of dollars there and then you got Stargate where again, they they earmarked 500 billion dollars to go Bill data centers, which again, if you look you know, under the covers its know we're gonna deploy, you know, the first 30 billion dollars. And, you know, this is this for granted up. Yeah, yeah, so, but you know again it is it is a lot of it, a lot of those headlines where you can see and investment. And but it's a stake in the ground too. And, and countries saying that, no, I get, this is hyper important. It's one of the biggest revolution's that we've seen in our time. So, yeah, I want to make sure one that the funding is there. So that, you know, we protect our sovereignty, what number two that we help businesses innovate, and, and move forward. So again, yeah, data center GPU access is in the bottleneck or the threshold to go, innovate and build. Is there any other
 Topics that you want to touch on that. We didn't touch on as Buzz. We've been building Enterprise platforms, but we've also started to incorporate a sovereign philosophy and Sovereign framework in that. So when I say an Enterprise platform that that's going above again, your basic cloud and AI tooling that, you would see
 To develop an AI project is to get incorporating very rigid compliance. Very rigid is security techniques and Technologies and systems. It's incorporating High availability, reliability tight slas for our customers, right? And then bring in the Sovereign. It, you know, it's around again adhering to certain National or local policies and and keeping governance and control over in the environment. So, Sovereign actually has become the new standard and if you say, hey, I'm a startup and I don't even care about stand as Sovereign. You might be right, you may not need Sovereign, but because Sovereign is setting a high bar. You enjoy the reliability of that cloud. You enjoy the reliability of performance of those of those, you know, sacrifice just to be Sovereign, correct, exactly. Perfect, dude, we got it.