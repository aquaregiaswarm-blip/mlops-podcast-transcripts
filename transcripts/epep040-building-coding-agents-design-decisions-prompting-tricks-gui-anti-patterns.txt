So our our primary objective is to save human time. You saw a lot of like interesting demo videos, but I would say like nothing that really worked day-to-day, the more we played around with a tool use models, the more we realize, hey the the assumptions here have changed around what the models capable of no users of amp. Which is our new coating agent generating, like 80 90% of their code. We do spend a lot of time thinking about how to nudge the user toward the right way of doing things. So one specific example of this is
 When we talked last what, right? When you release a coating agent, I think that might have been shortly before shortly after we released Cody, which I was yeah, yeah, it was right around when Cody got released. So I think that was maybe like a little bit after the initial release of Chad GPT. Yeah. And so that was at least like, one AI era ago and so what has changed since then? Like I would say like at that point the dominant modality of using LMS for coding was still this kind of like copilot article complete mode where you just like type a couple of characters of Code yourself and then you get a line completion.
 Um, and at that point, what we were really excited about was the whole like rag model. So we figured out pretty early, like, hey if you combine a search and information retrieval and use that to fetch relevant, code Snippets in conjunction with a really high-quality chat based llm, it was a really powerful way of doing code, generation and Technical questions. You were uniquely like, well, suited for that, if I remember correctly. Because yeah, so, first graph, of course, like our first product of Market was, a coaster engine and stuff, like this makes a lot of sense. Yeah, so like we're our bread and butter is helping developers, read understand, search code. And turns out that that's very, very useful still and in the AI era but the big shifts since then has been the emergence. Shall we say of coating agents? And really, it's it's the tool. Use and reasoning models that have driven that or enabled that because a lot,
 Of people tried building agents in in the arrow chat llms and you saw a lot of like interesting demo videos, but I would say like nothing that really worked day-to-day but now we have really good. Agentic tool use models that are enabling a essentially, a new application Paradigm that we call agents that are kind of taking the level of automated code generation to the next level. It's going from, you know, 30 to 50%, which is what we saw in the chat base, LM era to now, you know, users of amp, which is our new coating agent generating, like, 80 90 95 percent of other code. Your theory is the ID environment is already dead. Yeah, so I think this is like a general theme which is the application architecture that was made possible by chat llm. So think LMS in the era of GPD 3.05 or 4 this sort of like chatty era. There was a very specific
 Type of rag application architecture. That was ideal for that kind of model and our our coding assistant Cody, followed that model, so did many of the other tools of that era. So the AI IDE the vs code Fork was kind of the the Pinnacle that are I would say but what has basically happened with this new generation of llm, is that they have unlocked. This new capability tool, use plus reasoning. So those two together, provide this kind of like agent that capability and that in turn unlocks, a new set of interactions at the application layer. Such that a lot of the ux that application Builders build for the old are of China is now outdated. In fact, I would say in direct tension with the ideal ux of coding agents. All right, this is where it gets spicy. So then what is the New World?
 look like,
 So the new world is much less manual context management and a lot less kind of like gooey Chrome and like different toggles. So I think what you saw, what we've seen with the chat based LM application architecture the rag bot application architecture is just there's so many toggles now. Like you gotta like manually specify through different like rules files, and yeah, different different ways of like tagging in relevant code Snippets. There's a lot of ux chrome around managing. What goes into the context when you know
 so then the LM can do a single shot with agents with that just started the funny thing there is
 If you know certain tricks it performs better. And so there's some people that are doing it really well because they've played around with it and they've been able to tune the knobs. Yeah. And then there's others who are like yeah like kind of helps I guess. But it also kind of messes up. Yeah, exactly. So there's this kind of like strategy for getting the most out of like a chat, based LM tool and now a lot of strategy is essentially gone out the window because with agents agents, have the ability to use tools themselves. Fetch contacts themselves and so it's much less. The human manually managing. What goes into the context window and more you describing the higher level of what you're trying to do. And letting the agent, go figure that out the analogy. I like to draw is it's roughly similar to the transition from like the Yahoo era of the internet to the Google era of the internet. Where like in the Yahoo era it's like what did what did what did Yahoo look like? It was like a million hyper.
 Links and the the ux was like I'm clicking through a nested series of links to find what I'm looking for. So there's a lot of pointing and clicking and kind of like manual following of links there's a lot of like knowledge that I have built in for you know what pages are good when Google came along, they essentially took that whole UI and like you don't need that anymore. Just type what you're looking for and we'll get you to the right thing and I think agents coding agents specifically are very similar and in that regard, whereas we're in like a lot of the strategies that people develop for getting the most out of channels that's like the pointing and clicking and the awkward, you know, no longer need to do that. There is a new skill so that you need to learn which is not as trivial as using Google. It's more, like, how you probably agents to do their work most effectively without active human intervention, but that's sort of a very different skill set, often indirect tension with the skill set that people learned in the chat element with the GUI.
 Yes. Interesting. Because with the GUI leads you to do, is it really leads you to kind of like micromanage llm which was necessary in the old world but now with agents you kind of want to just give it the appropriate context, the appropriate feedback loop and and let it run. Uh yeah and you want to let it do what it does and almost
 Give it that freedom that. Yeah. If you're putting too many micromanagement on it. Yes. In a way it's not able to get What It Wants done because it's feeling restricted. Yeah. And the
 Other point or the other thing that happens.
 When you micromanage an agent is that you as a human also, get frustrated. So like a common failure mode that we see is people who have over-indexed on sort of like the the cursor wave doing things they're like I want to be in there and like I want to direct it at every turn because that's what that UI trains you to do. It's like at every turn. I want to review the change before I apply it but with agents we want to do is you want to give it enough context to figure out itself. What the right things to search for what the right feedback loop is it's similar to like another analogy. I like to draw is like the previous generation. It was like the AI was was like a coating student. Like you had to be there to review every single little thing they did and they're like, okay you did this right now. Let's go apply what you did now. It's gotten to the point where it's more like a professional engineer. Maybe like junior or mid tier engineer, maybe maybe even sin.
 In some domains. But with an actual professional engineer. What you don't want to do is you don't want to babysit them, you don't want to be instructing them at every turn. Like, okay, now read this file. Now go do this change. It's more like, hey,
 Here is the overall context. I think you should you know use this command to run the tests in this case or use playwright to take a screenshot because you're iterating against UI code. Here's a general shape of the feedback loop that you want to construct. Now, go off and figure it out yourself.
 It is very much like a declarative way of doing things. Yeah, yeah. I would say it's less like it's less in the weeds it's more like let me articulate at a high level the key points and I'm gonna let you figure out the low. And how have you seen the best folks?
 Being.
 Effective in getting that context that it needs.
 Okay, there's there's a wide spectrum of how far people have able have been able to stretch the coating agent. So the top 1%, we love those users because in some sense they're kind of like discovering the future along with us. So when we look at The Amp user base, a lot of the Ford looking things that we build are directly targeted at emergent behaviors that we observe in the kind of like, top 1% of users. These are people whose token consumption is like, 10x in some cases like 100x. What the median user is and there we observe a couple different things. One is there's an emergent set of strategies or tips for instructing the agent to get as far as possible. This is like, you know, what's sort of details, do I put in the up front prompt to enable it to construct the right feedback loops to search for contacts in the right places. And then the other thing we notice is, is more more parallels.
 Nation. So amp is available both as an extension inside vs code, as well as a CLI. And so there's a lot of people who use the editor extension for more complex, tasks tasks tasks, that involve you know, more like complex chains where you want to kind of like remain in the driver's seat. So to speak and then they'll use a CLI for paralyzing. A bunch of shallower tasks. So like you'll have it like a team ups window where they have you know three or four amps client instances going on different. You know shallower issues or bugs bug fixes that is so cool dude. That is so wild to see it's crazy and how are you. So I guess you're just doing product feedback with all of these power users. So we've hired a good number of them know. I like to say like that man. Yeah. So it's a great source of, you know, Ford thinking devs, some of some of whom we've
 Welcome to the M4 team and we also talked to them a lot, you know, we interact over social media channels, we have a Discord we hop on phone calls but it's it's great to talk to that set of users because in some sense like we're so early right now, like people talk about ai's, if it were one monolithic block, you know, that has, you know, the wave has is, but one giant wave since chat should be T but it's actually a succession of multiple ways. I would say. And we're so early on the agentic model era that a lot of our product development process is really kind of like partnering or sitting down with our power users and discovering alongside of them. You know what the possibilities are, is that how am came to be? Because you saw that folks were clicking around too much and you realized maybe this isn't the best UI and ux that we can have that.
 Was a big part of what motivated us to build something from from the ground up. So you know, we had Cody which is an assistant, that was really good in the chat, LM era but the more we played around with a tool use models like, you know, sonnet 37. And now Claude 4, the more we realize, hey, the the assumptions here have changed around what the models capable of. And if you're, if you're holding it properly, you can actually get a lot more out of it than you could. In, in the previous era. The problem is that a lot of the old UI paradigms are kind of like actively working against you getting the most out of, of coding agents. So, this is something that we kind of realize in using it ourselves have and all so talking with a lot of our power users. In fact, one of the, one of the folks that we hired this guy with the name of Jeff Huntley, he was a canva at the time. He actually wrote a blog post about how he thought most people were using.
 Say, I coding tools incorrectly because they were still kind of using it like you know, Google search plus plus or in a very like chat based Paradigm and we brought them on the team because we're like, this is a guy that gets its different and that really understands hey you should be instructing these things, you should be. It's almost like your programming them through natural language if that makes sense. So like you're, you're articulating a very set of your articulating, a set of a very precise instructions.
 In much the same way that you would kind of like articulate those instructions to a smart but still you know Junior engineer. So like you're giving a lot of context up front and you're allowing them to get much further on their own. And how about the idea of just validating when code is working or not the beauty of agencies that they have this kind of like built-in ability to construct these feedback loops. And so when you're using amp for instance, when it's generating code for you as part of that code generation process, it will seek out an appropriate feedback loop. So if you're doing front end code, it can use a tool like playwright for instance, to screenshot the front end of the application as it's working. So you say like, hey, go make this bet background red or green, or blue can actually take a screenshot and verify whether a change at the code had the intended effects.
 Similarly, for backend code, it might be like a unit test Suite or some other command line invocation that it can use to validate. Whether it did was, well, there's something it did was correct in much the same way that you, as a human developer would seek out these feedback loops, right? Like read evaluate print, that sort of like core Loop. That's what agents are good at. Figuring out some cases, they need a little nudging. Just as, you know, humans need need a little nudging, or some pointers and in some cases, but by and large. If you can get the agent to figure out that feedback loop with with very high confidence, it will iterate to something that is, is mostly correct. Why do you feel like coding agents, had this breakout success and we're uniquely positioned for such a lift with LMS and the whole AI Revolution? I think the the answer that question.
 Comes down to.
 The meat, the immediately preceding question, which is, you know, how do you validate something is, is correct and coding is one of those domains where you have a very strong validator in the form of a compiler or unit test Runner. And because you have that validation point,
 Um, you essentially have a way a very reliable way to generate high-quality synthetic data. So, a model of evolution is ultimately a data game and there's two ways acquire data. You can either collect it from the wild, or you can create a synthetic learning environment, in which you place your kind of like robot or agent in there and allowed to do stuff with feedback about what's good. And what's bad sort of like reinforcement, learning environment. And I think, at this point, we've exhausted the amount of publicly available large corporate of of data. So, like, you know, that, that those sources of data are largely played through, but coding is one of those domains where it's like you can create a simulation environment with unit tests and you guys doing that to certain extent. So for certain special use cases, we don't do Foundation model.
 Training as of yet but for certain targeted use cases. We we do that sort of kind of like validation and I'm just been hearing about how more and more people are doing simulations more. It's more common to do that just to figure out where you have strong capabilities and where you're you may be are failing silently sometimes even? Yeah. It's it's essentially what you're doing is you're designing a game that approximates the what you want in real life. So in all the domains where AI has gotten really good, you know think about like you know playing chess or playing some other form of game it's because you have this feedback mechanism that tells you hey you're winning or you're losing as long as you have that feedback mechanism, you can turn that into a reliable source of training data because it's what you what you do is you take your model out of giving snapshot and then you just run it. You you say, go play the game. You simulate
 Game and based on the moves that the model takes, you say like okay you know, plus points or minus points and that's essentially what you're doing in these coding reinforcement learning environments when you say like oh compiler error or oh unit test failure. I like that way of looking at it. You you just sit around all day and you're thinking of a knowledge? Yeah, thinking of analogies. Yeah, the thing that I'm also wondering is if feels like we had a big jump from these Rag chatbots and the way that we were co-pilot
 Writing code. Yeah, to then. All right. We're in the ID and we are doing this almost like click Ops type of stuff and very micromanaging. Yeah, now you're saying we've got a whole new era that's being born with amp and how you're giving it this context as much context as possible. And then letting it do. Its thing is that the last era or do you feel like there's another one that you want to get to? It's just not yet possible or it's in the works.
 I don't think we're in the, the final era. I think things will continue to evolve. So, you know, one of the things that we're doing now is we're thinking about how to combine multiple models effectively in this new agent Paradigm. So, in the old world, the name of the game was was simple Rags. So like every AI coding system, had like a model selector where you just like, you know, whatever model you want to use. You can use that and then we'll just fetch the relevant Snippets, put in the context window and generates response. I think in the agentic area to be much more thoughtful about the models that you use. So you know, we use one model for the core kind of like tool use and a Gente driving of amp and we just ship a feature that allows you to use another model 03. Actually for for in-depth reasoning because turns out there's certain types of like nuanced problems that you might want to tackle that where these like reasoning heavy models can do a lot better than the models.
 That were kind of like trained from early for agentic Tool use. So that's one way in which the Paradigm continues to evolve, it's like now moving beyond just simple agents to maybe like reasoning agents or agents that can use different types of models to do more things in depth. And you want to extract that away from the user or you want to have it that every time I go and I give a task to an agent. I can say here's your three or four models you can choose from, you figure it out.
 they, if you
 But we want to enable kind of like a a spectrum of use. So for the the first time user, you know, you don't have to know that we have this. So the tool is called Oracle because 03 is such a powerful reasoning model. It's it's like talking to an oracle of sorts and, you know, we don't want that to be a prerequisite to being able to use amp. So if you don't know about what tools and paths access to, you don't need to, it will just select what it's what it thinks is the best tool for the job, but the same time instructing coding agents. In our view is a pretty high ceiling skill set. So you can get good at coding agents in the same way that you get good at your editor of choice or you get good at your programming language of choice. And for a power users, we do see prompting or query patterns where they're saying like Okay I want to I want you to use the Oracle in this case because this is a little bit of a hairy problem, it's more nuanced. I want some more in-depth thinking,
 So there is some exposure but it's not at the point where it's like, okay decide what LM you want to use for this case? That is now an implementation detail and I think it's it's almost you know, it was the best practice to expose that to the the end user in the chat LM era. But now I think it's it's a more. Yeah. Yeah it's funny. Are there any other anti-patterns that you're starting to see and then maybe surprise to you?
 The number one, Andy pattern is people trying to use coding agents in just the same way that they use the, the chat based coding assistance. And I would say those anti-patterns largely fall under this umbrella of in the chat based world, you wanted. Like the human had to be in the Inner Loop of like back and forth between you and the model out of necessity, right? Because each you know, model invocation was like a roll of the dice and in the chat based world, you know. The the probability of just working was probably lower than 50% like more likely than I would make some subtle bug. And it had no way of correcting itself because it couldn't iterate against feedback, it couldn't use tools. And so, it couldn't fix its own mistakes. And so, as a consequence, you wanted to be in the loop so to speak. Yes. To constantly course corrected with
 Regions it now has the ability to gather that feedback on its own. And so if you if you instruct it properly, in many cases the Fidelity you get from a single model invocation, like a single file edit or a single, you know, bash command that it runs is closer to like 90 95 99%. So, like, you can actually, like, you can get get out of the way much more if you use it properly and and it can do more for you. But that almost requires almost like an active rejection of. A lot of the best practices that people learned in the chat alarm era. So it's almost ironic like some of the people who are struggling the most to use, coating agents, effectively, where the ones, who early adopted chat based, coating tools little microcosm of the macrocosm or the it's a yeah just like go.
 Yeah. Trust the process man. Yeah, an org out. Yeah.
 Oh, that's hilarious. So I had I had a question about
 That I can't remember. Now it's not coming to me because I was thinking about trusting the process and not hold on. This is the power of post-production we can trust the process. Yeah, trust that let me trust the process of my question, asking capabilities. So you mentioned the different Power users and how they're paralyzing different things. And that seems to be one very Advanced way of doing it. I wonder if you've found nice tricks other than that that maybe aren't the power user tricks but it's just in the way that you're prompting or your asking the agent to do things like
 My mind instantly goes back to the early days of chat GB team and we started asking it like think step by step on this and everybody was like, whoa, it's so much better when you do that and have you found any of those?
 Almost like prompt tricks or maybe there's other tricks that aren't even in the prompt or in the way that you're asking. Yeah, so um, by and large and, and the best way to discover these things is really through experience. So I'll do my best to like tell them to you in the moment, but it's, it's no substitute for actually like using it and kind of like building the intuition. But in my experience, as kind of like, three buckets of of like prompting tricks, there is what I would call like context hints. Number two would be feedback loops and number three is kind of like structured approaches and slash planning. So the the first bucket is really about helping the agent.
 Figure out what tools it needs to invoke or essentially, where to look for the relevant context. So it's in large code bases, oftentimes, it can be a little bit tricky. Even as a human to find the exact spot that's relevant to our particular task.
 And so agents, agents, agent LMS, the context Windows, these days are much larger than they used to be. You know, I think, you know, sonnet for has 200,000 tokens total Gemini. Now has a million and so the context widows are larger but they're still finite. And what that means is
 The the more information you give to the model that where to look the fewer tokens that has to expend finding the sort of like General vicinity of what's going to be relevant. And so the more hits you can say, like oh like look in this part of the the code base or I think it's under these directories or maybe like use this tool to fetch the context that can help a lot. The second thing is feedback loop so you know, I was telling you before about feedback loops and how they're critically important these are essentially like, hey, you know, use this tool or use this command to validate your approach. Oftentimes it will infer the appropriate tool to you use on its own. But in cases where it's it's not trivial to figure that out again, you can save on the main contacts window
 Um, by by kind of like nudging it in that direction. And then the, the third approach is just adding structure to the overall approach, it uses to to solve the problem. So in the simplest form, this is just like hey before you go do this, large and complex tasks, I'm about to give you first write out a plan of steps and and maybe even let me as a human review that set of steps. So I can ensure that they're correct. And then and then more and more. We've we've sort of like built additional features into the product where knowledge of those features can help. So one of the things that we've shipped, well, I guess not so recently now it was like a month and a half ago, so it's like, you know, in AI land, we shipped sub-agents. So sub agents are essentially and as the name suggests, they're agents within an agent. So like the main agent can invoke, a sub-agent to go do a subtask like, you know,
 Searching the code base or going and implementing a feature in one part of the, the code base. And so, having knowledge of what sub agents are good at and kind of like nudging the main agent to use them, where appropriate can help you conserve the context window. Because the beauty of sub-agents is once they complete their subtask, they don't essentially like the tokens. They use the contacts window gets garbage collected. They don't use up the contacts whenever the main agent. So that allows you to get further in complex tasks because you're, you're essentially changing together. These sub-agent calls that don't eat into your overall token budget in the main agent that makes sense.
 Yeah, I've heard that described as agencies tools. A lot of people that's like the hot buzzword these days. Like oh agents is tools. It's coming and yeah, everything is a tool. Exactly. Just function calls at the end of the day. Yeah, I was laughing with a friend because I was saying you know, even humans are tools that the end of the day when you asking for the human to give you the feedback. It's like invoke the human tool. Yes. Yes it's like in is the Asian the tool or a tool for the agent to get his job done, sometimes the line? Yeah the
 Part that you just broke down really well on how to conserve that context window in a way so that you're not using it all, ah, because it's finite and maybe you don't have the ability to throw everything at it, but B.
 It's really good for the cost and keeping the cost lower. I can imagine when you're looking at agents and folks that are using agents.
 I think there's probably two lenses that you look from you look from like, okay, the consumer is trying to keep their costs low but they're interfacing with Source graph in a way and am and so yeah. You also have to be weary of costs and passing on the right cost to the users and the pricing and all of that fun stuff. Yeah. How are you looking at all of these different costs? And how do you feel like we've all heard this idea that? Oh, well,
 LM calls are just basically going to 0, right? And so it's just getting cheaper and cheaper. But now if you're talking about agents using sub-agents that are doing super complex tasks, yeah, it still could be like 50% or 50 cents for a task to get done and or maybe even five bucks. Yeah, who knows. So our our primary objective is to save human time because that is still the most valuable resource by a huge margin. And so, one of the core principles we've adopted is essentially to not
 To not worry too much about keeping the cost of the agent, super super cheap. So you know agent decoding tools. They look expensive, relative to chat bass, coding tools like your average token spend is is growing from on average, 10 to 20 dollars per user per month to, you know, in the hundreds, in some case, in some cases, in the thousands of dollars per user per month, like one, when we talk about the top 1% of users, who are really like redlining the what the model can do. And what the coating agent can do, oftentimes they're pushing into thousands of dollars per month territory.
 And so that looks expensive to people. But if you look at the amount of human labor, that's being saved, given how productive people are with these tools. It's like a no-brainer trade-off and
 I think a lot of other tools, I think they narrowly focus on the over index on like, hey, how can we keep the cost low as compared to the chat based, LM era? And I think that's, that's a, that's a very poor trade-off to make because
 It's kind of like saying, like, hey, I have this magic tool that can save you. The human hours of hours per day. Your time is Super valuable like a human developer time, is is still by Far and Away like one of the most precious resources within your engineering or and even you know, if you're spending like a $100 per month that comes out to what like you know, 30 40, 50 dollars per day, like how how much how many how many minutes of human developer time? Does that translate to saving? And so I think what you're going to see is more people start to have this realization over time that oh it's I shouldn't be thinking about the Baseline cost of this because really the upside as far greater the amount of additional productivity and the amount of additional feature velocity that I can unlock in my engineering team with coding agents is far greater than the cost that I will be paying for them. So, like right now, you still see, you know, CFO
 And people and accounting, and the finest Department being like, you know, oh it's it's difficult forecast but I think it's just gonna play out over time. Where the company is that
 Trust the opinions of their of their developers and encourage people to make the most out of coding agents.
 They're just gonna move much quicker. And over time, the market will reward the people that prioritize developer developer productivity essentially.
 Yeah, do you feel like we are not going to be?
 doing much of the
 or actually.
 So I play around, I've played around with a lot of the different tools and I feel like there is something that's happening right now where
 I no longer want to.
 Click around.
 And get things done. I also don't even want to like, code to get things done. I just want to say it and then it goes and does it for me. Yeah.
 That is very easy to do with almost coding tool type things. Yeah. Like if I say hey connect my website to this database great, that should be possible. Yeah.
 I don't know if.
 They're is a possibility for the world to look like this in the future, but I would love it if I could do that with any application.
 Yeah, I know, longer want to have to write out.
 The or click around to get things done and I almost feel like we are getting spoiled in a way. Yeah, with the software being able to do it when you're coding or when you're creating your your application with whatever.
 But like, are we going to be able to do that in jira and Confluence at some point? Are we gonna be able to do that with just like
 Voice next, right. Like, you gotta think it's going there. So I saw a tweet the other day.
 It was something to the effect of the gooey, the graphical user interface was a blip in between command lines and agents. Um, which I think, you know, rang very true in the sense that
 I think it's exactly what you said. I think the what we think of as a software application today is going to look much different in a few short years from now. So it's not that like
 I don't think like visual interfaces are going to go away entirely. I would
 I would say, like, precisely what I think is going to happen is that the primary input modality to a computers or to software applications is going to shift from graphical modes of input, like pointing and clicking to more textual forms of input like typing or speaking. Now, the output what you get back from the computer might still be visual. It's like, you know, I type in what I want and then show me the results. Maybe like, you know, Airbnb listings with photos. Yeah, there's certain things that chat cannot describe. Yeah, exactly it. Like, I don't want to read all that text. Just show me like a picture. A picture is worth a thousand words, but in terms of like, how, like articulating what I want out of the application, I I just think of it in terms of like bitrate, right? Like, what, what's, the bit rate of these input modalities pointing? And clicking is very low bit rate, it's like couple bits per second at most because you have to, like, you know, takes time for you to drag your mouse cursor, to the right button and then you got a, it's like, it's a very primitive form.
 Of of communication. It's like you know monkeys and apes do that, right? Humans. We have the we have this Innovation called language and language is beautiful because it's it's a relatively speaking. A high bit rate form of communicating our intent and now computers can actually understand language and also translate language to a series of actions that actually perform what you wanted to do. And so I to your point, I think a lot of the application input experience, is going to shift toward textual or voice-driven forms of articulating. What you as the user want
 So what are some gnarly things that you encountered, while building out amp, maybe on the infrastructure side, maybe not necessarily the the user's and the evals, and all of that stuff. But stuff that you as you're building out, you're like, oh shit man. Like I didn't think it was gonna be this hard.
 Yeah, there's a lot of like trickiness and Nuance to designing.
 The user experience and I think it really requires thinking from first principles, what you're after. So, like we've gotten a lot of thought to how to bake in the appropriate. Feedback loops, help it, get to the right feedback loops, help it to get out of like, common failure modes, where it kind of like loops and trees the same thing over and over. Again, that's a common issue with with a lot of Agents, how to conserve the context window, we give a lot of thought to that, where to use the model. So, like, what models are best for for which tasks. But these are very different questions than the questions that we traditionally asked around ux design, because traditional ux design is very visual. It's like, you know, how do I lay out the set of how do I lay out the button panels speak? Right? Color. Should the button be? Yeah, exactly. Whereas people, I remember reading a blog post on how people look at web pages and there's like the F shape of the, where their eyes go.
 And the attention goes. Yep.
 And so, you know, like amp doesn't have
 Any of that really like the the input interface is very simple. It's just like text box and like, you know, right what you want, or some cases in some cases, people like to do the voice mode. So they use like the like Mac OS, like voice input, just to speak to the agent. And and that's the the primary way of getting what they want. But it's a very different set of questions. So you kind of you can't rely on the rules of thumb that people developed in in the kind of like Point click gooey world, he really have to think from the ground up like, okay, eyes are, what do I actually want? How do we want a guide? The user to this Behavior? That's kind of like new. And this this new kind of like Paradigm that unlocks the capability but still feels familiar enough. Unfortunately developers are accustomed to using command driven interfaces a bit more than the average computer user so that helps but we do spend a lot of time thinking
 About how to nudge the user toward toward.
 The right way of doing things. So, one specific example of this is amp is
 Maybe one of the only I think we're one of the first.
 Agents where typing enter in the input. Box does not submit the query, so typing enter, just introduces a new line. You have to hit command enter to actually submit your request to the agent. And the reason we did that was it was a subtle nudge to encourage users to create longer prompts because the more information you give the agent, the more reliable, it becomes more can do for you. And so that was like a subtle nudge to users to say, like, look, don't stop here, don't stop here. This is not Google search, don't type, you know, for for keywords, and then expect it to read your mind in many cases getting to what you want to specially. If what you're trying to do is, is more sort of like, out of band or unique, right? You actually have to give it the information because it's not a mind reader. Like the information has to come from somewhere, either. It's baked into. The prior, is it learned during training? Or it's, it's, it's going to be embedded in the, the
 Words in tokens that you give it right now. Did you think about
 Adding certain shortcuts or hotkeys, and I've seen this done where you have the prompt box but you also have little boxes underneath that. You can click on where it's like, here's some common workflows or some common questions that type of thing.
 So I think this is one of the things that we did very differently. It was sort of like a contrarian take we actively didn't want to add additional toggles or modalities at the bottom because number one that's like mental overhead and it it makes it. So you have to point and click again which is I think, you know we now live in trying to get away from. Yeah, we're trying to get away from that like it's the age of Agents. You just describe what you want and be able to get what you're looking for. The second thing is that with a lot of other applications I do this.
 The the more toggles and switches you add, they essentially exponentially complexify the the interface surface area of your application to the point. Where like if you if you introduce like a single binary toggle that you know, like other other coding tools. For instance, they have like an Ask mode or an agent mode or like a chat mode. Yeah. Like if you introduce a toggle that has like, three different modes. Now, you essentially have three different, like, mini product experiences that are all very different from one another, if you introduce another toggle again with three modes. Now, it's three by three because you have this like combinatorial, like, okay, what if I choose option? One from the first talk, toggle option, three from the second. Now, there's like nine possibilities for what the product experience looks like and it's very hard to maintain a high-quality product experience if all your users are using essentially different products, right? Different products experience is because they all have some, like different
 Configuration that they're using and how about the times where you want to zoom in on specific things because I know like if you're if you mess around with loveable they have the bullseye and you can click on that and it's new mode that. All right and it's got the specific parts of the web page that I can click into and then prompt it so that it changes that. Yeah.
 Maybe you thought, what? We don't need this, we're just gonna have the user put that into the chatbot.
 The way we like to do it. So there's some like capability or some behavior that is more specific to a particular use case. The way we like to do it is put that into a form of a tool that the agent can use and and then enable the the agent to invoke that tool in the the right situation or enable the user to nudge the agent to use that particular tool in the right situation. Like hey, you know, go use playwright for iterating on this ux and the reason why we think that is better than modality is that tools the complexity of tools. It's more like linear growth and complexity rather than combinatorial growth and complexity. So like each additional tool, it's not like, it's not like modes where it's like,
 Bless you.
 Each each additional tool that gets added. It's it's just another tool that can be used. It's like, you know, o of n in terms of complexity. Whereas if you added a new modality now it's like you know, M by n by, you know, K. It's you get this kind of like exponential blow up. In terms of the services, you have tools that are standard off the shelf for the users to use and there's a description and the documentation about it. Yep. But then users can also bring their own tools. I imagine. Yes. So we have three kinds of tools. There's the built-in tools that are just, you know, as the names are just built in. You know, basic things like reading and writing files, and executing bash commands, as well as more advanced built-in tools, like, like the Oracle that you use different models, for, for advanced reasoning and other use cases, there are what we call connections, which are tools that call out to third party apis. So think about like, you know, bringing in your issue, tracker or bringing in your observability tool.
 Pulling in additional contacts from those sources and then the third type of tool is mCP servers. So mCP is, you know by now like everywhere, right? And so the beauty of that is that you have all these different other tool. Builders out there that have build MCPE servers that front their application or their service that can then be pulled in to to amp.
 How are you thinking about the tools that you?
 Support and are natively giving to users versus the other two.
 Yeah. So I would say all the the tools that are necessary for the day-to-day, like core inner loop, a software development, where it's like, you know, you're in the code, you're reading and understanding the code, you're writing code, that's our bread and butter. So we like to bake those in as really good first class tooling experiences.
 And then there's also like a second wave of third-party tools that are just like so common that we all so want to make sure that those integrate well and that's why we have these like connections, these kind of like first party connections to third party services. So like bringing in things like linear or GitHub or century.
 The way we bring these tools in the description of the tool and the set of arguments and and how to invoke them, it's very difficult to abstract fully. It's not like you can have the same set of tools that work really well. In a coding agent as works well in, I don't know, like a generic, you know, Enterprise knowledge, retrieval agent or whatnot. And so we try to refine the tool definitions for those. But then we also recognize that there's going to be a long tail of things that people want to integrate specially. Because, you know, we serve a lot of the Fortune 500 and, and there's a, you know, each each Fortune 500 code base is, it's like its own special environment with all its like different internal tools and unique combinations of external tools and so we all want to enable our users and customers to build tool providers. MCP, servers that.
 Connect out to the unique cooling environment within within their own company. Bring that in as well.