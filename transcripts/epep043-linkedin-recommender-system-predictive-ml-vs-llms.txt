So I'm working on mostly how we can recommend the right content, why is it different than traditional recommended systems? I have big specifically going to ask it, like, take the signal, take the signal and when I'm using LMS, I don't have to explicitly go and take this signal, okay, see what this person has interacted to. So, basically, you're abstracting away the feature engineering that you should be doing. Yeah.
 I liked posts on LinkedIn, just to show support to friends. It doesn't mean I want to see 50 more posts, like that.
 So you're like in just because how do I tell the model that how do I say this is a support like not a interest. Like Yeah, because it counts any reaction that you make.
 To the polls that counts as a pot Plus for you. So this is something that you're interested to know more about. Because if you're not interested, you might not like or comment on it, right? Imagine it as a, like a cluster. So if you have two clusters and then one cluster has all the IT industry people and other cluster has like all Finance people. So if one of the finance guy likes to post, it's pretty much your, the model is pretty much sure that other person is going to like it. So they will show that post to that other person. And then once you like it, then it gives the signal to the, and it goes on like that. So, it's basically two different cluster, every different profession, or every different people based on their activities or interaction, it's being in one cluster.
 and in that and they belong to the cluster which where they have similar interests,
 So that's how, if one of the user likes it. They are pretty sure in that class with other people will like it as well. And then occasionally, there's probably one that crosses over clusters.
 I think it's very it's very rare that I would cross over your cluster like I like because the because if you see how it decides, the cluster is based on whatever your profile information.
 And what ever type of content? You have been liking so far. So even it takes as a feature, what is on my profile? Your information is basically, the more most key point for the moral to understand what, actually you're going to like, so it, that's why whatever you enter your profile. It's the first entry point.
 In order to make any recommendation. Yeah, my profile is pretty satire these days. I am the vibe manager at Vibes community, so I don't know how well the model is gonna be able to understand it. It doesn't via things. Right? It's gonna default back to the old stuff. Yeah. It just like you and if you get confused, we do whatever we can think of, right? So that's the user-facing side that I'm seeing.
 You're working on the back end of it, right? So I'm working on, mostly how we can recommend the right content that user may have more and more reaction to it, or they like those content. And then also, on a recommendation side, we see, we want to make sure that whatever we recommending is that adding value to you. It's not some random recommendation that we are doing it in there. And to get those things we need to know. What are your interests. What time period is the one where you like to see? Most of the content maybe in the morning you're in hurry. And you don't want to see too many contents you just scroll and just leave. So maybe that's not the ideal time for us to give you the best content and then maybe after work, you like to scroll more and going to the depot of it. So that's the time we should recommend you more important content, or more valuable content that you might be interested in. So this is like one of the factors and then there are a lot of features that we consider such as like what are you in your recent interaction with the people or recent interaction with the feet basically and that we consider like Okay. So this person likes more video content. The person doesn't like
 Textbooks. So, okay. That's something that we need to consider, which shouldn't be recommending more video post to this person. And then also, we also look like, okay, so maybe you like icon 10 but you like more. Yeah, infra content. So it's more specific, right? It's not just GPD models and it's all about how GPT models are doing those things. So it takes all this very it looks like very minor signal but it makes a major difference on the feed side of it. And since with llm being coming it's getting much and more and more easier to get all those time information and then get the most out of it. So I think it's
 So I think every action or everything that you're doing, only it might sound like very nonsensical to you, but on the other side, it's something that you are sending that, we need to consider in order, to give you write posts that you're looking for. Why is it different than traditional recommended systems, or how has it changed? Yeah. So it depends like, I think, overall industry LMS is definitely something. Everyone is trying to use and recommendation. One reason is like, eventually early in the traditional recommended system. You have these signals that you need to create and you need to give it to the model. So okay, these are the signals that you need to look and then become the post. But with aluminum, I don't have to give it like look at the signal, look at the signal, I just give it like okay this is a post and this is the user and they like this post in the past few features other people have liked this. So just tell me whether I should recommend this post to user or not. So this
 Element is now already capable enough to understand like okay these are the signals that I should think about and then it recommends you the next post or it creates next post, if you want to use a limp for creating a post as well.
 Um, so I think what LM is a capable is like since it's being trained on huge amount of resources, it's able to catch those tiny signals, much much easier as compared to a traditional recommender system where I have to explicitly go and ask it, like take the signal, take this signal and when I'm using LMS, I don't have to explicitly go. Okay, take this signal, okay, see what this person has interacted to. I don't have to look on those tiny my new things anymore, which are then can handle because it has
 all those understanding that it needs to know that whether I should recommend it, because if you think on the backend side GPT is already for an example, let's take a GPT. If we ask it something, it gives answer to that, right? And now maybe a month back, if I want to know, give me my biography or tell me if I will be interested in this or not, it knows best on your all the data right that whether you will be interested in this or not. So it's kind of already doing the recommendation for you so it knows like what signals to catch if two if you have to make a recommendation so that makes it much easier if you use.
 LMS recommender compared to the traditional requirement. So basically, you're abstracting away the feature engineering that you should be doing. Yeah. Because it's making it much easier for them to do that. But I think the thing that I've heard folks talk about, which is
 Hard as if you're using the llm for the inference. It takes so long.
 To actually give you that recommendation and then how do you do it or think about it? If
 You're now having to populate a feed so it's not just one.
 Llm call. So I think that's the most challenged but when you're using it at them. So there are a few things that we can think of the one weighs maybe if I had to handle this problem. One way like make it light and more. I think Google is currently working on making some light or lightweight aluminum models know models. Yeah. But you can directly use during the inference and it won't add those latency. So you can still serve all those candidates like whatever candidates recommended you from the last phase and then you can still serve it on the feet of the user.
 But so, that's one way to handle is to make them like model more and more lighter. The other thing also is something known as knowledge distillation, which is something you have this big model which you already have fine-tune and everything and then you create a student model out of it. So the let's call the earlier more as a teacher model so you have the student model which mimics the teacher model, but it's much like weighted. It's much smaller so you can still use this to populate your complete feed. So that's to handle the infra case and other thing, if you can't do all this two options, other option would be to not use. LM directly on this inference side, you do it in the offline training or whatever training you're doing and then you do some other normal traditional ml models to do the final recommendation on your feed. Yeah. So in that case, you still leverage the limbs input and then you do the final ranking on the feet. So you just using the llm to help you generate features. You can use it either to generate the future because
 Obviously the post is already there. It's you're not using elements to create those posts for you. You use existing post and ask if this, who should I recommend this posture?
 So and so basically you are all those things can be done in offline but if if you want to use an inference, you have to consider the lightweight models. Otherwise I think it's not possible to use until we have such a huge collection of gpus and all those saying that we can serve the whole feed with the llama or whatever model we have so far which is very huge weight. Yeah.
 traditional recommended systems have very
 tried and true.
 Eval systems. But with LMS the evil systems are a bit different. Are you still going back and using the traditional ml or predictive ml eval systems? When you're even plugging in the llm,
 So I think if you are even to your using the new LMS, right? You can still keep the evil system as same because the base the criteria that you are counting if this. So for say, I have ABC post, right? And I asked my llm, like, okay, what out of this ABC? What should I recommend to are better? Should I recommend a b or c? And Alum says like, okay, recommend her C and I commended C to that user, right. But my eval still earlier even when the traditionally recommended the eval was based on like will the user like it or not. If the user likes it, that's a positive signal. Like my recommendation is correct. So even with the traditional recommended that was the same case, right? We were still evaluating, if I recommended this did the user like it or they spend or commented or whatever reaction they don't add. So I think the Evas system is Still Remains the Same because we still need people to show like, okay, this is a positive post, because that's how the element will learn in future, right, that, okay. I recommended see but I liked it. So means this is something.
 Valuable to her. So I should recommend similar posts to her. So I think it doesn't change as much on the email side of it. It just changes like how you use the output of your model in the website. You still need to see if user app. Making reaction to the post that you recommending either via traditional recommended system or buy them. But it still has to be the user liking it, or is it being interest to it, or they're just disinterested on this pose. So that's still a negative signal. So I don't think much change on the email side of it yet. So I guess where I'm trying to wrap my head around is
 Which parts do it change and it feels like it's that that model that you're using. Obviously if you're swapping it out for an llm, that's a big change. But then on the data side, like the data, your feeding, the llm changes to because now you're not having to feed it so much, you're just giving it a post, the llm understands the post and so you don't have to do much there. So I think earlier in the traditional recruiters system as well, it needs to know the member information and it needs to know the person information and still even with the elements. Yeah.
 It still needs to know the member information and it still needs to know what are the items that you want to recommend. So I think not much changes in that area word changes here is in the traditional recommended system. I have this, I have this member information, I have this item and item. I'm in post information and then we also give it like, what are the specific signals you need to look for it like features? Yeah, features to the model like look for the last interaction of the user. Or look like what he liked in the last seven days or eight days, all those information and what things that they don't like or what time, they like to see the post more so you used to give this signals as well to the model. But right now with the lamps, we only need memory information and the post that I want to ask them for. I don't want to give I don't need to give an information like over this person, will like it or not, the person didn't like this post and last seven days. So do you think I should recommend this post or not? So I think these
 Church, the features that we're giving to the model is not required anymore because llm already has those inbuilt feature, which it can incorporate in order to make the final judgment for the recommendation. Also, with recommended systems, a lot of times you're not just using one model, right? Yeah. Are you still bringing that idea to this type of architecture? So I think if we are using, if we are using llm, it's very hard to add more modern on top of it because it's self is. And also honestly I don't think you need multiple models because it's capable enough to handle all those scenario. You just need to use it in certain way to get out what you want. I think with the LMS, the most key factor is the prompt, how better you prompt your question? That's what will get you the right answer out of it. So I think earlier, in the traditional models, the key factor was the features. What features should I give? What more feature can I give to my model to make it more better to make it more precise recommendation. But now with alum, how
 Better. Can I prompted, how better can I get prompted in such a way that I get exact information I'm looking for? So the I think the shift has moved from feature to being more prompt engineering Parts because we know LM has those feature, it can extract those features, just need to know what I'm looking for. Yeah, you have to be specific in those prompts and those prompts will get you that feature engineering, you know. But it's like
 I mean, it's more trickier compared to the traditional because in traditional system your data science team tells you or any teams like these are the feature. It's very important or you look event for like Google or meta. They you see like what are the things that have been happening so far? And these are the feature that's important, the model you just give those features to your model but right now with the prompt you don't know what's the right prompt? Like how do I get the model to use those feature and give me the right answer. So you just play around and you think and you do like some literature serve and then you figure out like this might work. So I think the album side is still lot in progress, it has a lot of potential but I don't think from the scientific side we have actually experts all the potential of elements yet. So you know, using LMS in production on the feed or sometimes you're trying or you can't answer.
 I think I can't answer the 5th.
 Okay so well I guess once we have more details and it's open source, maybe then. Okay. That's a very diplomatic way of saying I like it. Now how do you measure that? This is actually better than the traditional or predictive ml way of doing it.
 yeah, so I think that's a
 I think there is no right or wrong answer to it, so one way would be definitely. So say, like if I have an example, like, a fee that I want to recommend to, and I use LM to recommend out of 10 just recommend five to this user, and then I compare what my traditional limb recommended 5 and then I
 We have the same email system for both of them, right? So when then we just compare the evaluation is similar or not. Like so if I committed five post using LMS did user like all of five or did you user had only paid attention to two of it? Rather than when I use a traditional, they like all five of it. So in that case, element is not performing as good as traditional recommender because in traditional, I gave the user five posts and user tend to like all of it. But here, I'm not having that case, right? So I think it's the, when we do the evaluation, it mostly is like, how is it compared to traditional model? Do you, did you recommend the post, which are more value? Or did you recommend posts, which had more interaction with the user? So if you don't satisfy all this to condition or any, like there are a lot more so if you don't satisfy all those condition then, obviously that's not the right model for you to do use. Because I think right now it's become so much like everyone wants to use them, but the point is maybe you don't need an element to do this.
 Maybe a traditional model is good enough and you don't need to worry about using LMS because I understand that it's a new technology and it's a soda. So everyone wants to use it.
 But what if you're able to achieve a pretty well or better results or at least not forget about the better and it's imperative LMR. Why do you need LM? Why do you need to spend so much on the infrared? Them and you can have the same character research with a traditional recommender system. So I think it always comes down to what is your interests and what you want to use your model for. So if my traditional requirement system is working good enough like Facebook, if you look Instagram, right? It's working good enough so I don't know what their using, but whatever they're using, it's working for us so I don't think they need to change it right now. Right. Because whatever is working. I don't think they want to plan or if they have to move to a lemon or they want to do it, they need to because right now it's good enough until unless there's something that I don't know, but but I think it's I need to make the decision and more sensible way rather than just run running.
 I found it like a little it's not the only solution I believe just doing it just because we just everyone is doing it. And then how do you look at some of the pros and cons? You mentioned like, obviously it's a headache on the inside because it's a much bigger model. So you have to figure that out. What are other ways that you're thinking? Well, the pros are that we now don't have to worry about this feature, engineering and we can just give the data to the model. Yeah.
 I think there's some more Pros to it, like,
 A burden.
 And traditional.
 YouTube, but make those clusters and then pick. Like, okay, this was goes to this class starts. So we should come into all the all the user in this class. They're not in this class. We don't have to handle all those issue anymore. We don't. So there are multiple models in traditional recommend it, alright. So one is taking care of those classroom, all things and then we are doing the recommendation. But in the LMS you don't have to worry about it. So even though you adding an extra info cost but you're getting rid of all those like foreign and backward things. So you just have one more which is taking care of everything that you need to do.
 So if you think in the pros and cons, so yeah, you do add infra cost to it, but you're also reducing the cost. You still were having some costs when you're using it traditional recommender system. Obviously it might not be as high as LM, but if you're getting rid of the, all the other steps that you are doing, you can still use those resources in your llm and use that as your potential recommended system.
 But I think there is
 There's a trade-off I believe if you don't want to spend on infra then obviously traditional elements. Add more features, keep adding more feature, whatever you think is working. And then the trade the trade-off is like instead of having just one model you will have to still have multiple models to take care of it. And then the trade-off is if you just need one more you need to have more infra 200 handle those things. Yeah. Yeah. You want many models that then you have to babysit and continuously be retraining and trying to optimize or you have this one model that potentially doesn't need as much retraining.
 But it's bigger and you have to figure out that inference side of things.
 Yeah I think it's basically trade of that. We do it. Normal ml models right there are so many trade-offs that we do like okay we want more Precision. We want less recall or less recall as. So you this is a trade of I think you have to make in every part of ml like okay I I can take an extra infra cost but I don't want to take care of the multiple models that I have to handle you, bring in the llm just to certain parts of the puzzle and you say, all right, well just llm here but then we're going to have traditional traditional ml be the final. Yeah, the final inference piece because we still need that speed.
 Have you seen LMS be put in other ways? Because I've heard of folks using LMS to suggest features.
 And this feels like a bit of a variation of that but not necessarily the same thing. If you're just giving it to the llm and saying you you got the features inside of you. Let's prompt it so that it uses them and we can find those features or we can find the best performance through prompting, not through featuring.
 Yeah, I think I did see some research work that it was more in sequential recommendation and they have used this ilm to do the sequential recommendation. So what I mean by sequential recommendation here is like say okay if I go to a new city for say, if I go to Tennessee what will the next step is like one to get a hotel. So now it recommends you okay? So even though when you for say when you open a book go and book for a flight, right? The next thing it recommends, you to rent a car and then once you rent a car where you want to stay. Yeah. So the complete package so this is sequentially Insurance Etc. Yeah, so I think one of the model that I was reading the paper about is like they're using llms to do this. So, This see like okay the user has books this book the flight for what should be the next thing that the person is looking for and then it comes like, okay, once the flight you'd need a car or new, you need to book Uber or deserve it and beforehand to go. What and then book hotel and all those like attraction.
 Spot that you need to go to. So I think in this an earlier traditional recommended system you have to explain the model. So okay, it was like given this, what should the next part that you do and then again, you okay this is done. Then what's the next that it has to do? But the llm can do all the sequential in one go. You don't have to ask a little every time it's like, okay, person booked the flight, what are the next five steps that the person is going to do? And then it will tell you like, once they have booked the flight, they will book the card, They will book, this is so that's what you need to basically implement it. So I think when we are doing the limb part of it, we are getting rid like on on the part where you mentioned for using how different that we can use them. So I think this can give you like the whole structure. Like after this, this step one step to step three and then you can use your normal models. If you don't want to do to, okay, out of this car, like herds or Enterprise or whatever, one of this, you can recommend to the user, whatever you have a situation with so you don't have to have
 A model which is a very heavy weight to understand all these signals, you have to sell them which gives you offline results. Like okay this is all the things that I want that a person will ideally do and then you use your model to just become those things.
 So I think this still pretty, in my understanding, is still reduces your model multiple models to do these things, and it's still reduces your. So, if you think, like, if you have multi mode like, multiple models, you're also adding the risk of the
 Accuracy of each of the model because if one of them, my model is not performing. Well, the rest won't be able to perform either, but with the LMS since I only have one more than just one more folder just fetching the results and just ranking it. So in that case like I'm I don't have to take care of them anymore and I curiously I only care accuracy for my level, right? Because the other is just ranking based on whatever score that and has given it.
 so, I think this
 Helps reduce. And even when I agree with the value mention, like we fetch the feature and give it to a limbs, that's another way to do it as well. That you use, your traditional models, like extract the features and then you give it to the Olympics. Like these are the features I'm looking for, and just give me information about it. So that's the one way to do it as well, because in this way, I think you even though you're using LMS but you still need, but you're still saving the time and the competition because it doesn't have to do all those fine tuning and everything for the model because you're just asking like giving this text post, give me the features from it.
 So I think that's one way to also. We can probably use llms here and I like this, it's almost like a
 reasoning model is going to tell you. Yeah. And you might not even need to have a reasoning model because
 Generally, when you go on vacation, you're going to do.
 The same five things. Yes, it's not. Like unless you're doing some wild stuff, which I can only, imagine there are people out there doing it then depending on where you go, all so you're probably gonna get different recommendations but for the most part you need some more
 You need somewhere to go. You need some way to get around when you're there. You need somewhere to sleep when you're there. So those are going to be pretty same for all the time. Yeah and then while you're there you're gonna want to do experiences or you're gonna want to have experiences. So maybe that's where it gets, very personal to each person and I think
 I don't know if there's still being using it but one thing they can definitely do with them is like if it has. So if I have been booking my things from the same website, right? So they can feed this information to a limb. So this person doesn't like for say hiking, they don't like hiking, so don't recommend them those things. Yeah, for that direction support. Probably comment them, more sights, things, get off of the side. It's as soon as we recommend any hiking activities. So I think they can use those information as well. I think I don't know if they're still doing it or not, but that's a very good signal for to use a lemon, customize your preferences, because we know like if we booked a flight, we take a card, we take a hotel, these are very generic, everyone will do it. But what? After that is very specific to every person. Maybe some person likes to, okay, I don't want to roam around the city, I just want to go more sober and use more sight like nature Beauties. So you can't recommend that person. Okay, go and watch like when I'm in DC go and see Abraham Lincoln Tower. They don't they're not interested in those things.
 So I think they can also the other part would be where after this three part they have this LM model being more Centric toward the user interests. Not like a generic thing that you will do in that city or town. Yeah, I think that's something very much easier to do using LMS, if we are using because with traditional ml models you can't say what people don't like. Yeah. So I think with the traditional model the problem will be they will have to first get this feature of the user.
 Like the more. Yeah. So if I'm a first time user if it won't be able to handle that. So I think LM does pretty good with the cold start problem because they just learn it like very quickly.
 So even though I asked them today that I am more laid back person, what are the things that you will become and it knows, okay? This is what you need to know.
 And since we are already using GPS so much and it has all the data on it, so it's much easier for them to understand, okay? This kind of person might like this thing. And then
 The question becomes.
 that data sharing, because
 Chachi BT or whatever anthropic or Gemini. They have that data because I talked with it all the time. Yeah. But then is the service that I'm using to book, my flights or book, my whatever, is it going to be through chat? Gbt? So it has that date on me. But I think even though if that using any LMS and they can still can understand like okay, if the person is more toward this nature, they might like something around it because even in general, as a human, if we see some person, he like more introverted person. We know what things they, they know they won't like to society, right? So how we know that is just we just know one data point about them that the person is introverted. And so the same thing is with LMS, right? I think they just need few data point. They don't need all the data points. Like how do I look what I do in every day? Just need one, see what you're saying. So it doesn't have to be so rich. It doesn't have to you don't have to give it a million features, you just give it one and it'll give you.
 And then we'll give you at least.
 Put you in the ballpark. So you can say, hey, we've got cool movie theaters, but then those super specific ones. You'll need special data for. So I think even for the any
 Ah, even for your feed or anything that you are using llms, right? It's very good in doing a, generic recommendation, based on your past interests or something. But if you want your post to be very, very like granular towards you. It has to learn all those feature eventually. So and that it learns over the time, right? Even how does a GPT currently know? So much information is because it has learned about us over the time that we have been chatting with it. Like, when we ask something about a mortar, something it knows like okay this person might be working on certain areas. So when you ask it gives you similar ideas like right? So I think that's what everyone will learn over the time. So I think as it's trying to do, similar to humans, right? So as a human we talk and then we get to learn more and more about the person. So and we can recommend more things about the person. So I think that's what the llm is trying to do here. But when you compare traditional recommended system or any traditional models, they are only learning whatever, we are giving it to you're not doing any
 Active Learning while they are doing. So if I only give you three features, you are only going to learn about those three features. You don't have any idea about that. They can't write the current model. I think there are some improvement that's been going on, but it's not there yet. Okay, if the person is introvert, then the person can also with this. They don't know that yet but LMS knows that, right? So if the person is say autistic, they might be introverted or to stay or they might be. So there's only two ways that they can be categorized, but in traditional model, they won't know, they just know. Okay, this person is autistic, that's only information it has. So it doesn't know the features of autism basically and in LMS they know the feature of features so I think that's what is making them more powerful compared to the traditional elements. It's yeah. It almost gives you a much more Rich feature or that coming like the 360 view as a very two-dimensional view of. All, right. There's this feature. Yes or no? Yeah. Okay.
 There's this feature. Yes or no? Boom. Yeah, there are
 Some improvement that they're making in the dark side as well. Where do you cross featuring? So if you have this feature, then probably the feature, if the person has feature a, that person will have feature B so then they do CrossFit ring. But I haven't seen any successful research paper out of it yet so I can't say 100% it's going to it's working or it's it will work but I think as the AI is evolving. Obviously, I'm pretty sure that a lot of researchers actually working how we can do the same thing without it says, well without so I think recently did a work on ssms so which is State space models. So I used this model to basically do question answering and obviously it, we used llm is much better to do it but what I did it was just for the like index languages like language that's being spoken in India over. So there's very much less data that you have and there's much more change in the scripting part of it.
 So I didn't use him for two reasons. The first, it's very heavy to use. So it's hard to find tune in, if you are doing from academic purpose,
 the second part is like, it's a
 So I wanted to see if we can use some lightweight model because just a question answer is I'm not asking you to recommend after this or after Above This, anything, just giving a question give me the answer. So I think for those kind of things I did see that Sim is able to perform much better than a lot of other Transformers model and transform models are. So if you consider like a bird or robot or models, those are also large language models and it did perform better than Roberta. So we so there are some models that's being developed currently which are more
 Like kind of equally well as well and or like slightly underperforming. But then the problem is, they are very specific. Like, it's only going to work for question answering but in them, it works for everything. It's summarizes. It question, answer, it gives like summary of whatever you have given it to it. So I think there are people can develop or when eventually, there will be some development where we can do so many things with smaller different models rather than having one huge elements. Yeah. But that's like another area that probably will have some research later on. So, yeah. And you see that being different than the way that we're doing recommended systems now.
 Uh, I don't think that will change anything with the recommender system because in the recommended system right now, we are doing the LMS right, because it's making sense. But if I force for right now, I don't see anything like that, but in future if there is, it might change. But based on this, SSM evaluation that I did, I don't think it can replace the recommended system, and because it doesn't have that much. So, it's more for different use cases. Yeah, it's more. I would say it's more very specific. If I want to just do like one task out of it, it's that model is going to be just made for that task. So you have to create multiple models for each of the tasks that you want to do. So it won't be able to replace the whole llm for sure. But what I'm saying is like maybe in future if since people have already put some put on this direction they are all. So probably be researching on how we can do.
 A more better recommended model without using elements as well. We never know like what's the future if it's really good at one task, then you can potentially plug it in to your dad and you have that as the one task that it does. And you know, that in my workflow, I need this done. So we have that done but or you plug it in as a tool for an agent to use. And I think that's the next
 A wave that's coming right, agent here and I think with the agentic I have been coming since you bought it up. So I think it might it will change a lot of things. Basically if we if it actually starts performing that well because based on the certain based on the like research work that I have seen. So if I don't see lights outperforming drastically anything but maybe over the time it will evolve because I think right now it's ending is not that phase that we can count on it yet, but I think if that is there then it's definitely going to change the recommended system as well. Maybe I don't need really and I'm says, well, I just asked the agent. So this is the person and this person likes this just recommend it, whatever and you put some layer on, like, put some more inside the Gentech. Yeah, to do certain tasks like right, you just add some flows to it. So like, even there's nothing I could be for say like if I want to like a research paper, right? And I give like, okay, so this is Agent which rights research papers and I give you like
 This is the, this is the paper. This is topic that I want to write about. So do the literature survey. Do related works out and just write a paper for me. I went to submit it to say a new ribs or CPR and it does that for you. So you just need to review it and that's it. And if, if the gents feel like they're lacking some information or they want some validation, they can obviously ask back. And so this that's the least effort you have to do, right? It does the experimentation it does deliver teacher survey and it just writes the people for you. So then, what's the future for the researchers? If there's anything, I was able to do that, you just have to give idea like this is something I think might work and then it will do all the different layers of work so you can have agent for each of the tasks and it will do that. I'm ready for when the agents can go out and also collect the data to their calling people. Yeah, I think I think it's evolving, but I don't know if it's going to work that fast.
 Because no one, I think five years back. No one thought about LMS or anything, such that, but it's it came and it changed everything drastically. So we never know, maybe they didn't take a is going to be, usually, reliable by tomorrow and then everyone is moving toward it.
 so yeah, you bring up a great point with the reliability on, especially on agents and how
 Right now, it's not good enough to actually be using for a lot of different pieces of this puzzle and is specially, if you're at a big company like LinkedIn. I imagine it's very hard to figure out.
 Can this work?
 in the manner and fashion that we need it to be working at like holding it to this high standard so that it's able to
 Complete the tasks.
 Nine times out of 10 and there's so much work that goes into that. Yeah. You think about it for a second? You go. Well, actually our recommended or maybe there's lower hanging fruit that we can tackle before. We need to find out. If we can recreate a recommender system with agents as a to just the LMS versus the traditional ml.
 Yeah, I think I agree with that because I think the agents
 are so fast. The thing is like a LinkedIn or any other companies, you're shedding those information. So first you need to be very sure that the agent is being used correctly.
 And so that's like the first part like privacy and everything is being taken care and then still, you don't know if the so it becomes very hard to debug and agent. Like if something goes wrong like where so I got five output but maybe all of them are irrelevant but I don't know like what should I fix in the agent to get those to be relevant? Yeah. Because even with LMS or even with the traditional so I think one thing that's very easier for the traditional recommended system, it's very easy to debug, you know, like what is coming and how you, which one do you need to tune to get the right output? Even the LMS, you are only 50%. Sure that white might be doing it but you're not 100% sure. But I think with agent you are 80%, not sure how it's doing what it's doing. So you it's very hard to debug it if you don't know what's happening inside the black box, so the agent becomes a kind of black box for us, right? So we know like we are giving this information, we are asking you to do it but we don't know like how it finally ended up doing it.
 Early. So I think as as more advanced we go project or any other thing, it becomes more and more black box going backwards. So I think that's where the traditional ml models or any traditional models brings more sense because you know, like okay this layer is taking care of this, that's why we're getting this. So it's simple maths that you do and then you get it. Yeah. But with llm I know it's still math but like you don't know exactly which math is good to get you what you want. Yeah. So I think that's that's going to be very challenging with identity I guess. Yeah. Right.
 Total random question. Why have I been seeing older posts on my feet lately in LinkedIn?
 Okay. That's a very good question. I don't know why. But when I say older, I mean, like, a week old two weeks old, three weeks old. I remember seeing a nursing and a new content. No, I am seeing, but every once in a while, I'll get a two week old post. Put in or three week old post put in and it's like, what is this doing here? Maybe. They don't have any new posts for you. I've looked at it. I'm not much of a power user know. I have more friends. I got more than like five friends and I think they post about. Yeah, I think sometimes it's also like maybe the model, does it have the new data? So it's not recommending, then you post. I thought for sure it was some kind of a weight, got tuned to show more.
 Wonderful. Yeah. Older posts or like your post has a longer life time now.
 because there's certain posts that
 Have more exposure or but it's not. Like I was thinking about it too because I was looking and it's not like these posts have been performing wildly. It's not like they're like those thousand likes posts. It's like a 30 like post or a 100 like post but it's two weeks old or three weeks old. Maybe there's some bug that you should definitely because that's not, that's not what we expect. It's not normal. Yeah, that's really normal actually. Yeah.
 You shouldn't be seeing like older and older posts? Yeah, I think three weeks is the oldest that I've seen but it's pretty common. Honestly on my feet. I'll show you in a sec. Okay. Yeah. And I thought it was for some reason. I thought it was your your change in the model to give the post a longer Lifetime and
 It made me think now.
 because when I first started using LinkedIn back in whatever 2019 the posts would
 Have a long lifespan.
 like,
 it would take a few days for the post to get going, and if it got going then it would stay for a bit longer like a week and a half to weeks type thing when I say longer, and
 then I saw it shrink and it was like, okay now it's more like
 it happens for a couple days, but
 It's really hard on LinkedIn to share things.
 That are happening today or tomorrow. Not like, you know, like with Twitter. You usually, oh, I'm going here who's coming or I'm free in the airport for an hour. Ask me, anything that kind of stuff is impossible because it wouldn't even though you posted your user won't see it. Exactly. So it won't make any sense. Exactly. That's it. Yeah, I think that's the area that I don't think Lincoln is currently working on like but I think that's going to be. I think they will be working on that very soon because that's the important because if you think of a LinkedIn it's more kind of professional networking, right? And for professional networking you might not use such things like, okay I'm at the airport or let's meet or let's chat you probably plan ahead, right? So I'm going to this workshop and I plan to do this this. So feel free to connect or feel free to come and talk. So that's like a professional thing that you will do on LinkedIn. Maybe that's why that's not the party that they want to focus on because on Facebook Instagram you can just go and write. Okay. I'm
 Here just meet me yours but because that's a purpose, right? They want to be social networking, but I think that's where LinkedIn separated from Facebook or LinkedIn or Instagram or tiktok. Is that a LinkedIn is very specific. The professional networking. What they call is like you connect based on your profession. So you basically look at someone is in industry is doing very well and you want to connect to that person. Yeah, this is a platform for you. So you, so basically, I think that's probably why they don't have this feature that you can just post it and everyone can see and come. It's more about pre-planning. So I'm going to be there. You can come and we can have a chat, explore and talk whatever.
 So I think that's the One Direction and regarding the older post, did you also tend to see this post earlier and then you saw it again? Or is it just the first time you saw? And it's three weeks old.
 Sometimes I would see so both but sometimes I would see it once and then I would see it again. Okay. A few weeks later, why is that something? Now it makes sense. No I it's still doesn't make sense. Trying to see what are the things? Yeah. Yeah, because I see that. I liked it already. Okay. And you still see it? Yeah. And I still see it. Okay, I don't know. We're debugging live on air. I like it. What is going on? So is it then my cluster has a finite amount of people and they're on when they're on and then you show it to him when they're on and if they're not on you don't show it all. You don't show it to him but it's like, oh there's 2000 or 2 million people in your cluster and outside of that cluster, we're not going to ever show it outside of that cluster, unless it really.
 So I think if some post becomes very viral that's being shown to everyone. It doesn't matter what cluster you are, but I guess the question I have is then. So the cluster is basically on the offline side of it just to get the features from their butt on the online side. There is no such thing as cluster, everyone is safe user. So when the post is there, I the model just knows based on whatever it has learned from the class or whatever feature it has been given it just knows like okay this is arpita's AI post. Maybe someone from LinkedIn or someone from a, I will like this post. So or is interested in this book, it even though that person is not in my network, it will still recommend that post to that user. So I think what it does it during the inference time, it doesn't know any clustering, it just know whatever it has learned so far. So when I use example of clustering it's just from model to learn like how it's learning those features. So once it has learned it like, okay, so are with us not from finance and there's her friend who posted something about
 This maybe she might not be interested in it because it's not the area she works or something. And then it might not show up that day on my feet but later on since this we are still friends right? So it might show you okay after even three weeks your friend did finish her mind and finance education or whatever. But then so I think it based on the model at that time they already have like say it has to rank top five posts for my feed and it already has the best top five, then it won't take that Finance Post in. But after 10 days or 20, I don't have enough post or there's not enough being posted about then it will pick that post and we'll book at like the first position that this is a post and all. So this answers to that question where you have multiple post event showing up again and again probably there's no they couldn't find any relatable content that's available, currently that could be shown to your feet. So they just show that post again. Like this is all we have for now.