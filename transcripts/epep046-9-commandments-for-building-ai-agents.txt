At any given point in time there will be a bottleneck or something that doesn't work. It's like oh we need and you know authentication solution. We need a better rag solution. We need a better embedding store. We need the better model. Yeah. I don't think there's a simple Vector where I say like Well in that space will never buy again or never build. How do you make sure that your agent has this idea? Okay as this is ambiguous actually don't know what to do so I need to go back and forth with a person. So actually understand. What's a problem is we always prefer to have this clear borders between things. The reason act observe plan act, it hardly ever happened like this
 Today, we're talking with Paul and Dmitri about building effective, AI agents and the design principles that go into that.
 Paul is the VP of AI at process and Dmitri is a senior director of data science. I myself and me trios, the host of the inner Ops Community podcast that you are listening to, let's get into the conversation.
 For all this talk of AI Workforce, I still haven't seen enough agents, helping me with my Awards. Your email has got to be basically your whole when you opened your laptop, the notifications that you had were overwhelming me just in the first five seconds. Yeah. I mean, you know, it would be helpful if they actually start to take away some work so far, they're helping a lot creating more but it goes to that idea of the cognitive load and then how you can get this overload because
 Information is so cheap now. Yeah, and how just it can be so noisy, I continuously reference your idea on WE plugged an agent into GitHub, and we turn it off about six hours later, because it was just constantly pinging and pinging super verbose, like giving all sorts of commentary that just then requires you to read that. Yeah, process. It judge it and act on it or not. I call it like the agents or the llms and AI in general is disrespectful of my time. It doesn't recognize that you have a finite amount of time. Yeah. And so it will be verbose and it will give you all of this information or it will ping you and just kind of like about nothing important and so that discernment I'm not sure if you figured out a way to get through that filter. Oh yeah. So I think there's a lot of interesting lessons from building agents for e-commerce. Where each of the initial experiments we
 Doing, we're just building, let's say a chatbot for, you know, shopping and ordering food for buying a car for looking through real estate. And it was sort of like you get people coming in and they say, you know, they're looking let's say on OLX right? Which is our secondary Marketplace and I type in, you know, iPhone 15. That's their start of the conversation iPhone 5S. If it's a search engine enter and then comes back like 10,000 tokens of. Yeah, you know, we've got this one over here expensive and you're oh yeah, instead of just scrolling you realize that that's suboptimal. So how do we deal with that to ask you a question? We're starting to go into much more of an intuitive UI with Jane AI, which is you give people some information of course. But you know, which is tends to be more visual much more structured, but the end you have buttons, is it? Listen, you're now need to choose. Do you want more options, different options, cheaper, options, options, near me, and so you kind of preselect what the next thing is the user wants to do, yes. And you make it
 Clickable thing as to then putting that sort of high cognitive load burden of them. I'm actually having to like describe all the other things that they want. So anyway, so this, this feels like one of the principles in building out agents. We want to talk today all about the different principles that you can have when and you need to think about on a technical level with Dimitri. But then here just like from your side of the fence. How do you enable the team to go out and make sure that they are fulfilling these different principles? And so when I think about this, I reference the last talk that we had with florist and how you all are doing hackathons all the time. And you're trying to really push the boundary of what are some wild ideas of where we can throw in agents?
 Through that. I imagine you learn a lot. Yeah there's a lot of different things. Here's a big open question. Yeah we do a lot of different. Whatever thoughts. Right by these we did have fun recently it sounds different than what I thought was gonna be for a minute.
 And so the the goal here is, you know, the role of our team, right? So is is to basically figure out where can we move AI into production agents into production into real products into the real teams that where is it ready? And so the only way to do that because the decision the field moves so fast. The tools evolve so quickly is to continuously you know roll up your sleeves and try them in an AI team. You may assume that we all know and see and use all the tools every day and we try to. But if you don't actively spend time on exploring that you also fall behind. Right? We tried Devin a year ago. We try, you know, minus the moment came out, six months ago, we tried deep sea, all these things. And if you try them again today, they're significantly better yeah? Right. And many other tools that we tried, didn't get significantly better yet, right? So, having this sort of continuous drive to experiment, to try to hack around and see if they
 Work is something we have very much in the DNA of the team to make sure that we all understand what is real and can go into production. At the end, our goal in the team is to make sure we build real things.
 That are useful and aren't just a demo.
 And so to have the distinction, what's ready? And what's not, you need to get your hands dirty continuously and try it all the time.
 I want to ask you about.
 How you think through forward compatibility because like you said a you test tools at a certain point in time. Those tools are how they are, but the teams continue working on them, the technology continues to get better.
 That's great. If you come back to it and you keep revisiting it.
 That seems like a lot of work, but all. So, there are things that in my head are continuously getting better and you can try to make them better and Brute Force. This,
 Capability from the agents or the llms or you can wait, and maybe it'll get better in six months. So thinking through the forward compatibility and how that looks in a future that's moving so fast like the six months down the line,
 Is there going to be a longer context when doing? Then you don't need to think so much about trying to hack together a solution or
 Is it something that you need to invest time into building yourself? Yeah, it's a great question. So at any given point in time when we build agentic systems AI systems more, broadly, there will be a
 You know a bottleneck or something that doesn't work. It's like oh we need you know, authentication solution. We need a better rag solution, we need a better embedding store, we need the better model, right? Maybe the model isn't perform at the same level and you can think about what to solve the model problem. Like in theory I could just go and you know train my own model. Yeah. Right. But I'll tell you like the fastest high value depreciating asset, I know are elements, right? Like companies that spelling 100 million dollars and training these things. And then three months later. There's a new one and they they switch, right? Like it's a commodity in many ways and whatever. There's a new one. Everyone forgets about the old one, right? And all the traffic goes there. So you don't want to end up in situation. We're a small team.
 Even though we spend a lot of time on building the right things like you know, we will train models, but only for areas where we are very confident that you know, there's no nobody's gonna solve that for us because it's a specific domain and specific area or we needed to be efficient. So it needs to be fast and so on.
 in terms of so-so forward, compatibility here like
 Again, going through the list of problems could be.
 I don't know, maybe this the model we used today is too expensive.
 Should we therefore not like work with that model? Or should we just assume that in six months it's going to be, you know, 50% cheaper and we actually operate under a couple of principles that where we believe that you know, technology is going to kind of move.
 In that direction no matter what one is models will get cheaper that's certain rate and we make some assumptions on that second is you know model context will continue to get, you know, bigger. We've seen that happening that's so true. And so you don't want to continue to optimize too much on their Rags side and chunking and so on. If you know that eventually you know you have in your infinite context and you know on certain modalities we have some expectations. So that's voice or video or imagery that they will be able to get better over time so you can already start to build solutions that today are 80%. But you know soon they'll be, you know, 99%
 So, we with that sort of intuition of where things will move, we're fairly common to start building already, and to have take that in six months, it'll be cheaper, it'll be better, and so on. But there are some areas where we actually need to build a solution like software to authenticate as part of a rag pipeline to give you an example, right? We need to retrieve documents that are inside the Enterprise at the company. And we need to make sure that only the, you know, certain types of Agents can access that and use them for answering a certain question. We had that problem two and a half years ago and you know we're pretty sure everybody's building these things has that problem, right? Because you need to also give agents that I permissions and so on.
 So then the question is, do you build for that yourself? And your so that is kind of the framework that you're working on? And that's why you continuously are revisiting the different tools and you're seeing? Did they get there yet? All right, we've got our eye on these
 Set of providers like the composers or the arcades or whatever it may be, you know, you need off. And so you're keeping an eye on the space, you're testing it, and then you're waiting, and then you're testing it again and your way waiting and you're seeing, is it?
 Advancing in that rate that we're looking for absolutely. And, you know, there's just so many of them and the problems we're trying to solve are real observability, rag authentication, you know, logging and so all those things are real, evals your problems and they all try to solve those real problems. But many of them aren't there yet and so we try it. It's a line of Smith in arcade a compose you and sometimes,
 Actually, most of the time, unfortunately, we still have concluded that once we move to production, the tools are not there yet. But again, we're small teams. So I very actively encouraged everybody. The team to make sure if there's somebody out there that's solves this General problem, let's use that tool as a post for us to build it.
 Unfortunately, often still the tools aren't ready yet, but we starting to see with our kids to get example, which we know we are now adopting because it's good, you know, good enough for what we what we want to build and there's several others. Now in the, in the tool Suite, we'll talk about
 but there's another thing like,
 actually, what's in our benefit is that it's much cheaper to build software for, you know how much easier because all these tools now,
 so in some cases, we're actually faster better off just to build
 You know, our customized solution with, of course, the Devins the cursors, the wind serves of the world because it's much quicker than to go out there and evaluate five vendors and test their Solutions which are never perfect for your situation. I get legal agreement, do price negotiations, and so, it isn't just only a economic like, is it? What's cheaper, what's faster, right? And something that we just need to move fast and so we'll just put something together and some parts of the software that's fine to build our own. But what we see is it's much easier these days to cheaper to build.
 Your own then it used to be to three years ago where you just don't have time to build whatever, right? You don't nothing solution or a Content management system, whatever, right. So
 are their vectors that you feel like
 Have been completely.
 Demolished that you never want to build, or you never want to buy anything in that space because it's so easy to build and that time to production is so fast. Well, it's never say like always or something or never or whatever. I think you
 It, you know, as Engineers, I think we always have the natural propensity to build to build yourself. Yeah. Right. It's fun. We think we prefer to do that. And so, we understand it. So that's kind of where it's been and then, of course, as a team, you need to sort of make sure that you Choose Wisely build or buy
 and buildings becoming much easier and cheaper.
 So that's that's one reason where for small things we will build and ourselves more frequently and by hasn't been ready for many of the cases where concerns agents in production but by the space of options work you can buy of course in two years from now, we much richer, right? You have all these startups that will mature the solutions will mature, Community is open source projects standards like mCP and so we build basically like a solution for MCPE a year and a half ago, tools controler right now we have MCPE and we're grateful because now, you know, that makes all of our work much easier, right? Because there's an agreement standard to this. So,
 I think there will be some areas where I don't think there's a simple Vector where I say, like, Well in that space will never buy again or never build. It really will depend a little bit on also what others are doing with compatibility of the models with the you know all their parts of the software stack your interacting. With you've mentioned a few times different
 Things that you're encountering and then later Tech comes out. Yep. To or a yeah, open source project or the standard like mCP. Do you see the folks?
 that are on the team building tools and specifically becoming more
 Adept at the tool building process or is it more in the vein of? I just want to have the agent and I'm going to build this agent that goes and does something for me.
 So right now, we are definitely thinking about most of the things we build as a
 Let's take a set of building blocks that the end user can quickly stitch together to solve their need and I'll be give you a specific example. So our internal, you know, AI assistant token.
 Has been around for a while as we talked about in other episodes, you know, answered millions of questions for you know, tens of thousands of employees around the world.
 And now people have, you know, lots of use cases as part of their daily workflows. Hey, I get this Excel sheet. I need to kind of upload it and write a memo around that like a nine monthly report or something. Or I've got some customer calls that are coming in, I need to transcribe them, to figure out, you know, what's being said in the center. So there's a, you know, examples where people are starting to basically, you know, integrate this is, you know, daily updates daily reminders of things that they're doing right. Give me a plan and give me actually an agenda for the day generated dot. ICS file, based on these things. I want to do that. I can upload to my calendar. So I've got all my invites there. That's cool. So, but those are you will be doing this. Something for the me, and, you know, the next person in the team will do something else. And so, we are now with token building spaces where people have basically the ability to create their own tools integrate into their sales force environment, their monday.com environment, their databricks environment, and have
 This General agenda capability that then they can point to those different tools to solve a certain problem.
 Many of those people are not as a native AI practitioners, right? So we need to make it really easy for them. They're almost like, think of like gpts, but, you know, accustomed to for us to, to process to Commerce to the our world. Yeah, right. And that means that we have a certain set of
 Systems that we integrate with, like, I mentioned databricks but also other Cloud environments with data and financial system sap. And some of the are standard tools that we make available. So anybody in finance can connect their part of that database or anybody in HR or the legal teams, or the data engineers and so on to create their own identic systems. So then it's about offering people in general, logic capability with a set of tools and giving them a no code way to describe what they're going to do this agent or this space is workspace, and just can't workspace is going to be meant for as an HR Support bot, right? And then basically, this HR employee points to what data that HR Support buttons have access to how should behave they described that click and now it's publish to everybody in prison and they can now get you know questions about paternity. Leave about a performance review processes and so on created by somebody that has
 Basically, no, I didn't have to program or understand any of the underlying agentic systems to build it.
 do you feel like, as
 You are using agents more and more.
 it becomes clear that, that is the way forward where these
 Tools are going to be built with the no code solution, but then you have the engineers on the back end that are making it as easy as possible for the subject matter. Experts to
 Put their magic touch on it and do their stuff. That's exactly right. So we actually have this theme across processes, AI Workforce, and Sean will talk about that where we want to make sure that everybody's got access to their own AA Workforce, you know, because considered everybody should be able to have it, you know, team of Junior analyst some interns that are agents, right? That they can create and have them work alongside them.
 And so we have very specific initiatives, you know, objectives for the coming period to actually measure number of agents that are created across the company. How often they're being used, how many questions they're asking to actually, push the adoption of these basic capabilities for anybody in the organization that, you know, doesn't need to be software engineering. It's actually should be anybody.
 And we do that through token and many other tools of course as well, okay? So going to these 10 commandments that Dimitri is going to talk to us about. I wanted to get specific on one that potentially isn't
 Understood the same way by every person which is the memory piece. I know there's almost like two ways to think about memory. One is I know that you, like, buying a certain type of shoe or I know that you like these movies traditional kind of recommender system, I remember that you do these things. And so I'm going to know that for the next interaction with you and then there's another memory, which is the agents, remember how to do things. And so they have this tool in their tool belt. Like you were saying when you're connecting the different systems together.
 It would be great that.
 An agent.
 Learns how to do something within a system, and then it always has that in their memory so that it's not just guessing when it is trying to accomplish that same task. Again, this is such an interesting topic, I think the memory piece is, you know, it's an obvious area that we need to build that. Once you start to think about, you know, the types of memory that these agents need to have to accomplish certain tasks, they become, you know, you know, it becomes much more granular. And in a way nuanced complicated, what you need to build short-term memory, long term memory, you know, like character, right? How do they behave over time and so on. So there's lots of things to be said, let me focus on.
 The piece of the agentic memory which is related to getting better at a certain tasks which I think we're going, right? Because of other memory like memory about me because you talk to me 25 times and so on. But let me focus on getting things. Done for you better and faster. Whether it's, you know, helping me with the pr and the software world, and agent system like Devin or Manus or the e-commerce agents that were building with the large Commerce model and so on, to help you find what you need. I think that overarching sort of thing that we're seeing here. Is that
 These agents will are now starting to learn from their experience with the world.
 And what does that mean? If I go in and use an agent in a Commerce setting? Like we do at iFood and OLX and take a lot and emag and the companies of the prosus group.
 This agent, let's say I come in with the search query and you know, you're going to have a conversation with me about this. I don't know, let's say an apartment you want to rent in Paul's on and Poland and it will help you find what apartment you'll say. Well, I have this kind of requirement needs to be 60 square meters. This is my budget. It needs to be in this area and you should refining that. And eventually, you know, you'll know whether we know the agent will know, when this person contacted the renter said this successful event right now that we have helped them something that they thought was interesting. And so, in some cases, also know, when they actually, you know, made the agreement to move to that apartment.
 That journey is now something we can see that that was a helpful agentic Journey. There's other cases where the person isn't fine or it doesn't succeed or we ask the agent to help browse the web, right? But it didn't find the information it needed and so on that's also useful because that's a negative example. Like in this case it wasn't helpful for the intent of the user.
 Those experiences if you store them and you can actually train your model to do better reasoning right because all of these are reasoning agents now, right? So they have a model that they. The first thing it does. Is it reasons like deep sea? We've all seen it and now a one or three or four. And so on are first, making a plan and thinking through, how should they approach this problem now, that's generic reasoning.
 It's great. It's generic reasoning for answering a certain question that you any question on Chaturbate, Claude, Gemini and so on. We're trying to figure out is what does it look like if you use the experience of the agents storing when it was successful or not successful, those experiences to fine-tune the reasoning. So now the reasoning becomes really good to help you build a certain, you know, type of software in your coding environment, right? Because you always care about having these standards or it becomes really good at taking a query and food delivery search query and helping the user find what they actually were going to want to order. And when you say fine tune, you mean actually.
 Renting gpus. And yeah, not just throwing over the training models and it's not even just only fine tuning, there's all of the training variants, you can imagine that. We're we're working with now to basically create models that understand what the best path.
 to success looks like, and what it, what we're able, the reason we're able to do this because we can actually very quickly gather the data, whether it works or not, because these are, you know, real experiences, real products in the world, we've got and, and so that allows us to create that flywheel collect experience is
 Got to the objective or didn't get to objective, and it's sort of a, it's sort of a reinforcement learning, not in the traditional, technical reinforcement, learning sense, but you do store the successful path and that becomes input in the next training round. And you're saying that is creating more memory or that is. It's like inherent memory in the model now, right? And so that is it's a form of memory because you're storing all the successful paths to a destination, right or successful action.
 Because we've got, you know, hundreds of millions of interactions with users those paths.
 Our store, their memory, write this. I actually learned how to help somebody find their shoe, right? I actually learned, what is the best way to help? Advise somebody on, finding an apartment to rent in poznan. I sorry, I thought you meant find your shoe like you lost it inside. Oh yeah. Sorry like buying a shoe, right? So finding the shoe that you want for your next example. Yeah. And I needed to find it. The model helped me. Yeah. And so yeah. All right or somebody says, Hey, I want something healthy quick for lunch at the office. Like, that's a search query that, you know, surprisingly, I guess. Surprisingly. We're very bad at, like, at answering today, right? Healthy for me, what's, what is quick? What's? Yeah, and doesn't matter if you're at the office as a matter, if it's you versus me, like all these different things that
 by said being very deliberate about memory, you're you're creating and giving the agent access to make a big difference so I hadn't heard or thought about that way in thinking about memory as
 you're taking successful Journeys, you're all, so taking the non successful Journeys, and then your
 Giving the agent, you're spending Cycles on fine-tuning it. So that the agent has that part of it. I had always looked at it as something that you do after
 The reasoning model is there or after you've set up your agent and it's just like memory that you're bolting on top of it with caching it. For example, you can do that so you can definitely do that. So some areas where we've done similar things is, you know, we we've been playing with web, browsing agents like many others. So you give it a task go and I don't know, find me the cheapest iPhone 15 Cellar today, right? Or help me order, you know, salad for lunch. Let's say in the food ordering space, and then this agent goes starts to browse goes to the various websites and
 What we saw initially was, you know, wow, like we tried this 50 times and it only succeeds, you know, 10 times and maybe sometimes five times because he got stuck on a capture got stuck on, didn't scroll, it didn't really find the items because the search term it was wasn't good. So but what's cool is that you give it a simple test, go and find me a cheap healthy, lunch, to order to my home and it goes all the food delivery providers. It looks at the restaurant that are open, it goes and browses the web, right? Like you're, I would
 Um, but that search space is actually pretty broad, right? It'll take all these steps and these paths, if you will and out of the 50 trees, let's say five are what you would have liked or you would have done yourself, right? And
 And we then store those five.
 So that next time somebody comes in and searches for food and a general sense, it will access those five paths as a reference successful way to get to that. Then we slightly different things because maybe I was ordering in a different area and your or in different country or you know you gave a different preference for whatever you want it or the website got updated. Well the website that updated then yeah exactly. Then you gonna find, you know five more ways not to do it, not to succeed. So and that can be accessed perfectly as sort of, you know, in a cached away. Doesn't need to be trained in the model, right? We also tried those things, but I think the important piece is once you start to be delivered about storing, what's successful?
 And what's that isn't the path to get to successful outcome? You can then feed that into the model either as a cache or through rag or eventually if it's large enough, like in our case we actually also train models on that as well. It really goes back to what I was talking with yani's about yesterday and he said, oh my my take is that evals are your moat and so the better that you can get with your evals, the better, you can expect your agents to perform
 It's a really.
 important realization to, if you don't know whether what your model or your agent did was good,
 very hard to improve.
 That's simple, right? I think that notion everyone understands but then what does that mean? The real world that means you need to actually get feedback from the users or know what they were trying to achieve or and know what they were trying to achieve to know whether they're successful or not. And because we've got, you know, two billion consumers that we serve across various parts of the world, interacting with the Platforms in different ways. We do have ways to know whether they got to their outcome. You know? Did they find what they were looking for that? They buy something that they contact a seller, if they're on the second hand Marketplace. And so on that,
 Isn't evaluation, right? Evals is a technical term. We would use as AI developers. It's basically, this was it, it was good or not. Was it successful or not? And that flywheel is indeed a moat because that means you can then feed it back into your agentic systems. They can use that to get better. The next time, the same or similar question comes in and I like how you're saying, there's many different ways once, you know, if it was successful or not, which is step one. Yeah. Then you can figure out how to incorporate it into the technical side of the system with. Yeah, cashing it or updating your rag system or fine, tuning it? Yeah, I also like that you are hyper-focused on certain tasks or certain verticals per se, for example, if it is any Commerce and you're just trying to figure out the path of one of these Food Delivery Systems when someone is using that, you know, there's only a select amount of
 Things that someone is trying to do when they get on to app, and it's probably along the lines of ordering food. Yeah. Or or in travel, and so on, and we found that it's actually the generic Asians the broad ones. They're, they're very bad at some of these specific things. Like, if I actually want to get some help and booking a flight,
 The agent gets stuck, like things that we think are very easy.
 These agents fill it. So an example is scrolling is not something they automatically do or understand or think about if I go and select my departure and this and arrival destination airport or look at the dates. Typically, every travel website is a little pop up, drop down. Yeah, scrolling because whatever calendar you need to pick out the day stations, suck at that. And so we were trying to do.
 you know, those help these do those tasks and sure, you know, you could perform at, you know, 50% on OS World, Benchmark or whatever other you know, web browsing Benchmark, these agents are being
 Benchmarked against.
 That actually doesn't translate very well to the use cases. We were, we are helping our users with. And so, then storing this memory write and say, actually this, this is the way that you helped the user, find the flights from A to B, and you need to scroll, right, or you need to actually translate this dates into an action on, you know, a grid with the calendar. So on those are the kinds of things that we need to build and be very specific on to get to a certain level of accuracy for the user because this is if it's not like
 I mean this case really 95% successful useful people won't use it right. If it gets stuck all the time and you know and then choose the wrong flight. Yeah exactly doesn't accept cookies in Europe. You need to accept cookies that agents don't know that. So
 They haven't been trained on enough European data. Yes.
 I want to bring in the experts now though. So let's get to that conversation.
 Action live. We are here with Dimitri in the studio. It's great to have you. I want to talk all about this unified rule set for building AI agents that you have put in an enormous amount of thought behind
 when I saw it. I thought, man, this is so good. We need to have a full conversation and podcast and breakdown. Some of these, hopefully we can get to all of them, but I want to hit the most important ones to start.
 that being said,
 AI agents is a contested term. You have a special
 definition for it. Give it to me. Yeah.
 So well, thanks for full. Thanks for having me here.
 Yes, I think that for me, AI age and he's a solution that is able to achieve a task by select. And by itself, the boss towards the goal and also by defining itself. What the Andes. So, wait to stop.
 and they know that it's not complete and you can have so many Corner cases where you would point to a simple piece of software and say well it's kind of does that and I know that some people say well what would be good to add here is memory
 So it can learn from the past, it can learn from its mistake and do better. And
 Yeah, I think it's it's a fair point. But again, there are so many cases where you say, even without memory, you can build a successful agent. Yeah.
 It does give you that spectrum of. Yeah, it's autonomous in a way it also knows when you stop and knows when they get more information, it's not a workflow that just gets kicked off and it's not something that you have to hard code and say, do this this, this and this with a little LM spring in there and then you call it an agent.
 Exactly. So not everything which uses a llm.
 And flexible, execution, boss is an agent.
 Oh so when you need to be careful here, but all, so not every sin which has certain rules. Predefined rules is not an agent. Yeah.
 There are.
 A few fundamental principles when building agents. And I think you with this document, you put the most fundamental at the top. What is that?
 Well, for me is the most important part is, how does a cycle of an agent? Look like, alright. So when we started building agent, by the way, within know it was called Agent yet, it was couple of years ago. And with this piece I believe that you talked to some of my colleagues about data analysts, right? And we essentially implemented, what is now called react cycle. So reason act where we say, you know what, most of the problems that you need to address, they will be implemented by doing two separate parts.
 One part is what we call comprehension and reasoning.
 And another one is execution or acting, this is why reactors. The name is still a very popular concept and depending on the task at hand, you will have a very different distribution of complexity between a comprehend and between executive between reason and act. So let me give you an example. If you think about data, analyst type of agent, so something which takes a problem and tries to extract information and provide you with an answer.
 Significant the most complex part of this would be comprehension.
 So how do we take what user asks?
 And bring it to the point. When we know what we actually, what data we need to retrieve. What report we need to write. It's very difficult. My favorite example, it's real one. Somebody goes to data analyst and says, what is a fastest growing company?
 Fastest growing by profit Revenue people Sales Plus, open-ended fastest growing last month's last year. What do you mean, right? So and how do you make sure that your agent has this idea? Okay, this is ambiguous. Actually don't know what to do. So I need to go back and forth with a person, so, actually understand what the problem is and then once you arrive,
 To understand what, what person is a person actually means, what is the fastest growing company from our portfolio based on the revenue in the past year, this is very easy to give to llm to say, okay, please translate this into SQL, for example, gets this information and then I gonna combine it and present it in the report. So, for this type of task, comprehension is extremely alone, and difficult, and complex, and sometimes almost impossible. And execution is somewhat simpler. You can also look at a simpler tasks. Let's say use you give your tool a document and say, you know, extract all information and tell me a couple of insights about a b, and c. In this case, the comprehension of a task is very trivial. Yeah, they execution still not.
 As complex as in the previous example, but bigger than comprehension. So the distribution is different and this is the first thing that we did. And I think react was the first kind of a conceptual approach that was. So from most companies implements in, when we start talking about agent and then we start having more discussion, okay? But
 What else is there?
 So, what I like to add is, observe think.
 Act.
 And then reflect, and it's more or less taking this initial things. So comprehension reasoning and splitting it into two parts. One is Observe, and this is understanding user and Circumstance.
 Let me give you an example with a small.
 Demonstration, where we were, we created an agent. We that can order food for you.
 So you see it in the office, you basically click a button and say hey I'm an officer, I'm late. I want my usual and this is it and 2014 minutes later there is a career the door. And basically you've got your usual stuff. So
 Significant part of initial agent work is actually just looking at understanding users circumstance. So saying, hey, this is the materials he is in process of office, it's late. So it's immediately shrinks
 A space.
 Where solution can be found, right? And then you come and say usual and basically just solve it, right? So it knows what to do it. Hands it over to execution part and then basically, after it's easy. So hopefully it illustrates a bit, The observed part. Yeah.
 reflect part is something that is,
 Not usually implemented but at the moment you see it in very specific scenarios. The best example to give is if you've got a code in agent,
 Because coordination, you've got an assignment, you, it's executed writes a code, and then you reflect on the code laser is by trying, to execute it or try and Sue, write and execute unit test, or whatever it sees a result of execution. It says, okay, I'm not doing well on one or two or three metrics, so I need to repeat the loop.
 Uh and this would be a part which is difficult to do without reflect because then you more likely to create Solutions with errors and all suboptimal solutions. So the observed part is really this filter of do. I have enough information is the ask clear enough if it can pass through that filter then you can reflect and say can we set something up?
 so that if I do not have some piece of information, I go back and I ask that,
 and,
 So it's almost like you're getting through the observe part. There's one filter. The reflect part is almost like another filter on top of it. If you Flex is at the end, once you execute something like what did that happened? During this observed Parts starts at the beginning. So when I understand what's the circumstance, where in, and then think part is the understand what needs to be done and how it shall be done.
 And think part is often connected to discussion about ways of we've got static planning, we can touch upon it later. And so on,
 one of the things that,
 I think people find confusion.
 We always I think prefer to have this clear borders between things. Yeah, so we say reason act, observe plan, act observe think.
 It hardly ever happened like this. Not so because quite often, when you think about what you need to do, or you think about context of requests, you actually also need to do something. Allow me to again Illustrated with examples that I mentioned before data analysts
 So what helps if there is an ambiguity in the request that analysts can go read some documentation about company, maybe go to database and look what data is available so it doesn't come back to you with this range of random questions. Yeah trying to decrease ambiguity. It basically come back to you with more precise. Okay? But do you mean this or this like this is defined like this and so on and then it drives your kind of communication with agents. So it creates this Loops. Yeah. And sometimes can be very small other times, they can be much bigger but the key is that you have very Loops happening. Yeah. Throughout your agent Journey? Yeah, absolutely. What I put there as a cycle is not prescriptive in the sense you always have to do it. So there are some use cases where you say, okay,
 Like reflecting is not critical so it will not break some other cases you say without reflect you actually never get to this top performance in some cases you say you know observe it's more about personalized and whatever. Like if if you've got a very simple tasks like gives this recording transcribe and translate it. Yeah. How much context do you need to understand? Probably 0. You just need to think. Okay. So I need to actually call transcription tool. I need to call translation tool if it's separate from a lemon, and then I need to basically call something else and I'm done, right? So observe and reflect kind of this additional thing that depends on circumstance could be make or break stuff. But the core element is still that as the agent will figure it out or you are trying to
 understand the use case. And then at the moment, I think that based again on our experience, it's still a bit with the developer.
 So people who build agents they say, okay this is what we need. But of course, the more sophisticated you've got agents, the more you need this
 Freedom, indeed. Now, there's another design principle that you have, which is extracting all capabilities as tools. And I like this, because it's not just,
 Other systems or other tools that you can use, like, a Gmail tool Etc. But even humans can be a tool that you use. If I'm understanding it correctly,
 I think that you are.
 More.
 Adventurous little does this ways and me I did not think about human just tools to be honest. I will think in the ball as a agents us tools this was a bit of limit of my risk taken but now you absolutely right. So I think that basically, if you look at age and what we again discussed at the beginning, it's a
 Important that agent has all the various tools available because it will need flexibility to decide how to execute the task. And I think that in the simplest way, everything that it can call everything that can use Waze a mechanical or human, it's a different story. Could be and should be abstracted away as a tool with some simple interface for input output. We recently had some ideas from various companies of how it may look like. But essentially if I call a specific tool it's called via API. If I call another agent, by the way, it could be also done as a cool tool if I asked human for help in a way, you can obstruct it in the search way that it's basically looks like just a call and a tool and then you've got a lot of freedom, I think.
 yeah, I was thinking human's just because it's it's almost like if you think about human in the loop in a way, that is kind of a tool because you're getting
 The okay approval, which can be a tool. I absolutely agree with you. So I I see both sides of argument. So you basically saying look, sometimes when we give a request to agent we already in the way provide ourselves as a tool. Yeah. And I can relate very simple example. Sometimes I'm using one of these agents to help me to create the documentation and what I put in instruction for my request and saying, if you need more information ask me. So this is explicitly saying, okay, use this interface. So send the question to me and I respond to you. And in the way from agent perspectives, there is no difference sending me texts and getting texts from me or sending it. So some API text and get in it from there in the same way. If you think maybe another similar example, so you use opper
 Say look, you give it an assignment, it will execute, but if it gets stuck it will ask you exactly and it could be in the specified point. For example, when you need to provide the payment or it could be in the point where it says, you know what, I don't know what to do. So it's like a resolution. And in this case again, absolutely agree with you. It uses you as a tool
 That's it. So the greater theme Here is, how can you think about abstracting as much as possible? A way to make everything a tool call? Yeah, tell me about the sandbox idea.
 For the Colts.
 Yeah, so I think it's also very important. So, what we saw over and over again, and again, it's not only us. You can see the same idea when you are using other products like entropic or open AI.
 Is that you've got tools, but sometimes you've got tasks that cannot be executed by single two specific tool. And this is where you want to have a flexibility to just write a code.
 And you see it's happening. You basically have a quote executor with a limited capabilities to actually write the code if you want to create a graphs. If you want to run data analysis, if you want to ingest data, I don't know many different options and I think that this is critical, because it addresses this Gap in. Okay, is there are so many small tasks that you cannot foresee.
 First of all and build it into Standalone tool. And second of all, you actually don't want to overload. Your agent with a list of 1,000, let's say tools it can select from it's much better to say. Okay, you've got this core tools that you often need and then whatever.
 Other.
 What 5% of scenarios you can cover with doing a code? You build it yourself the code. Yes, you build it yourself and this brings up. This question of when is enough and enough, I think we mentioned how
 Right now, there's a very popular thing of long-running agents and the more time that you give it to think and to act the better the outcome. And you had said, there's a scenario where someone gives son an agent, a lot of time to try and execute a task. And it realizes, there was a library that it needed or it needed. Something merged PR requests merged in a library. So the agent went and sent an email. Well, look, this is an adult. I eat popped up in my ex I think. So, let's take it as an adult. But I absolutely believe it when I read it because this is also something that was. So in some instances in our work, if you give a task to an age and and you do not limit execution and dynamic execution. Pause! This is by the way, probably where we need to talk about static plan versus the number one. Yeah.
 It's a good. Yeah, yeah, bring that in. Yeah. So
 A one of the things that people work on a lot is when you have a task and it's as a task is given to an agent, the agent has or think about the task and then as around multiple options on how to go about it one is you create a plan, execution, plan, in the case. So this is my data, I'm going to call this tool. I gonna take result of this, call that tools, that tool that tool, and then I come to an end, this is a more or less referred as a static execution plan.
 It's actually very nice for simple. Predictable tasks. Again going back to one of my previous examples, let's say transcribe in and summarize in the meeting. Well, it's very clear. What needs to be done? There is no surprise between function calls about outcome. So you can do static Planet, it's really good in the sense, it increases chances of convergence, so the agent will reach some result.
 But of course, for longer tasks. There is increased risk of running into error, in one of the intermediate steps and that cannot correct because the plan is fixed.
 Now, the alternative to it is the dynamic Planet. So you basically say okay, I understand what I want to do. I know my first step, I gonna call it and then I'm going to absorb result, and I gonna call it again, something again and so on and so forth. Dynamic planning is great. In a sense that it decreases probability of getting stuck on a particular error.
 But it increases probability of Agents. Never conversion. So it can constantly go and go and go. And this is something that what I say, how do you
 Explain to agents this very human concept that better is the worst enemy of good, right? So, because it
 In theory, it can go forever.
 Trying to improve on your tasks and trying to get better and better results. So now go back to the anecdote that you mentioned. Let's say you've got agent that wants to write a code and it can write a code, it can test it can see if it works or not and then improve and so on and so on and this agent has access to Internet.
 So it's not a big lip to understand that at one point. It's a, you know what, I can actually Google stuff and we see already. Now, if you use, I know all three. For example, it does web search. If a translucent to an error, it cannot resolve from its brain, right? And it does web search and then if you give it also permission to, I don't know, write an email. It can contact. People asking for help like package developers, if if it can go on web Beyond web search. So with tools, like operator and so on it can go on Reddit on forums it actually, post questions, it can. So, again, back to what you mentioned earlier, it starts seeing internet and human as tools to achieve a goal. And if you do not create any bounce on what your next step could be, then anything can happen. And again, it won't be stretched to imagine if you
 Give it credit card. It will hire somebody to do a job for it. Yeah go on Fiverr and say can you do this for me? Which is
 Fairly interesting piece to look at. Because if you,
 Would like the best result possible. Potentially, you're okay with that, and all of these outcomes, but now, like you're saying is, there's that fine line of how much better can we get it? If we let it go and we let it hire someone on Fiverr and we let it post on Reddit, all of that type of thing when it gets stuck or maybe it's just that it needs to incorporate you, the human in sooner and say I'm stuck here. Do you have any plans for how I can make this better? So in that design principle thinking about when to incorporate the human in, or how to say enough is enough, is something that I think is still is that an open question in your mind or have you figured out a way to do that? No, I I think it's pretty much open question. I think that when to stop is an open question, I think that if
 You just leave it to the model. You observe to behaviors. Typically one is its overconfident. It's achieved the goal generally. If you look at the lamps nowadays, even on a step of reasoning comprehension, it's very difficult to get more to acknowledge. It doesn't know something, right? So you ask okay, do you have enough information? More likely than know it will say, yes. Even though it's obvious like it's not enough information and the same way if you ask a model, okay? You executed do you think you did well and get to good result? It's more like it's to say yes.
 An opposite side is and again, it depends on what kind of instructions and guardrails. You put in place, it will say no and just continue. So it's very difficult to strike the strike, a balance between this overconfidence and constant doubt and I think it's still an open question. Well, it's funny because that was one of your
 pillars of what an agent is is knowing when to stop.
 Now, talk to me about the memory piece. We talked with Paul for a minute, in the beginning, part of this episode on memory and how you have these two different types of memory paths,
 You also had mentioned this before? There's
 the memory of being able to complete a task in a way that
 It can do that reliably each time and Paul was saying, well this is where for us. The evals are so important because if you can say what the
 Path that got it to success is then you can update that information in the models like abilities or toolkit in various ways. Maybe it's through cashing or maybe it is just updating it in the rag system or is going as far as finding
 so,
 For you. How do you look at memory in the space of design principles for building agents?
 So, when I look at memory, I think about a couple of things. First one you've got
 A short term memory.
 I borrowed the term from somebody that I like, it's called scratch path. Memory.
 And it's, it's a memory is at you use within the task. So basically you start with a blankley East and us, you execute the task as you called different tools. You interface was a user. You basically write down what happens, right? So they showed her memory from the task. If it's a conversation, that's a conversation memory and so on, and then you've got to learn term memory.
 And learn to memory is basically what happened overall across many interactions across different sessions, across different tasks. And for me, this memory, I also looked at from two different angles. The first angle is more or less personalization.
 So you've got an agent and it executes tasks on your behalf and it learns something about you remember, going back to observe like understand user and Circumstance. So to we're talking about getting intelligence about user. So next time you ask my favorite, it actually knows what your favorite, it knows your communication style, it knows a lot about you. So quickly preferences, its preferences, a bit people sometimes, call it like profiles, memories, whatever, but it's learning about you that need to persist, and need to be used later during execution tasks. Now, the second type of memory is okay. I did this task
 What did go well?
 What I need to do better and this is not related to you. It's related to the way that agent executed, the tasks, allow me to illustrate. So again, going back to something like creating the report based on some business data, an agent looks at conversation, says, you know what, I spend a lot of time trying to search for city which didn't exist because I didn't know that there are Unicode or that the city name could be encoded in the data storage differently. So next time when there is a task like that I first need to understand what the spelling is if it's correct or not what encoding is. And then I need to verify that the city is known before I start you know pulling all the information on Source looking for something which is not there.
 So almost like the agent is doing a retro on its own. Exactly, exactly exactly, exactly. And this is also part of reflect. So when I was talking about
 Our cycle. I was given example with code executes called code writing and then reflect was really within the loop.
 But you can also have reflect a bit outside of the loop of you will or at the end of overall execution, just looking at everything that happens so far. Saying okay this are my learnings and I think that this is very important part. You remember at the beginning, I said, what agents
 Are. And one of the elements is memory and memory of in a way of learning.
 And this is a part. How are you to learn Korean corporating? That learning into the next time that the agent does that how do you have this retro? The Retro where the agent. Now understands I could have done it better and these ways
 What are you doing to update its understanding so that it does to do that. So essentially what you do is you put this information into context. So you essentially change instruction, so your agent
 But you've got the place saying okay if you, so you've got this task and by the way and this is also where Rock comes into play. So you need to you eventually, you will not be able to put all memory in ways, it's personalization memory, or execution memory, or whatever. You need to find elements pertaining to user, and to task at hand, which are relevant. And you pull them from long-term memory, and you put it in a context. And you say, okay, this is what you need to take into account because basically you're saying, hey, by the way, the last time you did this, you said that you should have done these things. Make sure to remember to do that. Yes, essentially not, not the exactly like that more prescription like a good practice. In this case to do this, and this a verified for this and this, but yes.
 okay, fascinating, and you also,
 Goes through the memory.
 So it's not necessarily part of agent execution, it could be part of environment. It could be something outside where you say, okay? So you've got this Learners Learners learning, but you need sometimes to compress them to generalize them because you cannot have like 100,000 execution. And then you've got 100,000 learning, 90% of them are the same, right? So you just need to be able to generalize and compress. Yeah. And so then it's like this reflect part plays into another one of these ideas, tell me how it's different from the internal critic is that the same thing or are they separate?
 It could, it could be again. So I was trying not to separate internal external reflect in a way. So
 if you think about agent writes and cold,
 Reflect is in fact, internal critic. So it looks at the execution, it says, okay? As this is what this is what the Test shows within the well,
 Right. It could be also look at something in other scenario. Look at documentary. And then say you know what the instruction of user was to summarize his document but convey this emotion. Did we do it or not?
 And it says, now this emotion is not really properly, conveyed. So we need to do another step.
 So this is in fact, internal critic, but you can call it also. Reflect reflect step. Yeah, but it's reflect within execution and then you've got another example, which is reflect at the end of execution or outside and you can mix it obviously. Yeah, there's a diagram somewhere in there that maybe we'll have to create where it shows these Loops that you're going through, especially with the
 Way that you're thinking about it with, you know, the observe and then the thing and the other one was act and then reflect and maybe reflect is at the beginning. Maybe it's at the end, maybe it is at the beginning and the end and it's continuously reflecting after each step. It does sound like that can get expensive or it does it does. And and this is why. So, in principle this reflected, the end
 You can, you don't need to do it at the end, you can do it on every step as well. It just extremely expensive, right? So many solutions that I've seen so far and many solutions that we've built. I actually doing it at the end and it's simply because it's Arts. Delays it at Cost but yeah the more you can reflect the better one. You just need to make sure that eventually you converge and not reflect reflect reflect. And again better it's worth of enemy of good.
 One thing that I wanted to say just based on your question because you refer to what Paul says learning from previous execution. So one of the things that you can do with the memory is actually optimize your execution path. So not only go for trivial things like the one I mentioned where you say, okay to avoid this mistake. Like this is a good sequence of Step of whatever, but to actually optimized execution path, altogether, an example of this could be you spoke to florist, right? So he at one point was working on an agent that uses web to browse websites. Yeah, and essentially, the ways that we implemented, it is, if you go to task you exec is to go website and start basically browsing it so finding out. What is clickable, what's the field?
 Or that you can feel information and so on. And then you basically set. Okay, so I need to click on the menu. I need to look for restaurant, for example, in foot ordering case, and then I need to click here to add to baskets and I need to create. So all the steps
 But, of course, once it's done and it's successful, it looks at the whole execution and says, you know what, I actually don't need to wait and at this step, I don't need to wait until the whole webpage is loaded. I can just put it triggers, say, in a k, once this element loaded, I can activate it.
 And then I can do it next next next and suddenly instead of spending two minutes browse and you can do it in under 40 seconds.
 Are not wasting resources or website, also not waiting resources of yours. So we moved from slow execution to fast execution. And then another thing that happened, it looks at this slow execution. Say, you know what, actually if we do this sequence of steps, we can predict what where we end up on this website because actually website is a limited amount of pages of use essentially, and this place where we end up has a specifically formed URL that I can form already at the beginning. No one where I need to go. And this is what we call reflex. So, next time, I've got the task, when again, I'm going to say order me usual. It says, okay, I just go there.
 And in parallel, I'm also trying to do this fast and in parallel I'm also trying to do the slow if I go good with reflex execution.
 I'm good if not I fall back to the fast. If files fail I fall back on a slow. So slow. An example of this would be website changed.
 Element changed, right? But this is also an example where reflect is very important. It's not critical in a sense that your application will not work without reflect, but it's very important in terms of optimization of performance.
 And this is why again, memory within relation to execution is important.
 Yeah, there's so many things that I want to comment on there as special because if you think about the
 way, that, that happens if it gets done with reflex, then
 You how do you call off the rest of the actions? Like how do you call off slow and fast or
 It's to be on us to this, is this depends on the application and just implementation all details. So the concept itself is actually not new.
 I saw it many years ago I believe Siri was working on Apple this way. When you remember the Oliver version of Siri you would say like call Mom and it would call Mom. So what happened to now? It doesn't do that for some reason, it's been five years and it got worse, change arrows, don't
 Up. But essentially if I understand what happened is, it would take your voice and would start processing it. Locally on the phone and at the same time, it would send it to the server where you've got much more powerful processing. And then if the phone says Okay, a processed actually understand what needs to be done. It just communicates back to the servers and okay, I don't need your support a stop. Yeah. And it's a bit of waste of resources but it's significant optimization and terms of how quickly you can get result and the accuracy of that. Yeah. Now
 speaking of wasting resources or budgeting, I wanted to touch on the idea of
 How you think about budgeting every action, and I'll bring this up, because I spoke with Zach probably three, four months ago and he was putting together different agents and an agent builder at his company. And when folks build agents at his company in staging, they then have this little number that says, if you are to push this to prod, we estimate it. Costing this much money because of the scale and the amount of llm calls that we're going to be making and the resources needed.
 you were looking at budgeting in a different way with long-running tasks and being able to say, if you exceed a two dollar budget then just stop because I don't want this all of a sudden to get
 Racked up to a 10,000 dollar open, AI bill. Yeah.
 Yes, so I think budgets in is extremely complex. Questions to be on this.
 because,
 one thing is to say, you know what, we just want to keep limit the cost of execution,
 And I think it's a, it's not particularly difficult. You can estimate cost of execution. Again, as you just said, based on number for lamb calls or maybe some other things that it does, we actually did it again, going back to one of the things with the food ordering agent, we actually can very precisely say, okay, so it did this food ordering, it looks for options. It reached out restaurant, it looks way, it's easier to deliver order it via platform or Via Restaurant directly, and it's selected the best option cost twice. And this is orders that was made for this amount. And from there, we can also say, okay, but it runs so many calls we know on average what infrastructure cost. So we say it's actually safe to user like a dollars and it costs 1.5 to run.
 So, and you can put a very easy caps. And you know what, on average, we are bringing this value for user. So, if you exceed in this value, please stop. It's it's business discussion. It's not technical discussion. This is one thing where budgeting becomes extremely difficult in my opinion, is when it becomes a part of trade-off discussion. And unfortunately, this is where I do not see a lot of interesting solution and please tell me if I just miss it. So,
 It really remember agents have tools.
 And if you look at most of the cases now on the market, this tools are not overlapping.
 so, you cannot replace one tool with another
 What happened? If you can?
 Very simple example, you can have three image Generations.
 each takes different execution time, each slightly different from the quality of the delivery results, and each cost very different
 Did you actually see a good solution that is able to navigate this trade-off?
 What is a task at hand?
 Which tool is the best option in terms of speeds of answering quality of answering the cost. So this is where I think budgeting will be extremely important moving forward because we build again, we build agents with more and more tools.
 And internally already seek a couple of use cases where we've got like two tools, doing more or less the same. So how do you let to choose?
 How do you communicate? What is important? What if the importance changes over execution of your tasks at one point? You know, again, go into human example. How do you explain to the agent to an agent? Sorry.
 The concept that it's better to have an answer now.
 Then a good answer later tomorrow or next week. Exactly. So this is where I think in will be important and this is yeah where I still see a lot of opportunities for development almost like you want and urgency in knob that you can die. And you can say I'm cool with this one going as long as you want or I need this as soon as possible or
 Somewhere in between. Yeah, so if it cost me less, it takes me a week and it's not critical tasks fine. If I need an answer now,
 How urgent is mine? Now you see how it's very difficult. Also, if you think about human, you work in the team.
 How easy it is to convey. And also understand the sense of urgency
 And people say, oh I pay whatever if it's done but then what whatever is oh whatever. It's if it's done and then you realize well it's actually not what whatever and it's not really done. Yeah and whatever is different for different people and definition of done. Exactly. It also reminds me of the paper that I read back in the day called Frugal ML. And there were a few different ways that they were exploring how to bring down the llm cost and some of that was by throwing in two questions into contacts, when no to similar questions and getting the output. And then another one was
 being able to have a dynamic router. And so if the question was simple, it would go to a simple open source model that was a smaller one hosted self hosted. If the question was more complex, it would kick it off to pack those days. It wasn't a reasoning model but something of the sort, the bigger model now,
 what you're saying though is imagine if tools had that same kind of router or it just was
 A capability that an agent, could understand. These are my options and considering I need x amount of emergency versus y amount of budget. I'm going to choose this tool. Yeah, exactly. It's exactly that. And I'm really eager to see a solution there at actually address it. But
 yeah, I still in the face when we've got just a handful of tools and again you don't really have this options where you can trade one characteristics for not
 That's all we've got for today but the good news is there are 10 other episodes in this series that I'm doing with process deep diving into how they are approaching building AI products. You can check it out in the show notes. I leave a link.