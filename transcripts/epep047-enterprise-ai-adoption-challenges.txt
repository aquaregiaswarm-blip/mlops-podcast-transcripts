So let me start with the metrics on the productivity side. You want to make sure that you keep your power users. These are the guys who are going to really push you to the next level users right now. Scream of oh, we want Google drive. What does that mean? They're like, I don't know, but I want to we're now in the loop of. Can we get this to work at all? Can we make it something that users can easily set up? And can we make it so intuitive that? It's going to be a no-brainer.
 We talk with Sean and Paul both employees at process. Paul is the VP of AI and Sean is the product lead for token. I myself and Dmitri's. The host of the mlops community podcast that you're listening to right now. Let's get into this conversation.
 This episode, I wanted to view from a product lens and token has been built. And it's had a lot of iterations. It's also had a lot of learning specifically around how to get users to use AI products. Yes. So, you know, just to kind of
 Sketch the environment, you know, the group that we work at roses, right? So it's a big Global Group with, you know, about 100 companies part of it, some very large like OLX, and swiggy and knife food, and delivery hero, and others and some smaller. But you know, at the center here at the AI team that we have built here in Amsterdam, our mission is to help the entire group, adopt AI, everywhere it makes sense.
 And so when in the early days of these large language models, you know, we were partnering with you know many of the big Labs out there you know before chat gbt and so on to kind of understand whether this was going and it was very evident at least to us that this this was sort of this technology was on a acceleration path. And so in the early days we basically started to make these language models available through slack for people to kind of experiment with them and eventually that grew out to be token. And that's now today, it's a basically a productivity tool and even starting to become sort of a platform for folks to build on top of all the language models that we continuously expose through token, not just in slack but also you know on a web interface if people want to chat to it and so on. And now we'll sew through apis to build on top of all of these large language models generative models for images and other agentic systems that are sort of powering token and many of the use cases across the group. What are some product metric.
 Because you've put around the usage of token. Yeah, they're basically two buckets. So the first is around productivity and Adoption of gin AI across the workforce. So we believe that it's really important for everybody to, you know, play with actually for them to understand how these models work what they can and can do. And the only way to do that is we found is for people to try it, right? Because the technology changes so fast, you can't just design a course and put it on, you know, our internal learning portal and say, learn prompting. It's gonna be done, right? These models should use because that course has a, you know, a half-life of three weeks. So that's the first bucket as a bunch of metrics which I can highlight there. And the second is around adoption for actual consumer face in or internal use cases across the group. So we're very large group two billion users that we serve different parts of the world. There's a ton, you know, we've got thousands of ml models and use cases that could be powered by some of the same systems that we're building for token that are
 Agent. They use alleges the latest language models, the tooling so on
 So let me start with the metrics on the productivity side. There, we primarily focused on number of users, that tried token. So, how many people have actually tried token? We trying to get to basically more than 80% per company. Well, people that have tried it because there's a big hurdle. Just try asking token. A question related to your work. You know, how do I summarize this? How do I translate that? So people start to do that. The second is actual frequency of usage and so there's a really interesting, let's say Evolution. We've seen happening is how people go from asking it, you know, casually once a week once a month a question to becoming super users and I can share some stats around making sure that you know, we see growth of super users who is the category that asks is more than five questions a day. And and then the third is a total number of questions asked across the
 Group. So those are the kind of three metrics we focused on for, for a long time. And then on the second bucket, which is more on the adoption of
 Use cases for not productivity but everything else. Right? So where you put things as part you put the token engine as part of your workflows through an API and then we measured API calls and also number of individual use cases that were seeing you know using the technology underneath that kind of engine as we call it.
 It seems like this five questions a day is like your North Star metric because if you can get someone above that then they are now a power user. And you want as many people to become a power user as possible, is it like that? Like it reminds me of I heard a stat back in the day with Facebook. They would try and get someone who's onboarded to Facebook at least seven friends. And once they had seven friends, they were hooked. Yeah.
 I definitely think that that there is that sort of turning point where now you've become a regular user of these tools, right? And by the way, just to be clear like we encourage people to use all the tools so kind of the in-house one, which uses, we know we swap in and out models all the time and so people can experiment with them and we learn how which which ones work better and not. But we also encouraged them to use all the other tools, right? In fact, if you look at my browser I've got you know basically One browser with all my AI assistance open, right? That includes Claude and includes Chachi includes rock with a K inclusive, of course. Okay. It includes Gemini and now I've got Devon and a few others that I'm testing with and you do see. And so the five questions a day and for token, it was in a scientific as maybe the seven friends on Facebook, but, you know, once you become a daily user, so your first intuition is hey, should I ask this question to token?
 That is the kind of thing you want to achieve. And then it doesn't matter if it's still can or cursor. Or we want people to become a sort of natural users of this tools and help them do their work better faster and more independently.
 How are you?
 Measuring that because I'm sure there's a lot of stuff that people are using that are outside of token but they're still using it.
 And you can't really track it or can you yeah we can. I mean that's for all teams. So obviously for for our team we track all sorts of things, like how many PRS are being, you know, generated with the help of AI, how many PR's are accepted or commented or involved some kind of AI right. And the first days as well, you know how many people are actually using cursor or using a certain set of tools. How many copilot users do? We have actively. So there are things. We in my team that our team that we can definitely track and, and do track across the group. We don't have that visibility everywhere. And but we do, we've done sort of experiments where we give part of a team access to one of these tools that say, in the early days of co-pilot we had done that and then the other team not. And then we do surveys and see how often they do. They use it, what's the difference, what is the feedback? And just for us to understand? Because, you know, there's a lot of independent research they also gets done. It says, you know,
 Engineers given average productivity increases 20%, but that once you peel
 that the layers a little bit further. Like, which types of engineers for what types of tasks is that 20% overall, or is it just on those tasks? You know, used, it's it's much harder to really pin down what the value is, and we're pretty convinced that the value is real. And that it's in the double digits, we care less about whether it's 21, or 23 or 41 or 42, or, for whatever we just want to make sure we, we make it easy for people to adopt if they want to. And then also have a good understanding of where we want to encourage people to adopt certain tools which types of, you know, we've got big engineering teams, right. Thousands of people across the group that are building software, we've got big marketing and sales teams. We've got, you know, basically Pockets customer support and so on that where it's natural for us to kind of make sure that those people can do their work better faster more independently and we want to understand and that's why we measure these things and once we see that the value is real, we start to sort of encourage and push for
 Option more actively is that what you talk about when you say like the AI Workforce. Yeah. So AI Workforce indeed as as a big productivity element to it. So how do we make sure people become more productive? But like I said, it's really hard to kind of quantify. This second value of people using AI, but it's so important in a tech company like ours is they need to have that intuition, right? So if you, you know, if the lawyer is in the folks in finance and HR and marketing, all the different functions don't understand AI. Well, it's much harder to do all those other you know, Forward Thinking products and features. And and actually trying to think about how do we want to build
 You know, a better delivery experience. A better online shopping experience, online travel booking experience. So the intuition having that is, it's almost like a culture change, right? You need to have that on top of the productivity benefits which are, you know, an obvious value as well. All right, so let's bring on Sean now to talk about how he's been encouraging adoption for Tucan because he's been the product lead. And I know he thinks a lot about these trade-offs and what to build for the power users versus what to build for the general public or the general employee.
 I'm Sean. I'm the product leader tokan at process as part of the prosci team and I take my coffee and overdose and I we actually got a barista in the office and I started to only take machine coffee because I find that it takes the joy and the magic out of the weekend coffee. Oh, I like it.
 What were you saying about the stigma? I think when Danny, I started or when it started coming out and you used it in order to complete a task, he was trying to hide it and because it always felt like the cheap way out. That's so true and I think that's still there and and anywhere. Right? I mean, it's oh, this is a Devon pull. Request is not my pull request or this is a, this is something that I've ridden with token, and you always feel like this looks like AI generated, which can be perfectly fine content, wise, but there's there's a little bit of not even from the other side, but at least on the back of my mind and many tasks like, ooh, and you're like, no, no. This is what we build it for. It should do this. But yeah, it's one of those things that I contemplated Bunch on the doorman Paradox. As I've heard it called where a hotel got rid of all, it's dormant and then
 It thought. Wow, we're saving money. This is great.
 But later, it found out that people started loitering in the front. Also, the guests weren't having the best experience. Because the first thing that they were hit with, when they entered the building was, they were lost. And they realized that a doorman does so many different things than just opening a door for someone. You mean that in terms of customer touch points or in general. Well, I, I think about it with AI where we are so quick to try and use it, but we don't think about the secondary and third order effects of when we're using it. And one of them is this in my mind, I draw a parallel to
 Oh people look at it and they think this is AI generated and maybe you lose trust with someone or it's not the same.
 Kind of outcome that you would want. Yeah, especially when you see so many people toting. Ah man.
 I got my content marketing flow, perfect. Because now ai, does it all? And it's this incredible pipeline blah blah blah. But then you look at the content that comes out and you go, this is absolutely shit. You're just ruining your brand by putting this out there, it might be great that you can automate it all but nobody's reading what you're actually creating. Yeah. And I think it's very much a question of when and intent wise how you want to use it.
 I think deep research isn't is an interesting example and if researchers one of the steps in the job that you're trying to complete and you use deep research for that, it might get much harder to complete the steps down the line because you don't actually know all the considerations that have gone in. And
 I think for many tasks, its
 Or many users actually, it's how you use it and many users generate something without reading it and then do something with like that's not how you're supposed to use it. It's not there to just generate blindly something. And so, one of the things that we've been trying to teach uses to really use it like a buddy, like hey, if I were to go do something, how would you advise me? Go about that, right? And so more on a discussion level, of course, you can have the execution afterwards, but you should be very confident that at least it's going to write Direction. And then you can look at okay. Quality wise, of course you still need to read it. You need to make sure that what is there is actually useful. Let's talk about the evolution of token because now you're starting to see these clearly trotted pads of how people are using it. Like you just said use it as a body or use it for data analysts, use it for x.
 It wasn't always like that and I think you all started working on it, two years ago, it has been a long journey.
 What can you tell me about? Like, just summarize the evolution. Yeah. So let's start with probably the question of why our app exists in the first place. And this, I wasn't part of the team at the time, but the team created a slack app before, I think gpt3 came out, because the team started seeing these models, come out be like, well, they look really interesting but it's still quite hard to find moments where we can use these in business. What can we do? Well, the easiest thing might be to just create an app, where anybody can interact with them and we'll see what people do and from there, we then figure out what we do next. And so we started creating a slack app at the time. This was again far from agent to get like nothing like that was around. So we had some basic intent detection, that routed, I think, four, or five different kinds of work. And then out was spread through the portfolio, companies that we have, at least on the ones who won at the doctor, it was very organic and but a grew a lot faster than we thought it would.
 And at that point, we decided, Well, okay, let's actually turn this into a product and we spent a lot of time on critical tools that are needed in order to complete tasks. Like, they're now pretty common place, but the ability to work with any kind of file, generate files and data analysis, came as so, these things we worked on quite early, still on the intense detection model.
 And then we just kind of tried to bring that more into. Okay, well how do we take this experimental app and make it something that people can actually complete work with and that we then converted into an agent that seemed to quite drastically outperformed. Even at the time, the intent detection. And then from there, we've just what do you mean by the system changed from intent detection to an agent. So we had a system where when a user asked a question, we would route the requests down a almost like a workflow and so we would have to figure out what intent they use ahead and we were quite limited and then out of the tents we could add and we would if we wanted to add a new intent, do some new fine tuning and training of a model to do the routing. And so of course with an agent you just add quote unquote just but you add tools and it's it's easier to manage and expand over time up until I think. Like six months ago you all had you all just started doing a ton of updates. Can you talk to me about the last six months and what you've been doing? So,
 So right now, I'm the product lead for token but when I started, I actually joined kind of as an adoption advisor. So my role was to help the companies help teams and companies and the employees there to actually use the product. So we, we found out quite early. That there is a set of companies in the portfolio, who were adopting this tooling a lot faster than other. So we knew that there was potential and room there and the idea why that is. Yeah. So this comes down to to quite a while or not that much but the new ones are difficult to figure out, but much of it was almost top-down culture like it's a okay, let's give this a try, let's see where it goes. It's very much, a mindset difference of and being stubborn enough to make it work, wanting it to work and being excited by all the opportunities that come from it. And so it's very much at least on a larger scale adoption level. It's very much, a cultural thing of how does your company view this? Kind of technology? And a lot of it is driven by leadership and the way it's encouraged because it's very
 Easy to say, oh yeah, AI is important, but then there's no, there's no policy, there's no guidelines, there's no instructions around that and that makes users not feel very encouraged. They're just more uncertain and so building certainty around. Hey, we don't just want to, but we expect you to spend time on these tools and in the beginning, it's going to cost time and that's fine but it's your responsibility to learn. And here's the resources that you have in order to learn it. But at the end it's on you in order to figure this out and you should be interested in this. Not just because it's good for us as a company but also because it's good for you. It's a skill that will only become more and more important. And so the student we start the better. This is going to get the cultural aspect, I like that. And there's a there's a certain set of flexibility and nimbleness in there because and it also is part of the culture but it's not just the adoption and go and try it, but this inevitably changes how you work? And that's something everybody says. But but in reality, oftentimes especially, these kind of new technologies conflict, quite heavily would existing process
 You do something in a certain way. And it's not always easy to just plug in plug out, but you might have to rethink everything that you're doing, which some teams and some people are more comfortable with than others. And generally speaking, the ones who are more willing to experiment to just say hey does this actually work? Does it help and then our quick to say yes or no and they're the ones who benefit from this a lot. And then the secondary effect is if you have a subset of those teams available, then you, then you want to look at sharing. And so that's the second part where it's quite painful for individuals to do a lot of this discovery, because it is, lots of it is still quite Technical and it's very difficult and most of it isn't particularly use a friendly actually. Agents are kind of the opposite of user friendly and at least in their earliest iterations. And so building a community of sharing is a super important because that means that if one user discovers something. Now, the next 10 don't have to make the same mistakes and
 the difficulty goes back to stigma is
 Asking questions asking for help on things like this, where you feel like everybody is 10 miles ahead feels so stupid. But oftentimes everybody's struggling with exactly the same thing. Right? And so yeah, you see these posts, I've done all my marketing Etc. But how does it really work, right. How can I do it for my work and to having a kind of an open culture to share and learn together? I've heard people tell me that, that are in this field. They say, I don't know if I should be learning rag, or agents or tool calling. I feel so behind. And in my day-to-day, I'm working on a recommender system, but I am not sure if I can plug in AI, in some way. And so that fomo is really real. The culture is very much in the neighborhood and an accelerant, but I think, and that's a lot of what I spend. My most of my time machine. In the beginning, on this is the actual education part because it's very easy to tell people, oh, go and try and use it, but it's very, very hard for most
 People to do that, right? It's not not it's not obvious. Do you don't even know how to start you?
 Um, I, at some point, I gave a talk on how to build product using a, or how to build AI products for users that actually work and are useful. And one of the things that that come up so often and many companies do this, and part of it is early experimentation but you get a chatbot and there's a chat chat input field and it says this is chatbot X, ask it anything and as a user you're like anything, right? Like so you asked the first thing that comes to mind and usually it's not something that's helpful to you. It's just the first thing that comes to mind and even if it's helpful to you there's no guarantee that the agent or whatever chat board actually is able to do it but you have no other way of figuring out other than throwing things at it. And then it's not going to like you'll it'll fail. And you'll be like, well, ask anything, clearly that's not the case. So I'm just gonna ask nothing because it doesn't work. Yeah, and then you lose a user and that user experience is not ideal. I've been banging, this drum of like chat is not the ideal way to interact with AI and I wish there were easier.
 Ways, I know that you have thought about.
 Building products like you said, you give a talk on it. You also saw
 Some user adoption challenges. And so, on one hand, we've talked at length on, how can you build
 More support for people who are trying this so that they can have that stubbornness to break through and realize the value of it. Can you talk to me a bit about some of the things that you did to try and help folks? Yep. Get through that filter. Yeah. So
 I think, in terms of interface, we've done a few things, like follow-up questions. I think lots of it is kind of experiments around chat interactions. The fact of the matter is that the chat is to kind of predominant also in the way people think about it and so changing it. Now, again, it's going to make it even harder for many people to understand it. Because many are just getting to the chat part, right? And so now, if we change again, we'll break something else. I think for us, it's been a pretty tight balance between we want to move fast with the product. Everything is happening all the time. We have a small team so we need to be able to build new capabilities, enable our power users. And so we've actually spent a lot of time in hands on support. I think in the beginning, I did a live webinar, every two weeks with users and we did lots of hackathons and workshops and training sessions. We have the benefit that in reality. We have a pretty contained small audience, right? I think we look at about this 3000, ish, amplifies. And
 So I'm not not so small. No no, but I'm not too worried of like oh we will have a potential of I don't know 20 million people out there that we need to educate but it's it's something that's much more feasible to do. So we organize big events like we had a token day and we organized training sessions. We organize cross company team events. So a lot of it has been kind of Hands-On because
 It's a very easy thing to keep talking about and there's parts that we can build in the platform, but what I, what I really wanted to get over is the initial reluctance of fear of using something. And some of these, some of these webinars were just
 I'll give you one that that actually turned out to be really funny, or funny in the sense that it worked because it actually started as an accident, we had a case prepared. And we joined with a company that just got access to turkan, or I thought they did. And so we we joined, we joined this webinar. I think there were about 200 people and it was a Hands-On case, right? So like okay, here's the case. This how it works. We introduced a bit of the product before but like just go try you have an hour, our hypothesis was, nobody takes time to experiment and try. So if we get them to try and dedicated and the first kind of fear response out of the way and now people are much more comfortable to start, okay? But in that session, particularly it turned out that some part of the onboarding had gone wrong and so they didn't have access. And what I then decided to do in the kind of a mild moment of panic of having 200 people sitting in a webinar being like, okay, what are we gonna do? I just did the case live myself and it was both one of the best received webinars as well as
 one of the highest user uptakes afterwards, because
 The way I did it was just kind of walk through. Okay now I'm thinking this this is how I'm going to use it and this is and so just kind of Life interaction almost like an example even if the case isn't super relevant for the user turned out to be incredibly appealing. And so,
 It just going back to the product question. We've done some experimentation on the product and part of why we've enabled our app and the web as well or where we've done a big push for the web is to make it more use usable and user-friendly as well. It's like it can be a bit tricky but a lot of the education has a lot of the early user guidance has come from actual training and guidance and materials. It's almost like you have one aspect which is you're trying to make the technology and the user interface as
 intuitive as possible. But then on the other side, your evangelizing as hard as possible to have folks. Jump on the train and get involved. And I know there's this trade-off between
 Building for the power users versus building for everyone else and making it as intuitive as possible in the lowest common denominator versus adding. All the features that the people that are ahead of the pack want, how have you looked at that? Because it seems like it's going to be hard to have wide adoption.
 If you're constantly chasing and adding features for the people at the front of the pack. Yeah, it's a difficult balance because
 You want to make sure that you keep your power users. They are your most important users in. I mean, in a, in a company political way, in terms of metrics and impact, but it more in a product way because these are the guys who are going to really push you to the next level. And they're the ones who will figure out what could work, how that could look. And they're the ones who really give you good feedback and they will educate all the other users if they're able and willing to share. And so you really want to keep those users around and if you don't build the next thing for them, you risk them going away. So that's that's kind of always been Forefront of mine. And then it's been, what's the minimum product guidelines? And, and usability that we need in order to get other users on board and we've under an overshot? And so, we course, correct as we get use of feedback, and but I think the balance has been mostly, what's the minimum to get users started? While we build the next big thing and the
 Of a building in the next big thing. Usually, as can we make it work at? All right. Is that something that we can make work? Because and now it's somewhat commonplace, but at some point in the past we build a text or SQL agent as a verticalization on the platform. And the first question wasn't, oh, how do we make this useful? How do we make it intuitive? It's still neither of those and that the question at that point in time was, is this feasible at all right? Can we make this work? Okay, then we made it work, but we did it by ourselves building it. So now we're like, well we are not data experts, the power users, the data Engineers to analysts or the end user and commercial that once data, they're the experts and their domain. So now how do we build this platform in a way that they can use it instead of us? Setting up everything. So then that's the next step. And now at some point down the line you would look at well, okay, how do we make this super easy to use and super into it? But the first question was just are we able to get the users to set up and answer any questions by themselves? And so I think that's kind of always the
 Push down like it's always a balance and I think a lot of the reasons why many AI products are not the most intuitive is because it's a it's a very tough challenge to crack and it comes at the cost of other features it's almost like you have to optimize for the early adopters right now.
 Yeah, you do. And
 and in a way, you, you
 Put a lot of requirements on the user. And so there is the balance of, where, where do you do that? And we're not and but it's also in the hope and expectation that the users do spend time on learning the system. Yeah, because one of the challenges I heard was that folks would give up after trying to do something or asking token to do something for it and then it wouldn't do it. The first time they would try again but you don't really know. Am I not able to ask this correctly or is this just not possible? Yeah, yeah. So that's super difficult to navigate as a user and there's a couple of things we've done around that for Music Experience. One is just make the system much more resilient itself. So when we build the first they took analysis, not the date, not the sequel connection but just Daytona or code execution functionality in token and it would fail almost all the time because it couldn't
 The file that you shared or it couldn't handle the formatting, or it will timeout because it installed some absurd library, and you as a user would never know, this is something that you can't easily. I mean, you could theoretically solve in a prompt or you think about how it's maybe because I didn't ask it the right way or like, oh, maybe this is not even enabled, right? I've seen a video of it, but maybe that's something different. Maybe I misunderstood, it's very easy and using the newest version of token, but right? And so it's for, as a user perspective, these things can be hard to interpret. So what we made sure, is that your first touch point is a lot better and so that by itself actually helps a lot and just in terms of how the system responds both on being able to succeed. But also, when it says like, hey, I'm sorry. I couldn't do this, but here's a set of things that I can do. So you're you're first touch point being like instead of ask me anything. It is asked me this because I do that's the second point.
 Then that's more in the onboarding of users being like, okay, well, here's a checklist of things. We want you to try because we know that these are generally valuable as capabilities and so some of these might be really interesting for you, but it gives you a good ground of some successes and that's more onboarding side of. Let's say, here's a list of 10 things, so and I would call, we can go over how we communicate with users in a second as well. But summarize an article, right? And it's like, oh well, it can do that. Okay, that's one win and even if the article isn't relevant, now you as a user have one win, it's not that you asked the first question it fails. You would try again it fails, you're like, well, I give up right? Yes. So it's that but then, but then on the product side, really? Or more on the technical side, making it much more reliable catching. A lot of the edge cases that could go wrong in order to help the user, especially when they're when they're actually starting to own work, not immediately got frustrated.
 Now, as you're looking forward, I know that you have
 thought a lot about what to do next. What's the general consensus on? Like how you're going to continue the progress? Yeah, so right now we are very much a
 And or we're in very much in the AI assistant category at chat interface that allows you to kind of have conversations with AI use tools and complete tasks. What we're looking at over the next five, six months is a step changed to our current Paradigm as a Workforce and so we can talk a bit about what that means. But the fundamental question we've started to ask ourselves and there's hypotheses baked into this. But as a platform in process because we're horizontal solution, how do we allow every employee in process to build AI employees that can complete their work? My fundamental belief or so, there is an observation and these terms are flying around a lot. AI employee especially with current technology. I think it's mostly marketing term, right? It's something that you use to sell it to a stakeholder or something that you used to sell it to your investors. AI employees are such don't exist because we as employees are actually very complex.
 A situations that I think in an Ideal World you wouldn't want to replicate. If I think of hiring and an actual employee then hiring is one of the most impact imperfect workflows there is right because I have a team of seven people. I need to wait until I have work for at least eight before I hire someone. And now I need to find the person with the right skills to do all of that work that's piled up in my ideal world. I just look at that work, as jobs to be done right? And very much in the idealistic product. Thinking of if I hire an analyst, one of his jobs is cleaning data. One of his jobs is to generate weekly reports and there's many, many more things he does but in between, but, but there's some chunks of jobs to be done.
 If we look at it from that perspective and I believe that almost all jobs, you can break down into at least many of those. There's going to be some fillers in between, but just to be done and we actually take a look at jobs to be done and we try to do that categorically, then almost every job to be done, start and ends either with another job to be done employee or in a system. And so, a lot of what we are doing when we're completing our jobs as we create transform or move information around between systems and just to make that more practical. Yeah, we can we can look at something like I might store my user research in Google Drive so I'll jump on a zoom call. There's a call, of course that that one at the moment doing, of course myself.
 Here, from that interview, I get a transcript and a recording and notes. And so those are already kind of piece of information that are stored in a system. If I now wanted to get insights from those notes, I take those notes. I can either manually myself, or currently you do it within some sort of AI system extract some insights, and those insights either directly go on the product, backlog, or they go into another place, and maybe in Confluence somewhere else, and you can break this down for almost every job, right? So,
 Let's take marketing, you have your campaign data somewhere in, let's say Google analytics or somewhere on Google AdWords in any place that manages your paid ads campaigns. You take that campaign data, you analyze it to see what campaigns are doing well. And then from that campaign, or from that analysis, you create again a file in Google Drive, probably slides. Or if you share point could be Michael could be PowerPoint, maybe a look or dashboard, something like that. Yeah. And and you would use that, but I think the important part here is we're moving it into a report that we now give to someone else. Right? And that other person now, looks at the report comes up with a set of recommendations, which could be in an email in another system that we then send back to the person that updates the campaigns in Google ads. Yeah. Okay. And so in all of these processes most of the things we've done is we've stored or moved information around in systems and of course we transform it along the way. And so the way we look at the
 Work right now, or at the kind of AI Workforce paradigmas in an ideal world. Not, probably not the next five, six months, but an Ideal World. We see that companies run drastically different within a Workforce because the core components are they're kind of Three core components. One is the systems that we can use today, like your sales force, your looker, your, your actual, your own code bases, GitHub Etc. And the Agents or are employees that are able to complete tasks in between the systems. And so, when we say are employees, again, it's probably more jobs to be done basis. They might grow and scale, but but these are basically connections between the systems in order to fulfill tasks that need to happen. And then the third part and that's the architect role is
 You'll probably get a subset of extremely talented domain, experts who are able to, instead of doing the work. They think of, how should my marketing department work? What are the different elements that need to be in place? And so they're going to be much more in the process of building these systems, building these employees monitoring them. Making sure that they're up to par and that they're completing the tasks properly, but it becomes much more of a machine that they are kind of Designing and running rather than doing the tasks. So,
 It. So, I have to understand my field deeply, but then, I also have to understand how and where I can plug in.
 The assistance in a way. It reminds me of
 Like, how is this different than zapier? Yeah, so I think zapier is difficult, So that's its, it's a right way of thinking about it because it is
 Connecting systems. And let's just assume zapier is a great tool and it works which we can go down a whole different tangent on how shity that is. But let's not make that the um yes I think you you introduce a couple new elements, zapier Integrations even for technical people or quite difficult because you need to honor on a hyper nuanced level understand every connection part of the system. And so these connections are very fragile. You need to deeply understand them in order to get them right. They're very prone to break if something changes. It's very difficult to build any sort of
 It almost conditional logic, I don't want to say, conditional logic because you can write your own code in between but if it's not straight moving information or always take this number and multiply it by 2, this kind of this cognitive aspect in between that currently employees are doing. That's in borderline impossible to replicate with zapier and I think the way we're looking at the system now is as a platform we need to provide the Architects with the ability to
 Easily implement the connections and in part it's it's easy because if we abstract away connections with tools, then users should just be able to click right email, right. And they don't have to understand all the endpoints that go into email creation. It's just write email as a tool and that agent and update, look at dashboard and some of these are more complex and some are easier and there's going to be a while for us to build up all the relevant connections. But we as a platform should abstract that and then users should be not too worried about the specific technical connections. But more about the flow of information and the actual completion of the task and do you see it as something that the user is going to have choices when they're
 Working with certain systems or tools that well if it is Gmail you have choices of writing emails, adding people BCC. I think about that today actually. So we or we're about to go live with our first set of integration. So we've tried Integrations in the past users scream about and not we can talk about about user Discovery as well. But users right now scream of oh we want Google drive or let's let's stick with Gmail, we want Gmail and they're like, okay, what does that mean? They're like, I don't know, but I want it right. It's very, it's very abstract in many cases and users know, that, that might be interesting because that's where a lot of their workers. So if they're paying us, but they don't know exactly what and what we're building now is a user level authentication and integration systems so that users can connect to their Gmail and we now allow them to select the right relevant tools. And so the tools themselves have parameters were of course because it's basically a layer on the integration. And so,
 We're about dependent on the what make what the, what the Integrations make available through endpoints, but for the most part agents, get that information as. And this is what the tool can do. And so they can ask the user for questions. We can, we'll build a learning over time mechanism, for example, or you might always want your manager CC if you talk to this client, something like that. So the end user is going to have a select set of things that it can do with the different services but on the engineering team, on your side, if you wanted to, you could build out a tool
 Or build out something that someone can do right? Yeah exactly. And and the way we
 also communicate part of that to use right now is because let's take let's take it up, get those probably a good example.
 And and overload of endpoints, right? So we're looking at
 100 plus endpoints. That the platform can have. We've selected. What we think, is the most relevant for now and build Tools around that. And I think we are ending up at around 20. But even then, that's something that users, that isn't easy to navigate, right? It's like, okay, well, you have list repos, you have get PRS, you have get comments on PR. You have make new comment review, PR and something else, right? And so, the way we're communicating, at least part of that to users is, we've started to group them into skill groups because we say, in order for you to understand all of the new ones of these tools, it's going to be somewhat overload, for most users. So we say, okay, if you want to talk on, to be able to manage your PRS.
 Click connect here and it's going to automatically connect to six of these because it needs to get access to your repo. It needs to be able to read the comments and it's able to add a new comment, Etc. And so we started to group these. We'll adjust the email these along the way and but this kind of framing around skills is quite helpful. And then it's becoming a skill set, right? This version of token needs to be able to do these things, in order to complete my tasks.
 so, just closing the loop on the idea of the system and basically,
 everyone needing, or
 Folks, being able to think as an architect. Yeah.
 you're now thinking,
 Whatever your job is.
 you have certain repetitive tasks in your day-to-day and
 let's figure out how we can throw an agent in there.
 To make your life easier. That's the starting point yet. And what's next, what's next? Well, we first need to get this to work, right? So, we're still in. We're now in the loop of. Can we get this to work at all? Can we make it something that uses can easily set up? And can we make it so into it? If that it's going to be a no-brainer, right? And so, we're still at the start of making it work. We're about to release the first wave of Integrations. We already know that we need some sort of memory or learning mechanism for this, because even things like tool called details, I'll give you a very simple example that I've been using to illustrate this, but right now, fast. Talk on. Please schedule a meeting with my manager. I get a sure who's your manager, even if I've done the same thing 10 times, and then I'll be like, oh, it's yeah, nice. And then it's like, okay, well, what's the honest even? Like
 It's the same thing every time right? And so it's actually just a very, very simple example of something that it's actually just one parameter in the tool called, but without this parameter, we're not going to be able to do anything. And if the ambition is to do complex, multi-step tasks between systems and we can't get simple parameters, right. Then we're not going to be able to do it, but I think this is an interesting point where we look at memory now actually quite differently than I think many other platforms. Especially if you look at how Jet gbt Etc. Do memory, it's more personalization and we're looking at how can we learn to do tasks more consistently and in a better way but figuring out what the right inputs and outputs for tools should be power users are screaming for multi-agent. They are screaming for observability and evaluation on these kind of more complex systems, Etc. And then yeah, more beginner users are looking for Marketplace is right there like I don't know how to start. I want to see someone else share and then I can maybe copy and update it which is what I
 I thought I'm obviously the lowest common denominator because I thought, man, when I go to dokkan, I would love to see. Hey, you're in XYZ job. Here's a few great flows that you might want to get started with. We can connect this system with this system and then do this small task for you. Yeah, and that's coming when we have those connections and we know they work. It's been something we've steered away from before because it's very difficult to share something that's actually relevant to you, I mean, it's very easy to overload you and things that someone in your kind of role has done. But because every employee's workflows can be so different. And that's also why we think that the agent creation needs to be bottom up. For the most part, it can be quite difficult to be on the examples. Share! Hey, this is relevant for you because someone might work into Blow you might work and look her, they might connect to a specific database and you get your data set from Finance through an Excel sheet. Like your workflows your way of working are going to be drastically different. And
 This is probably one of the more similar kind of flows. And so sharing has been here is an interesting example, in where we make trade-offs in the product and we've, we've built or one, one of the bigger things we've built over. The last quarter is a configurable version of token. The Assumption was if we allow users to configure a token for their specific tasks, not just the token that they have available by default and they can give it permanent knowledge. They can give it instructions, Etc. Then they're going to be able to build a more powerful version that even without integration starts to be able to do some of those tasks.
 And while that's true, one of the things that we've not build out far as sharing and so we thought well,
 We will build our sharing when we know that this configurable version of token is valuable. We know right now, it's still hard to set up. There isn't a lot of them that are easy to you. There isn't a lot of them out there that are providing a lot of value that there's still a big gap in what users need. And so building sharing. Now has no value because yeah, sure. You have the ability to share, but there's nothing to share, right? So make it work first. And so we have the simplest version of sharing right now, which is a horrible user experience, which is the admin clicks on share. They generate a link and you can share the link with someone else. And now, you can join that custom version of token, use a flow wise, not as far from ideal but it works and it's not the world and don't think you don't need to go that hard on yourself because it's a but yeah, sure. But it can be much better for actually quite a little effort but it's the the concept of configurable versions of token isn't where it needs to be at. So building out sharing just like the marketplace idea is
 It sounds nice but the reality of it is probably going to be quite under in theory because there's so much customization and that gets to this other question. Now is going on in my head on
 Why you don't think about just verticalis certain?
 Tools or token products. I know that you thought. All right, well with data analyst we're going to Vertical that.
 Yeah, so so um it kind of just goes back to a bit of business reality where because of our target audience and we are somewhat Limited in the address of the market in a way. So we have 30-ish 1000 employees.
 User experience, research, we have one big advantage in terms of our users which just that because they're all portfolio. Companies, it's incredible on the phone with you. It's incredibly easy to reach. Well, they have to, they want to there's a lot more trust immediately. There's a lot more willingness to spend time. I think you're not trying to sell them anything. Yeah, exactly. Where there to listen to their complaints and I think when I started it was a lot of us reaching out at the moment. I might my first agent might be something to manage my inbox is because we get so many requests all the time from all kinds of different teams and it's hard to manage, but it's it's amazing. In the sense of seeing how many users are actually interested in this and and the benefit we get from that is we get to take a step back and Abstract a bit of well. Okay, lots of people are always asking for these things. I think that's kind of the product management dream of. Okay, we have 200 users from different companies, and different teams, and different workflows and different departments asking for something that we could conceivably try to build like this, okay? And then a lot of the user research
 balance is
 Um one tricky part is that okay? We want to kind of build a hat for the future, right? So we want to build new things and that are barely possible or not really easily conceivable. And so users are not really going to ask for that. At the same time, users, see all of this AI technology and like, oh, I want an AI for my legal database. Like, I don't know what that means, but if you ask them, they also don't really know what it means. They just want to plug in AI. Yeah. And no, it's gonna be useful. And then you go to them with your, you talk to them like well. Okay, when you say this, do you want to just have access to the documents? You want to summarize? Write something for you like and then generation should that work on a template or not? They're like, I don't know. And you're like well, okay. That's it's a, it's a very iterative process and I think one of the things we've learned is that we speak to users a lot and we have things like slack channel that has 1,300 users in there that if we have an idea we have a question. We just check it in there and we get lots of feedback right away.
 But what we've learned this build, a first version as quick as possible like the Integrations.
 Our assumption is that the user level authentication on top of a layer of apis is good enough for many workflows
 We'll see. So we want to give that to users as quickly as possible, see how they react what they complain about and then if we need more will build more. If it's good enough. It's good enough. What we know is that we need to be able to talk to their systems. So this is our first best, guess at how we can do that in a way that we can actually scale.
 How are you using breakdown? The flow of
 How you are using tokan in your own job.
 So I have a flow that might make me, I think it's a home office flow but I'm in the office every day. So, um, and I'm saying that particularly, because when I come to work in the morning, the first thing I do is I bunker down in a meeting room and I just use the voice input to just get out all the thoughts of my head into structured list. Oh cool. It's just
 It's not a like feature Wise, It's not that.
 It's not that impressive but it's a it's a very interesting flow of just I hate typing and I think every user Cuts corners and typing prompts. But if I can just get out all my thoughts and one go, then I start a lot of the things that I need that. I know, I need to get done for the day in the first 15 minutes of my day, it might start four five, six different conversations, and all I'm doing is I'm providing the relevant context by just
 Babbling on for five minutes that creates a massive prompt that I can then use as a base for tasks that I want to do down the road. And this can this can this depends on what I need to do. But this can be creating presentations and then kind of reports and structures like that and this can be
 Preparing for webinars doing some research. This can be doing a product update and so there's I still find myself as my head being the best source for a lot of this data, I can't easily pointed just as a Google Docs, but it's very easy for me to just summarize what's on the Google Doc and provide the Google Doc, and then that's a great foundation. And then, for example, presentations, there isn't a single great tool to build presentations. I've seen all of them are I think my favorite so far has been gamma. Yeah, I've seen that as well, but I think it does.
 It falls into the repetitive Consulting style slides, where it creates, three columns that have headers. And it's always, it's always so far from something that I would want to use. And especially if you want to explain something, it's not easily able to visualize and make connections. It's more
 There to break down content, and put it in a slide that you could present. But it's not easy telling the story. So now we've just started having to kind of create HTML reports, and so now I'm going to have a roadmap session next week, with our users and the plan is that I just have an HTML page that I click through that. I actually use as the presentation, which isn't the presentation, but it works a lot easier for token to generate it. There's things like this data analysis, I don't write a single line of code. I'm banned from all of our codebases and making any technical comments. So any sort of kind of review of data, is a lot easier for me like this. And if I have to go to Google sheet or Excel thinking about how you were talking earlier on the architect. Yeah. And what you would do when it comes to you, give this brain dumb through a voice technology. It then transcribes it. You fire it off to promise. You get that.
 How do you see that system working in the jobs to be done and all these tasks? Yeah, so so I think there's two things missing for me to lean into it. And either own, dog food, which is just that one, you can't. Yet configure a version of token that has Integrations, will have to add that soon. And so right now there's just one token and I can't have oh, this version of token writes my product updates and it has all the right sources in this version of token. And that's my user research and has all the right access. And so you see it as different token agents like gpt's. I think so. Yeah, it's a yeah, gpt's different different agents essentially because we know that completing tasks, especially like, because we're not really talking about reading email and response, right? But in an Ideal World with talk about
 Do a product update by looking at all the relevant things that we've said on slack and look at all the things that have gone into GitHub. Nprs and look at the jira board and then write it up as an email, send it to two people from the team, to see if there's anything else they want to add and then put it together as like, it's like block it that we can send out through a messaging system. And and that actually is still so much simple to help because it's not simple but it's a it's a very clear step by step. There's a lot of thinking in between if I talk more on strategic planning, for example, it's like, well, okay, well sure. I want you to know where the okrs are. I want you to find the latest product that I want you to be able to get a current status of the product. I want you to get the data for the product. I want you to do outside research. So these are much more complex tasks to combine and we know that at least would current Technologies and model performance, that becomes possible, but only if you have an agent that is actually very tailor-made. To do that specific thing. Otherwise,
 It can go all over the place, consistency goes down. So it might work two out of three times. And so configure, configuring a version that is tailored for job to be done is important and that actually allows you later on to share it, right? Because if I just share my tan, it's going to be harder because the likelihood of someone doing exactly the same jobs to be done. That I'm doing is somewhat low but managing a backlog, every product manager does doing user research, every product manager. That's right. And so,
 That yeah, makes it also easier to scale. And then there's a version of this where
 You share yours with me and I can just copy it and swap out a few things because I think it's a little red, you can, well, they're probably be two ways, one is just use it as well, so just join use it and that is probably more relevant for the company, like, within a company. So if I have, if I have a data analyst in a company, the likelihood that the next day that list has a very similar systems and access and rules is high. If we talk about sharing a cross companies, it's probably more like a template or a blueprint that you could update and change that systems change instructions.
 When we talk to florist last time, he mentioned, there was a hackathon you all did and the folks that won the hackathon were a jira agent. But then everything worked really nicely in the hackathon. But as soon as you plug it in to a real world jira scenario, the agent had no context that didn't understand what was going on. How do you think about that with the integration so that it actually works? Yeah, I think the hackathon we did was
 A quite well, I think it was the first time we did a hackathon around tool building. So there's a lot of things we learned around to a building. Number one is that and if we build a tool, assuming how a system works, then things are not gonna turn out well. And so one of the problems is that if we build a jira agent, ourselves as a team, it's another reason not to vertically. And we just assume everybody uses to your same way or all the boards are the same or everybody has a clean backlog or know everybody uses labels whatever you're looks like then, then this is not going to work and so our thinking is
 The core building block is access to jira and in the configuration you can tell your version of token. Okay? Well we just use we use we just use canva and so there's one continuous Sprint and there's just to do a refined to do in progress, done. And those are the only thing tickets at matter and whenever you create a ticket follow these instructions, so it's really about access to the to the integration or it's really about the integration itself but scoping that integration and shaping it in the way that you want to use that. Yeah. And then and then the main part there is what are the actions that uses want to take and systems? Right? So if I if we go back to the skills metaphor and it's if I have my version of token,
 What's the particular skill that that employee should have right? It should be able to create the ticket. Okay? Well and now it's more on
 Contextually, how do you guide it to do the right ticket and the right moment of time. And that's another reason for this kind of Knowledge Learning, right? It's actually its parameters in the tool called saying, this is the space we use in jira. This is the board we use in jira and now you learn over time that when I say, hey, for the token team, can you please add an infrastructure ticket that this does x y z? It's like, okay. Well I know we don't use labels, we've learned that before. I've made that mistake before. I just gonna put a square bracket infra in front of the ticket name, and I'm going to put it on to do with the same board that we use for everything else.
 But this is this is learning over time and and this is all our first draft, right? And there's things that will be able to make easier. If I think on more like the two year Horizon and also at process more like an investor perspective. Then the really interesting part comes in, when we can say, we can buy a company and within a month, we can start deploying an agent, Fleet across the organization and that probably means some crawling and indexing and learning from existing data and not having to rely on only users.
 So crawling and indexing, talk to me. Well, that's an interesting piece too, and it's fascinating to think that you could do that. Learn from the systems that are already in place, learn how they set up their jira and what kind of if they use tags or if they just use brackets. So, it's a, it's something, we've deliberately not touched because because looking at the current set of hypotheses, we say, well, the first AI employees are going to be bottom up and that inherently means bottom up and very, very narrow in scope and again micro but, and because of the employees that we've been looking at as examples, and as use cases, for used to build up the relevant context is almost always hyper focused on just completing that task. So when I do that, it helps as absolutely no. Let's say I'm doing a flow somewhere in product. It matters, not at all that currently.
 Says, has an event on going somewhere else in the company or how an operations team might structure their dashboards. Absolutely no relevance to this specific job. I'm doing so contact in that sense, is overrated as a company context. I think maybe I'll take, but the specific context is the most important part for completing job again. Probably current assumption, is that that's tool? Call specific.
 We currently think that the best way to get that out is through user interactions first because we wouldn't know where to start. When crawling, I think crawling is such a huge topic and you can almost every system is
 I don't want to say poorly managed but if you look at any Google Drive, it's a mess. And if you look at any Confluence and jira and GitHub has whatever and I don't want to talk about Salesforce at all. And like, so these are things that are very difficult and I think almost one of the things we're doing right now. Is we build a golden test set that says, well, we've been talking to this user for three months in order to complete his work. And now it's running completely autonomously. And these are the things we've learned, let's scrap that and say what happens when we crawl and index the system, how can we learn something that gets Us close enough in order to say, okay, this is a good starting point, but we don't have that test set. So it's not something we're going to start. So basically crawling and indexing just creates so much noise. Yeah. And and maybe crawling and indexing isn't the right way of looking at it. It's really
 Trying to understand reading reading and extracting, right? It's you want to, you want to extract the relevant piece of knowledge and I think right now we don't know the rules for that.
 It goes back to there's certain paths that are taken. There are certain signposts and if you think about the 80/20 principle, there's probably
 20% of the stuff that you're doing on jira is very important, and, you know that, but the other 80% is still there. And so if you have everything weighted the same, it's going to create a horrible system for the agents. Yeah. And useless might work in a different ways and so then do we ignore it? Do we take one. I think there's another actually really important point that I skipped at some point with just
 Many of these Asians will require to use it to redefine how they currently work. My, my current, and again, on a very specific process level, my current way of writing product updates. It's incredibly chaotic. It's very messy. It's not a process at all. And the reason is, I don't need a process. I know where I need to go, when I do it, I go. There I go here. I look at, I talked to the team and I get it done, but that's not agent friendly. It's not gonna work for an agent and it might not be best, right? This is very much.
 A human nature thing of like I mean some, some product managers would have built a process around it. I'm more non-processed so I wouldn't have done it in the first place and I'm gonna not do it and until after I had it over probably but

It when we talk on the learning from existing knowledge, we basically just look at existing processes. We don't have any space to redefine these. Right? And so, very much, the architect comes back into place and saying, well, maybe the right thing to do is, of course, we can look at what's there, but maybe what we should do, is say, okay, this looks like what it is. This looks like it should be the jobs to be done rather than this is the rules to replicate exactly what you're doing right now because the replicating exactly is, I think more likely to not work. Then giving a suggestion of how you could refactor the process work, right? I think that's a, maybe, an interesting view on this. So the reading and learning and extracting knowledge, inherently takes all the existing things as gold standard, or at least in a first version, which might also not be a good way to go.
 That's all we've got for today but the good news is there are 10 other episodes in this series that I'm doing with process deep diving into how they are approaching building AI products. You can check it out in the show notes. I leave a link.