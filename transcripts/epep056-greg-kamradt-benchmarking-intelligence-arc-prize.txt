This is too good. You were awesome, man. This is great.
 That's how we know it's legit now.
 Oh, I mean what? I was looking forward to this dude. I can't tell you how stoked I am. Tell me exactly how it went down. That you were on a live stream with Sam almond. Yeah. Um so I run Ark price right and we run an AI Benchmark called ark AGI which is we want AGI progress pulled for it like we want Tech progress portal because we believe it's going to be one of the best technologies that Humanities ever had. Right.
 There's a big question on. Well, how the heck you make progress. Go faster. And so, our route that we've chosen is from a benchmark and it's by created by Francois delay in 2019.
 He takes a very interesting approach, there's a lot of benchmarks out there they go, PhD, plus plus problems. And so, they'll ask you like the hardest question and then even harder. And they'll say, this is the last test where ever gonna have to take because we can't come with any harder questions. AI ends up solving, those like ends up doing it. Well, like the ceiling on AI is like, um, really high like it's insane. It's already doing some superhuman stuff so we take a different approach on that.
 We want to know what types of problems are easy for humans but hard for AI, I love that and the reason why just getting into it like the whole stick behind it is because we have one proof point of general intelligence. Right now
 And that's the freaking human brain. So these are things like strawberry. I would say that that is a class of problems where if you can find things like that, it's like dang, AI can't do that, but human still. Can we probably don't have AGI if we can convert those problems right now, the hard part, the hard part is, those are one-off questions and so it's easy to find one-off questions. But if you want to find a domain where you can come up with like, 200 questions in the same class that you can actually quantify this for then that becomes a lot more difficult. And so, our theory about AGI,
 And this is more of a working. This is an observational definition, rather than like, a inherent one is when we can no longer come up with problems that humans can do.
 But AI can't. Then we have AGI the inverse of that though. Is if we can come up with problems that humans can do an AI, can't do then, we don't have a not there yet. And by virtue of Arc AGI, one, our first, our first bench, our first version of our Benchmark being out there. The fact that it's even out there and unsolved
 That's a class of problems that humans can do. We just came out with arche GI too, and we actually went and gathered. We gathered up, 400 different people, and tested them on Arcadia tone every single task within there. And we made sure, because if we're going to claim that humans can do this, humans better be able to get better, be able to do it. So we, when we got four different people down in San Diego, and we tested on tested them, on all this and every task that was in there was sold by, at least two people in under two attempts. So, humans can do it. We have first party data for that, but AI is still can't do it. So,
 We clean that we don't have agf but they're kind of hard tasks they get harder for sure. Yeah, well that's what's crazy is the way that I think about it is there's a gap in between what humans can do. And what AI can't that Gap is narrowing and so we need to make sure that humans can still do within a reasonable attempt. We're not looking at phds, we're not looking at two girls to see if they can do these, a competent person. Give them these tasks and see if they can actually do. So, just if you pluck somebody off the streets, they have college education, type thing, more or less. So, like when we did our filtering, we made sure that they could use the internet, like things like that. Like we didn't want my mom is out. We didn't want to teach him how to use a computer taught them. What art was, you know what I mean? And so that that doesn't allow us to make the claim about the average human. So we are careful about. Not saying that, that's not where we're going for. Yeah we're going for a capable of human. Yeah some people like to argue with us on that but that but that's that's a different conversation on it so run this Benchmark arkhi one. Okay great we can email from
 A one of opening hours, whoever who we have a relationship with in early December, and it more or less. I'd say, hey, we we have a new model.
 We want to test it on Ark and back in that day, it was strawberry. It was the strawberry. There's so many names going around. I mean those are Ryan even at that point there are strawberry. There is what did ilyasi you know? There's some oh who the heck knows like what were? What rumor refers to what version and it hasn't gotten better to know. Official names are probably worse than the rooms and I think that, that tells you don't expect it to get better. Yeah. Because it won't get better. So, again, email says, we got new model, we want to test it. Okay. Cool. Yeah. Sounds great. It's opening AI. They have a new model and they claim to have a very good score but they didn't say what the score was in the email. And so, on Art, prize on Art prize because we have public data. And so the way we run our Benchmark is, there's much a public day that you can go train on, and you can go kind of test yourself on it, but then we have a hidden holdout set, nice that
 We can get into why that's important in the first place. It's the only way to do it. It's only way to do you have a hidden hole that stuff for it and they said, we want to see are we overfit to this? Because we think we're doing pretty good, but we want to try it on her. Holdout set, will you come and test it for us?
 So we spent the next two weeks, testing it basically working with their team, to go do it. This is through Europe's 2024 of last year too. So I'm like at nurse like in Vancouver thinking I'm gonna relax and just watch talks the whole time. I'm like, literally testing and hitting it open as API, endpoints for that, but we get through and
 It's like, holy shit, that's good. I mean freaking soda. It was multiples better than we had ever seen another model do beforehand. And keep in mind that this thing had been, this thing had been out there for five years so far. And there hadn't been this type of progress. So we're like holy cow. And so I get on a meeting with Jerry and Nat.
 To kind of just like, kind of like pre-brief before we go and do the testing and I say, what score do you? Do you claim on rki because we're gonna go and verify that because if they claim when it's different than that, be a big story, they claimed 87% and keep in mind like the high the highest on here with a publicly available models like in the 20s and then custom built Solutions. Purpose-built just to try to be Arc or scoring in the 40s and 50s at that time and they're cleaning. 87%. And so, it's like, all right. This is a really big deal for us anyway, long story short, we go through it. And what's interesting is in inference time compute world, you can no longer. Just say, here's our model, here's our score. It's here's the model. Here's how much inference time can compute, we spent. Here's our score. So now there's another, there's another variable on it. And what we confirmed for them is that on low compute and we can get into what low compute actually means in the second here, they scored 75% and on high compute. We saw it. Yeah more less we've validated their 87% score which is like okay. Yep, it's validated so we
 up our blog posts and just like a one page or Google doc and
 somehow or not somehow, but just like along the lines, Sam ended up getting pulled up on the thread, like on the email thread that we had going back and forth and we said, we have our results here they are. We want to discuss some live. He goes great. I'm free Tuesday at 5:30 or whatever and it's like, oh let's go. Yeah let's go like it's wonderful. I mean it's like this is a huge opportunity. It's like we put together a blog post and we get inside the room and we show them basically put up on the screen we show up a blog post. Everyone reads through it and discussion discussion and he goes okay great. You guys should join our live stream on Friday.
 It's we're not even like we hadn't even considered there were gonna be testing this new model like, you know, if you how sorry and then he says, you know, on Tuesday, you guys should come join us on Friday and our One requirement was that we didn't want to just go up there and have them tell us what to say. Like we didn't want them to write the script for us and so Mike and I my knoop who co-founded art prize, we basically wrote the script that we were happy, we were comfortable with, we gave it to him.
 That's a yeah, looks great. All right. Cool. So right exactly well so they they had a very big production not I would say big production but you know, call it
 You know.
 12 people between marketing comms, like videographers and events and sound and everything that were in there. And so we had two rehearsals that went through for that to rehearsals went through went great made edits and then, you know, the live stream comes out on Friday or went out on Friday. It's funny because there was a room that wasn't much bigger than this, but it was part. It was much bigger room, but there was partitioned off on all the sides. You know, with like kind of just like, you know, they whatever. Yeah mental. It was like, it was just a table. You guys are sitting around just with that. Um, but so I'm on the other side of the partition, I'm here in Sam and Mark talked about it, Mark 10 there at the time, they're sap of research. And they're like, now we'd like to invite Greg and then just walk from behind the wizard like behind the curtain and just go jump on there and what's Wild is that, you know, how many people were watching on the live stream but it was a small room like it was like I said, only like 10 people in there but it was cool. So did that. And but this was an unreleased model. So we now
 Call it 03 preview because there's a preview model for it and it was more of a capabilities demonstration about. What if you push this to the max, what could you actually do for it? And to put this into perspective on the low compute, it was they were spending about twenty dollars per task on this and we verified with 500 tasks and so that's about 10,000 bucks of compute that they spent on this. Just for Arc. It's like, dang, that's a lot, right? Yeah. Like, that's a different. You're not gonna find them in people that want to spend 10 grand on solar systems. Right? But that was low compute and then the 03 preview was the first reasoning model. No, no, it wasn't the first reason model because you know it depending on when you want to call I believe their first reasoning model was when they did 01 preview, I don't even know when that was that must have been early. 2024 mid 2024, maybe even 2023 but so we tested oh three preview, look at you and then we also tested High compute which is way more money that used. I forget the exact dollar amounts it was in the thousands of dollars per task. Oh what per task and again remember we tested you know 500 tasks
 Or whatever I think was 170 times, the amount of compute that was used on the low compute side, but either way the teal it's like, okay, so what? That's a lot of money, what what's the important part?
 the important part is,
 It just reconfirmed that you can pay for better performance, which is crazy, right? And there's open questions as to where that scaling actually tops out. And so, we haven't done it as thorough analysis on that system as we'd like to. There's a big open question on, does it asymptotes?
 Or can you get to 100% if you just give more and more and more? But keep in mind, it's log what you give it? So you they, you know, let's just say you spent a million dollars in order to get a couple percentage points upgrade you need to spend 10 million and then you spend 100 million. It's like, well, we're into actually end up stopping for us. Yeah. What's that trade-off? Yeah. And all. So
 Are you gonna have to wait a year before it gets done? It's a long time. So for the high compute, the job took overnight more or less like overnight, maybe you think took longer than I forget, the exact time on the duration for, but it was not a short amount of time. You're not gonna be sitting there waiting for the response. Something, you do. Yeah, let it run. Yeah. Go out. Have your life and then come back and see if it was able to do it. But actually, just today we opened at last week, they launched their 03 production great. Oh, three
 And so there's like a big open question. It's like, okay, well how does what we tested in December match to what was publicly released today? And we asked openhab, we asked Jerry for confirmation on this and a bunch of nuance tldr. It's not the same model. Exactly. It's not the same model, and there's less compute being used, so we should expect not the same scores and so we just that we tested on it today and yeah, as expected, it does really, really well, it doesn't do as well as the model that is 7%. It's not the 80%.
 But also they release 04 Mini, so they're just they're freaking keeping the models coming, right? And so,
 A lot of good testing, a lot of good stuff. But what's cool is that, like, arcade ghee is the tool that we're using to evaluate these things. We have arcade GI too and all these models are still going really, really low on our kids GI too.
 So, basically, Ark AGI 2 is meant to be like that next step, like order of difficulty more. So I I've been looking for the good analogy with it, so apologies, I don't have it down yet, but the way I think about it and this may be an incorrect one. So apologies, if I butcher it. But like, if ArcheAge, I won measures is really good at measuring car, speed between 20 miles an hour and 40 miles an hour below. 20, it's not very good over 40, it's not very good because it just maxed out. It's like, literally redlining it's over at the top arcade GI too is measuring cars from 40 miles, an hour to 80 miles an hour, right? So below 40 miles an hour, you're not gonna get much signal, you're gonna get a little bit of, you know, a little bit of stuff. So it's got to be those premium models. It's gonna have to be premium models and we're not yet seeing the that models are making substantial progress on it. So I think that the best open source model right now I think is getting like three to four percent. I'm sorry not best open source. Even when we tested 03 like medium, it was going like three to four percent on this and down at that.
 Range. We're only talking about 120 tasks on that. So like down at that range we're talking about noise, it's not until it starts to like 10 15 that you're really gonna start to see some substantial from it.
 Yeah.
 How did and how do you go about deciding these questions? Yeah and then there's also the other side of it where you can't just have it be a super hard task. You have to almost. You have to be creative about it. That's not what like again because we hold ourselves to the Restriction that humans need to be able to do it and that restricts you from just doing hard hard, hard hard. Yeah I can't be this Rite HD. Plus it can't be the PHD plus but as long as we can come up with those problems that tells you, there is a gap between human intelligence and Ai. And like, people argue with me and say, oh, you don't need to aim for human intelligence. If you want to aim for AGI because they're two different things.
 I agree. But, like, our hypothesis is that, the fast track towards AGI is understanding how the human brain works and understanding where the gaps are because if we aim for those gaps, that's going to tell something, interesting from there we can talk about this later. But like it's nowhere, the human brain is nowhere near theoretically optimal intelligence. Like we got a lot of biological baggage. I could tell you that right now. I my human brain is not working to full capacity. Exactly ever. So by no means am I saying it's the best example but it is our only example of general intelligence and so we see it as a useful model to go out there anyway so how do we pick the problems? So in 2019 first wash Lake came out this paper called on the measure of intelligence, which is so fascinating because it's like how do you come up with the problems? That's actually the not the question to start with the question to start with, is, how do you define intelligence? Because if you can Define it clearly then you can come up with problems for it.
 There's the freaking faster. Okay, so France walking on the paper on the measure of intelligence and so his definition of intelligence was
 What is your ability?
 To learn new things.
 It's not how good you are at chess. It's not how good you are go. It's not how good you are at self-driving.
 It's if I give you a new task and a new domain, a new set of skills that you need to learn in order to do it, can you successfully? Learn that thing? Is it how fast you learn that? So now that's a great question. So my opening definition of intelligence is always just binary, can you learn new things or can you not but his actual definition of intelligence is your efficiency of learning new things? So just for example, I like to do efficiency in terms of two axes. Number one is the amount of energy required to learn new things and we'll get into that in a second. But like the second dimension is the amount of training data that you need to learn that new thing. So basically how many times you need to do it before you learned it? Exactly. So a crude accrued crude example is. If I'm going to teach you how to play go, we might need like six hours. I'll teach you the rules and you'll become you'll become like basic at it. We can at least have a conversation around it.
 I think about how much training data went to the system that ended up beating up a lot a lot, right? And so, of course, that was better skill for it, but there's almost out outside training that I went into it. So another way to do this is do humans have an internet's worth of training data in their head, to Output the intelligence that you see from us right now. And the answer is no, no. It doesn't language models do. And so on the recent podcast it was the internal one with openai, Sam Allman and believe the name. The fellow's name is Daniel but he was talking about the efficiency of language and what is an LMS efficiency of language versus a human's efficiency of language and he said by his estimate I think this might be a little low but he said that humans are 100,000 times more efficient with language than with current llms which speaks to. And one of the underlying things that they kept on talking in the Pod was that look compute isn't What's blocking us anymore. We have a shit ton of compute. Like we have a lot of compute like Stargate all of them in video. We have so much freaking compute. What's blocking us right now is more on
 The data side but underlying all that was blocking us more is also on the algorithmic side. Yeah. It's like we just literally need new. We just need new algorithms. Basically break throughs in order to get to the human levels of efficiency on it. Just the random points it really drive this home is like the other reason why I love using the human brain as a benchmark for is because you know how much energy the human brain takes like literally like how many calories does a human brain consume and you convert calories and energy and then you compare that to what is the inference energy used to solve Ark?
 Like you can already tell you're you're Miles Ahead your Miles and Miles Ahead. So human brains is a good Benchmark for us. Also we should note like did this all just start you down this path from the needle in the haystack. Was that like what blew up, you know?
 Needle in a haystack was is a fun bullet point on my journey like that I've been on so far. I want to call the thing that did it, right? I mean it was cool, but it wasn't like it. Like it wasn't, didn't make me Rich. Like it's like, oh, you say it's like, there's a small little thing like on, like you got a small reach, I got, you know, it's like, yeah, I got a few likes on Twitter but it wasn't like it wasn't much from that.
 So, no, but like the inherent thing, like, what, whatever it is about, what drives me and like, whatever it is about me, that makes me put my energy where I do needle and haste like, came out of that spot like other stuff comes out of that spot and like, you know, everything. And so, like I would say that all, like, all the activities that happened were symptoms of where I choose to put my energy and consequences of it and those consequences line themselves up to put myself on the path and where I am and then it opens doors. It's like, hey, this happened you? Because for those listeners also, they should know that you were doing amazing, tutorials. That was like, I was doing YouTube work. Yeah, that's how I found you is. Back in the day. When you were doing the YouTube tutorials, you were like, the first guy making link chain, what's well? So that's another wild story. It's just super brief on that. I remember the first link chain. Well, I saw scrolling Hacker News trolling or whatever and I saw it was this was October.
 Like 22. Yeah it's like right? When Chad came out, right? When you have to be, maybe even a hair before.
 And it said show Hacker News link chain. So it's like, literally like there's like the like the launch blog post, the link chain and I'm looking at this and I'm like, holy shit, this is solving a lot of the problems that I had building with the raw API at the time because it keep in mind at the time, there wasn't a chat model. It was just DaVinci 03. And so, like, trying to work with that thing was obnoxious. Like, you could go, there's a lot of friction to get the value out of it anyway, Lane helped out with that a little bit more. And I was like, this is so cool. And I had had a previous history of doing pandas tutorials on YouTube. That went nowhere. They freaking talked. Like, there's talk about like me and like my mom's basement in my underwear, like making Panda. It wasn't exactly that. But it was along those lines. So I made I think like some like 80 pan just like that because that was my craft like data analysis, was my craft at that time. That's what I pride myself on. And I saw I went to YouTube and I typed in Lang chain and nothing. There was one tutorial by a guy who ended up knowing a little bit later on. I'm super awesome. His name's James Brinks and there was one lynching tutorial and I kind of had just
 Like one of those small little, like little light, but light bulb moments, I was like, dude, great. You should do what you did for pandas, but you should do it for Lane Chan. And all I did for pandas was just see what I was curious in go and make a bunch of like tutorials and functions.
 And so at the time, just based off, just riding my pandas kind of like successful Ripples, and it wasn't success. I just mean, like, whatever was coming from it. I was like three or four new YouTube subscribers a day. And I did my first LinkedIn tutorial and I got 16 new subscribers after that one. I was like, that's 4X success. That's where I was. Anyway, I did number two, and that next day, I got 25. And I did number three. And that next day, I got 50 and keep in mind like that's 10x when I was doing beforehand. I pulled my wife in the room. I'm like holy shit. Eliza.
 This is like there's something here like I I've already told the story a few times but like there's a few times in life when you notice that the ROI on your energy that you get that you get sometimes often in life, it's like you put out one unit of an energy you're getting like 20% back like it's really not much, like you might get some money but you're not getting like fulfillment, you know, blah blah. Yeah, that moment in life. I'll spend a one unit energy and I was getting like two or three times back because you're getting an energy. I was getting energy, like, I couldn't sleep, like I was just like, I gotta wake up. What am I doing today? Like what tutorial am I making today? You're just upgraded my setup. Like, I was so freaking jazzed on it. Like I know like met Harrison did all this other stuff and just threw that just natural questions came around. Like how do you do better retrieval? All these business questions that I had beforehand? How do you do better on that? And one of them was for needle in the haystack, which is everybody was talking about long context. Oh, it's longer longer longer longer and I'd see some tweets that were like, yeah. But it's actually not that good at long contacts. I don't like you guys are idiots. Let's just go and test this. Yeah,
 There's some process, we can probably. I was like, remember I'm a day to, dude. So that's my craft. And all I saw in my head was a heat map. I was like the length and then there was that whole question around, like, if the position of where you needle was had a factor into, it was like, might as well, throw a two by two because it's gonna look pretty if nothing else and so ended up doing that. That's where needle in the haystack, came around so wild man. Yeah, so now we were talking before about the reasoning models and just this test time computer and you have thoughts. Here's the undisputable. Fact, you spend more money at inference time. You get better performance. The open questions are, and this is where people argue with me, but I still believe it's open. Is it does ask like for top, top Frontier models, does asymptote sub 100% or can you get to 100%?
 I think there's too much money that you need to go figure out to go try to answer that question. That's a big one. So it's it's so high-risk that why I even try? Well not high risk perception. You the cost is guaranteed here, it's been a time of money. What you were what you get returned TBD on where it is. It's not it's not worth it right now. But here's the other thing is like, I hurt a lot on AGI and a lot of that stuff. We're gonna, we have really, really useful economically useful models right now without having a GI
 That's cool. Like that's great. I love it. That's value to the world. I'm a capitalist. The heart. Like I want good tools to be used for the good of humanity, LMS 03, 04 Mini, all that stuff are great tools that are going to bring us really, really good progress. The AGI conversation is a separate conversation, and that's more of a theoretical philosophical scientific one around. Well, what is Agi? How do you actually Define and how we go in for that? Yeah. What is intelligence? What is intelligence and what's Wild? What blows my mind is, I'm your freaking get me going, man. I'm yeah. Well, what's Wild 11 up? What's wild man? Is that we don't have a formal definition of intelligence that the community relies on. Yeah, it's for something as Hot Topic as AGI and what we have right now, it
 It's making me wonder if it can be formally defined if it hasn't already beforehand. There's a few stories. I can tell my head one. Is that can't be.
 But that also takes a very humans are really smart approach. And we've seen many times over and over again, that like humans are not as we think we are. So the alternative is that maybe we just don't have a sensitive enough. Understanding about like the actual tool about what we need for it, but then the other story is the other story that you play in your head is like, yeah, it can be. We just don't, we just don't know potentially and we're never gonna know.
 Potentially. Yeah, and then there's there's a whole different subclass intelligence, which is human relevant intelligence. So, like there's a certain class of intelligence that you need to survive on earth. Right here. That's what humans have. That's what we have and build up there. But if you, if you really expand out, this is where we get into like, more philosophical like
 The in the, in the grand scheme of things, the Earth is a pretty small piece, right? So if you're talking about Universal intelligence and talk about like, theoretical intelligence and let's not go here, but I'll just, I'll just light The Mask. So the kid if you, if you jump into people are gonna think I'm going over the edge of this. But if you jump in like simulation Theory,
 what's the intelligence that governs? That type of thing that would make our own world that come from there. I guarantee. It's not human relevant intelligence and there's a there's a theoretical Optimum that's that we're not even gonna touch. But that's the other thing too. You got to walk before you run. We're going to start with human intelligence first anyway.
 Reason why? I mean, they're great. I mean, you can scale them
 Throw more money out of them. Get better performance. They take longer thinking for longer. There's big open questions on how the reasoning models actually work. And so one simple way to do it is the very first reasoning model that people ever came up with was they told the model, please think out loud first and then give me your answer that ended up doing better performance, crazy right? And then once you go do is you go train on processes like that for much much longer and that's another way to scale these things up. You say, think for longer, think for longer, wait, reflect a reflection step, you know, and you say, you say, keep on going another method to scale these things up, is you say, all right, I'm gonna tell ten of you, I want you to, I want 10 of you to think out loud. And then I'm gonna see what all ten of you respond and I'm gonna pick the Benson that comes from. There was even further ways to do it which is like, I want you to think of the first step in your process. Okay. Now what are 10 potential steps that would come after that? First step. All right, I'm gonna pick the best, the best one of those 10. Okay, now I'm on Step 2, think of 10 potential steps, threes. I'm pick the best one, and then, boom, boom, boom. And
 Go all the way down. There's always latency and cost straight off to come with those things. But either way I it's undeniable the performance, you're getting from these things and how good they are.
 Even through Vibe anecdotes and even through Arcadia High Performance. So they're very impressive. Yes. So it's almost subjective and objective. Don't get me started. I mean,
 This is another one. I think you guys have verifiable domain, like, you can just go check is the right answer, right. What blows my mind is like there's no right answer for how good a summary is, right? There's no right. There's no right. Answer for how good an AI took notes on your call and then went and put them into Salesforce. Like, how good are the notes, right? Yeah. And how good are they to who? Well. So, that's the whole point is,
 You have to keep in mind. What is the background engine? What is your eval engine in which you're evaluating these things. From with Arc we can it's an equality check. We can tell we have the right answer. It is not write much of what drives the economy and drives humans and everything that eval engine is human preference. Well, that's what I was gonna say with our, don't you find the
 Answers can be subjective. So if you're just looking at whether or not the task is correct. Yes. If you're looking at claims as this is human solvable or whatever, then it's a lot more subjective. There's a lot more subjective that comes from there. But in terms of evil engines,
 I have.
 I have a priority order of my favorite evil Engineers back. Their number one is going to be physics.
 And what I mean by that is I think that the coolest thing that we could have ai do for us, is discover new knowledge about reality basically about physics. So you think about what is the right answer? Well, it's what is the scientific process say about physics. As the eval engine. That's so freakin cool. There's no umbrella. That encompasses physics. Physics is what we're in. Right? And so I think that's, that's number one, that's super cool. Number two, capitalism. And so you think about capitalism is a human contract of a set of rules that we all, we all play by the system and there's laws and there's how we choose to do things running a business is an experiment playing in that world, right? And so it's like almost like capitalism is the evil engine and like I'm gonna go try to make a whole bunch of money but you got to do within the rules, right? And so like, there's certain things you need to go for us. I think capitalism is really interesting, email engine, and then human preference after that, which is like how good is the summary. But the wild thing about human preferences, there's no, there's no way to
 Like at scale, quantify that which is really tough, which is why when you do role HF you got to go spin up like not data centers but like huge conference rooms of hundreds and thousands of people giving you preference optimizations on which ones better, right? That's how you do it, which that's crazy, but that's what it takes in order to do these things. So go back. Sure, real fast for this capitalism. One or even the physics one, because
 In a way, we are assuming that.
 What is happening to us as humans is discoverable? Or is the engine that you valid? Yeah. Potentially it's not. It's just us as humans. Yeah. So a big caveat with that is the way that I think about it is if it's true what we see is what we get like if it's true that like reality appears to be what it is and I know there's going to be like even as you start to delve into like the quantum stuff and we don't know what's on the multi World side. Like we don't know what's on that other.
 Pending something surprising coming out of there, which I would love because it's like I want the truth and if that's the truth and freaking so be that's freaking awesome pending all that. Assuming what you see is what you get. Then I think what I say still hold on like I still think that is the reality is if there's some unexplainable thing that like it's just out of our reach to go do it,
 I'm a little. I'm I like answers less that. We don't have an explanation for at least, but like, I'm not ruling it out. I'm saying. Yes, that is a caveat. I'm operating looking this way for it though. When I think about it, it's like, there's something beyond our understanding. Yeah. Potentially that is what we are going to get helped to understand AI can help us understand it but it's going to be outside of what we are looking at. Just like when you have the, the chess move that is played. And then later it's like, oh yeah, of course. What I never would have thought of that or would have taken us decades to figure that out. Now we get to see but
 That's a wild one with you man. And humans are traditionally very poor at forecasting, the unknowns and right now. That's all I know notes. Yeah. And countless examples going. Ask somebody about something in the 1800s. What would today be like? They have to have no freaking idea, they just said no idea what came from so that will that will happen to us like whatever happens. And you know, even with how accelerated these timelines people talk about, I mean even called 10 years from now like you know what, I had a great dinner. Tonight's ago with a friend and he was saying, I had as a thought, experiment to come up with headlines for what 2030 would be saying in different magazines. So he was saying, I created one headline for Wired and it was that
 Teen 3D prints microchip in their basement type thing. So that was one. Sure. And then another one was and this is a complete tangent, but it's trying to think forward on like, oh, what could be possible? Yeah, he was saying
 Data center on the moon opened or second data center on the moon is open by the US type thing. And so you're like well maybe that's not too far off. Yeah I'm both. Those are very seemed tractable to me because the path to do those is you could lay that out, like it's straightforward. If you said something that didn't have a clear obvious like lineage to get towards that. Then I would start to think about a little more. But yeah, I'm of the David Deutsch philosophy. The all problems are solvable and that's the argument for optimism is if you believe all problems are solvable, then there's nothing out there that like should really worry you that much, because you can go figure it out, go do it all after. He told me that I was trying to think, what would my headline be for 2030? Where would I go with that? Five years now?
 Four years and three quarters. We're gonna be specific. Yeah I mean you kind of gotta be with these things. It's like
 Here I'm sad. Quarter could be a big because I think I've been listening, I've been going deep, really deep on. There's a big conversation around intelligence, explosion.
 30% growth, or GDP, growth rates, and all that. And one of the criticisms I have with some of the more outlandish ideas is that they're not as tactical and they're not as concrete, as I really wish that some of these projections were so getting concrete saying four years and three quarters, it's like, well damn. Open AI, just came out with 04 Mini this past week. When is 04 coming out? One is for pro coming out? Could it be like at the beginning of 2025, at 2026? If so you only got three years left,
 For with those types of things to go for it and so concretely, like how are the, how was the GDP gonna grow 30%? How is that data center gonna get up to Mars? How many like Windows launch Windows are there left, or even up to the moon or whatever it may be. So it's like, well what I'm thinking about one thing? That's called my that's nerds on me. A little bit is like, so Elon wants to go. He has a Mars window that he wants to go shoot for humans are not going to be the first
 Yeah. Why would you we already have the Mars rover, we have the Mars rover and so humans are gonna be the first one. So that means they're gonna send Optimus up there.
 Could you are we going to have AGI on Earth?
 Before that window. If so, then you pretty much have AGI on Optimus because like you just go send a bunch of commands. And so, next thing, you know, I feel a little bit like, almost insecure, but then I need to remind myself not to be so emotional, but it's like, damn, humans, weren't the First on Mars.
 So, you know, missed that one, you know, I mean, sort of it sounds so lame but to think about it, but that's, that was my first reaction was like, damn, there's gonna be this robot that is intelligent. That's its own human being, but it's not a human. And then I think it's like Dan am. I just species? And I just love like the human race so much, and I need to open my eyes. I wanted to plant that US flag on Mars, you know, I don't know, even if it's just like Humanity's flag or whatever may be. But if you think about it that way, there's already been the Mars rover. So how is it different than the Mars? That's where my biological baggage is bringing me down, you know? It's just because it's like a humanoid shape, you know, which I think it's less. The humanoid shape for me. And it's more just
 A generally intelligent being that can do it need to be but isn't the Mars rover? The martial Rover is not being controlled as it is. I think it is. I don't think send it instructions and tell it to go. Do I? That's a good question. I should figure that moves pretty slowly like weights like this. We got a fact. Check that one. Yeah. Just like, what next? You're like three minutes later or four minutes later. Okay. Turn. Right. Or pick up the raw. I mean whatever. I don't think it's that far off. Yeah, it's like that. That's funny. Yeah. I thought it was a bit more autonomous. Yeah. And or maybe they send three or four instructions at once and if it fails then resend no more figure out where we're at now. Something like that. Somebody will have to give us that one because that is, that is hilarious. What else you've been thinking about?
 Yeah, well, in terms of headlines, I still think, you know headline, I'm thinking about her so headline 2030 wired says it.
 I,
 I don't think it's outside of the question that there could be a headline that says,
 Humans are no longer able to come up with the questions that I can't answer.
 Which isn't that sensationalist like it's kind of muted from a sensation standpoint. Like if you use our definition, like the observational, definition of AGI,
 That? What? What are the problems are there, right? But I still wonder if there's a world where you have
 Run out of questions but you're still not seeing it where every once in a while you'll find that question it's not that you can find 100 of them but there's still those stupid questions where it is like the strawberry or the 9.11. Yeah and here's the thing, I don't want to give the viewer the impression that I'm relying on this as a formal definition. It's I think it's a pretty good working, definition for sure. It's easy to communicate and it's easy for us to go against. I think we'll come up with the formal definition but to your point, how often do you ask a human?
 a question and it's like,
 What are you thinking? You know what I mean? So like as efficiency is such a good big, big piece of this year, it's like that Will Smith. I Robot meme that keeps on going around you know it's like you asked me a question. Can you right? So yeah. So then I could see that though. Yeah we can't come up with more questions or we have to have ai come up with the questions that it can't answer. And you know that that's a whole nother. I think that's a very underexplored.
 It's talked about using AI to help build AI to help a line, AI to help test it, you know, all that other stuff. And that will happen because like again, definitions are important. But like, look at all the people using cursor right now to go build AI models. It's like, is that using AI to help you build AI? It's like, yeah, it is. So it just depends about how direct you want to use AI for. But yeah, so what we're thinking about for rpgi three, because we come out with Archie GI too is it's gonna get beaten one day, right? We know that Archie I2 could be Brute Force, so if you give a data Center's worth of compute and energy and time like a month worth of data center. Yeah, go through force. It and literally try all random permutations using one of the dsls to like try to solve Ark. Yeah, you're going to figure it out but that's why efficiencies is a big piece of this. Then the energy in the cash that you need to do. Go do that. Isn't it? Doesn't make us interested because it's a verifiable domain. Do you consider art one?
 Beaten.
 Because of that, 87% like is 87% a pass grade. That's like a people for a long time. We talked about 85% being basically human threshold on rki one. I think that much like the Battle of mlu where people were like we got 80.8. Well, we got 88.9, we got 90.1. It's like at that point, your red line, where your signals actually telling me before and you're actually losing signal and you get diminishing returns on this thing comes from it. So I think the Arcadia one for anything between like five
 To, probably 90%, I think it gives you really good signal on. Where something is anything outside? Those bounds is not gonna, it isn't giving you a ton of it for it. So, I think it's still a really useful tool today for it. It'll eventually go out of Vogue, though, once models, get so good at it. It's getting closer and closer. So it's almost like you see the end of this total life span. Like, here's the deal, it's like Benchmark, there isn't one Benchmark to rule them all. Like even if you wanted to understand a models capabilities, you need a portfolio, not only that but look how many benchmarks like had their place and then we're phased out because they did their job. Like, just even for example, look at image net, what happened with that to 2012 a big data set of images.
 That had a huge impact on the industry and it did its job. Would anybody go and do they report? They report on image that today. And that's okay. They have other types of benchmarks where they need to go deeper into like image Vision capabilities, in order to get a better job about it. So that's where arche GI 2 sit. But like I said, we're not seeing meaningful meaningful performance on it yet to have it. Give us a ton of signal brute force, it if you want, but then you're kind of defeating the purpose. Totally. I'm just so even though you can do it, should you? Um, so we run and we run a cowgirl competition to try to beat Arcadia too. The incentives, there are to beat it at any means necessary, because we have money on the line and within the competition rules. There's no type of solution requirements. So people prove for the crap out of the all the time, like that's a whole other part of my life, it's like if anybody was talking about benchmarks, great. I love. I can talk about all day long. If anybody wants to talk to me about running an AI competition,
 Talk to me about all. Yeah, we did all last year. We put a million dollars up to anybody who could be Ark AGI on cackle and nobody was nobody was able to but like we saw leaderboard probing. We saw people getting around the rules. We saw where our incentives where we made assumptions about competitors? Participants incentives. We're not in line with our assumptions. Wait how so
 Uh, yeah, basically if somebody if you want to win prize money.
 You need to open source Your solution.
 We thought that the money being a monetary incentive, would be enough to make people open source or solution. There was one group out there who had a really strong solution, really, really awesome and they made the choice. I'm not actually, I'm not exactly sure as to the exact reason. It was one of two. It was either we think that we have a better chance at not open sourcing our solution and competing next year, for the grand prize.
 To do really good at. And so they wanted the 700,000 dollars and said of just the the yearly 100,000 dollars or it was because it was so close to their startups proprietary information that they didn't want to open source. It both of which are not necessarily in spirit of what we work. Look, we were aiming for as a competition, but we did not properly construct the incentives enough or communicate early enough that this was an issue. And so we basically did what we could which is took him off the leaderboard because you're not placing if you don't open source and then this year, we made a lot more. We're being much more clear about our intentions with. How are you aligning incentives now?
 Through better communication and then not only that this year, we have a public and private leaderboard. So the leaderboard that's that's seen right now is all just based off a public data. But the final leaderboard that says, whether or not you've even placed their done, well is all in Hidden data and if you want to get your private score, you need to open source. Nice? Okay. Yeah, so we're hoping that that does it either way. We're not talking about 100,000 teams here, we're talking about maybe 10 teams that are in the running. I can go I can go and have conversations with each one of those tens and make sure that they're seeing it the same way and all the gaming of the leaderboard. You saw that? Yeah. I mean so people get creative because like money's on the line, money is on the line and calculus are professional competition people. They're really good at data science stuff in the really good at playing competitions. And so one thing that I saw is that
 They will try to suss out attributes about Ark, tasks one at a time and what they'll do is, is they'll put in a weight statement in their script that says, if you see this current task attribute, wait, 50 seconds. And then when they submit their solution to kaggle they say, did it run instantly or is it? Wait 50 seconds. And then that's the way that that's a way. You can tease out some more information about it because the only other information you get is you get a score that you get, you get a single integer, which is your score out. The other end, you can't really tell that much information about that.
 cargo tries to prevent that a little bit more with some obfuscation about how long it actually took, but people people could create it like that and now with the
 Arc prize 2. Yeah.
 Do you have to create?
 A variety of.
 Different tasks or is it very much in? All right, we're in this one field trying to do so you brought up a question earlier, which was good and I didn't answer fully, which is does it take a lot of research and like, deep thinking to build these things? So I would say for France, paper 2019, that's what a lot of work to put that that hypothesis together that formal definition or that that definition of intelligence right out of that came, okay. Using this definition of intelligence, what would a problem look like that would actually go and test these things and that's where the ark Paradigm came in. So,
 What it is is basically you have an input and you have an output grid and it's just it looks like a checkerboard and you see okay, the input turns into the output, some way. I need to figure out how to how do you transform the input into the output? You get a few examples and then you get a test and on that test you only have the input and what your goal is. You have to go sell, buy, sell and type out. What the output would be.
 The important part is that each separate problem on rkg. I requires a different rule
 or a different transformation to actually solve. So what I mean by that is let's say for variety super variety and it's almost like it's a meta thing. I'll get why this is important in a second. The way that why this is important is let's just say one Arc task has a square on it and on the input outputs, all you're doing is you're just adding a border to the square.
 Okay. Now we're on the test input. We're going to give you a square. We're going to ask you and I'll put you just need to put a border. Okay, cool.
 That border transformation rule will only be asked once.
 On another task. What? We might ask you to do is fill in the corner of every single shape, you'll fill in the corners of all those different shapes. And so, what we're what, we're forcing the tester to do is learn the new mini skill in each one of those questions. And then we're forcing you to demonstrate that you've learned that skill on the test, by doing it by doing it, which goes back to the definition of France was definitions, which is learning new skills. That
 Is.
 So simple for us, write a border on a square but it is, but it's exactly. And the reason why it's so hard for machines, it's just humans are very good abstraction and reasoning. It's like, oh, does just put a border. Yeah. Okay. But that's actually really hard for AI to go. Do now Arc one,
 People like, oh, it's so simple. It's not a good test of AI. Well, keep in mind for five years, it was unbeaten, right? And it actually pinpointed the moment like right when model started to get good, was the exact moment that reasoning models took off.
 Okay, that's just something really interesting about reasoning. The models and using Arc one as a capabilities to search and you can actually tell something about reasoning. The models that there's a non-zero level of fluid intelligence, that actually comes from that which is very cool Ark. Two is a simple extension of the arc. One domain we still have input output,
 We still ask you to do rules that the difference with it is that the rules are much deeper, and they require a bit more thought from a human perspective, code to go do it. So instead of just doing a border we might ask you to do a boarder and do the corners. So there's next and now there's two rules, I won't go to the details on. We actually have a full France while put it together. A we hosted a private preview of arkhi 2 for donors, for our prices were a non-profit. I just said that earlier not profit and he gave a 30-minute presentation on Arcadia too. Wow, but where I want to talk about, architect III, of course. Archie I3 is going to be departing from the archai one and Arcadia, two framework style of doing it, style of doing it. So it's a very scoped and narrow domain. If you just have a matrices input output, you know, film or whatever scope you don't very many axes of freedom for that.
 so, we are taking inspiration from
 Simulations and games. So, back in 2000 things, 2017, deepmind, they put together an exploration, they call the agent 57. So they tried to get an agent more or less an RL agent to go and try to be a bunch of different Atari games, right? There's like four that didn't solve, which is super fascinating,
 What Arc AGI 1 and 2, don't allow you to don't make you do is they don't make you figure out what is the goal. They don't make you figure out the rules of the environment. They don't make you have long-term memory with hidden States. So like you learn something early on in the game and you have to remember that that thing still applies later on in the game.
 And so what I tell people is if if you can make an AI that beats one game. Well we've done that a bunch. We've made aib chest. We made AI B go. Okay, cool.
 If you can make an AI that beats 50 games,
 That's much more interesting, but the problem is that those 50 games are all public and you can have developer intelligence and developer intuition as the how to go beat those 50 games. What Ark AGI 3 is going to be, is we're going to make AI beat 50 games. It is never seen beforehand, and they're each novel from each other.
 And that is a much further extension and actually is a freedom about where we're taking this, what you can, assert about the model that beats it is, it will have had no choice but to interact with inspirement learn the rules of the game in 50 different novel situations, but you're not letting it just simulate for hours and hours, or maybe you are that's a test time compute. We think we will. And that's where efficiency comes into it. And so, what we're going to do is we're gonna go test 400 humans on those 50 games and we're going to see how many actions does it take for a human to actually solve this? And how many actions does it take for AI to go solve it? So that's where we get. Our fishing comes from, in addition to cost and energy that comes from that,
 I think we gotta go. I just saw the beautiful boss, man, beautiful. That's a great way of ending it. We'll cut it there. It's too good. You were awesome man. This is great for going I but it was perfect. It was like